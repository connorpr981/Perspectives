[
  {
    "index": 0,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:00:00",
    "content": "Today I have the pleasure to speak with François Chollet, who is an AI researcher at Google and creator of Keras. He’s launching a prize in collaboration with Mike Knoop, the co-founder of Zapier, whom we’ll also be talking to in a second. It’s a million dollar prize to solve the ARC benchmark that he created. First question, what is the ARC benchmark? Why do you even need this prize? Why won’t the biggest LLM we have in a year be able to just saturate it?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nToday I have the pleasure to speak with [François Chollet](https://fchollet.com/), who is an AI researcher at Google and creator of [Keras](https://keras.io/).",
        "clean_text": "Today I have the pleasure to speak with François Chollet, who is an AI researcher at Google and creator of Keras.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "He’s launching a prize in collaboration with [Mike Knoop](https://zapier.com/blog/author/mike-knoop/), the co-founder of [Zapier](https://zapier.com/), whom we’ll also be talking to in a second.",
        "clean_text": "He’s launching a prize in collaboration with Mike Knoop, the co-founder of Zapier, whom we’ll also be talking to in a second.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It’s [a million dollar prize](https://arcprize.org/) to solve the [ARC benchmark](https://arxiv.org/pdf/1911.01547) that he created.",
        "clean_text": "It’s a million dollar prize to solve the ARC benchmark that he created.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "First question, what is the ARC benchmark?",
        "clean_text": "First question, what is the ARC benchmark?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Why do you even need this prize?",
        "clean_text": "Why do you even need this prize?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Why won’t the biggest LLM we have in a year be able to just saturate it?",
        "clean_text": "Why won’t the biggest LLM we have in a year be able to just saturate it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 1,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:00:28",
    "content": "ARC is intended as a kind of IQ test for machine intelligence. What makes it different from most LLM benchmarks out there is that it’s designed to be resistant to memorization. The way LLMs work is that they’re basically this big interpolative memory. The way you scale up their capabilities is by trying to cram as much knowledge and patterns as possible into them. By contrast, ARC does not require a lot of knowledge at all. It’s designed to only require what’s known as core knowledge. It’s basic knowledge about things like elementary physics, objectness, counting, that sort of thing. It’s the sort of knowledge that any four-year-old or five-year-old possesses. What’s interesting is that each puzzle in ARC is novel. It’s something that you’ve probably not encountered before, even if you’ve memorized the entire internet. That’s what makes ARC challenging for LLMs. So far, LLMs have not been doing very well on it. In fact, the approaches that are working well are more towards discrete program search, program synthesis.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nARC is intended as a kind of IQ test for [machine intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence).",
        "clean_text": "ARC is intended as a kind of IQ test for machine intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What makes it different from most [LLM](https://en.wikipedia.org/wiki/Large_language_model) benchmarks out there is that it’s designed to be resistant to memorization.",
        "clean_text": "What makes it different from most LLM benchmarks out there is that it’s designed to be resistant to memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The way LLMs work is that they’re basically this big interpolative memory.",
        "clean_text": "The way LLMs work is that they’re basically this big interpolative memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "The way you scale up their capabilities is by trying to cram as much knowledge and patterns as possible into them.",
        "clean_text": "The way you scale up their capabilities is by trying to cram as much knowledge and patterns as possible into them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "By contrast, ARC does not require a lot of knowledge at all.",
        "clean_text": "By contrast, ARC does not require a lot of knowledge at all.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "It’s designed to only require what’s known as [core knowledge](https://lab42.global/arc/core-knowledge/).",
        "clean_text": "It’s designed to only require what’s known as core knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "It’s basic knowledge about things like elementary physics, objectness, counting, that sort of thing.",
        "clean_text": "It’s basic knowledge about things like elementary physics, objectness, counting, that sort of thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It’s the sort of knowledge that any four-year-old or five-year-old possesses.",
        "clean_text": "It’s the sort of knowledge that any four-year-old or five-year-old possesses.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "What’s interesting is that each puzzle in ARC is novel.",
        "clean_text": "What’s interesting is that each puzzle in ARC is novel.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It’s something that you’ve probably not encountered before, even if you’ve memorized the entire internet.",
        "clean_text": "It’s something that you’ve probably not encountered before, even if you’ve memorized the entire internet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "That’s what makes ARC challenging for LLMs.",
        "clean_text": "That’s what makes ARC challenging for LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "So far, LLMs have not been doing very well on it.",
        "clean_text": "So far, LLMs have not been doing very well on it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "In fact, the approaches that are working well are more towards [discrete program search](https://slideslive.com/38935790/abstraction-reasoning-in-ai-systems-modern-perspectives), [program synthesis](https://en.wikipedia.org/wiki/Program_synthesis).",
        "clean_text": "In fact, the approaches that are working well are more towards discrete program search, program synthesis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 2,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:01:42",
    "content": "First of all, I’ll make a comment that I’m glad that as a skeptic of LLM, you have yourself put out a benchmark. Is it accurate to say that if the biggest model we have in a year is able to get 80% on this, then your view would be that we are on track to get AGI with LLMs? How would you think about that?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nFirst of all, I’ll make a comment that I’m glad that as a skeptic of LLM, you have yourself put out a benchmark.",
        "clean_text": "First of all, I’ll make a comment that I’m glad that as a skeptic of LLM, you have yourself put out a benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Is it accurate to say that if the biggest model we have in a year is able to get 80% on this, then your view would be that we are on track to get [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) with LLMs?",
        "clean_text": "Is it accurate to say that if the biggest model we have in a year is able to get 80% on this, then your view would be that we are on track to get AGI with LLMs?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "How would you think about that?",
        "clean_text": "How would you think about that?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 3,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:02:02",
    "content": "I’m pretty skeptical that we’re going to see an LLM do 80% in a year. That said, if we do see it, you would also have to look at how this was achieved. If you just train the model on millions or billions of puzzles similar to ARC, you’re relying on the ability to have some overlap between the tasks that you train on and the tasks that you’re going to see at test time. You’re still using memorization. Maybe it can work. Hopefully, ARC is going to be good enough that it’s going to be resistant to this sort of brute force attempt but you never know. Maybe it could happen. I’m not saying it’s not going to happen. ARC is not a perfect benchmark. Maybe it has flaws. Maybe it could be hacked in that way.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI’m pretty skeptical that we’re going to see an LLM do 80% in a year.",
        "clean_text": "I’m pretty skeptical that we’re going to see an LLM do 80% in a year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "That said, if we do see it, you would also have to look at how this was achieved.",
        "clean_text": "That said, if we do see it, you would also have to look at how this was achieved.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If you just train the model on millions or billions of puzzles similar to ARC, you’re relying on the ability to have some overlap between the tasks that you train on and the tasks that you’re going to see at test time.",
        "clean_text": "If you just train the model on millions or billions of puzzles similar to ARC, you’re relying on the ability to have some overlap between the tasks that you train on and the tasks that you’re going to see at test time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You’re still using memorization.",
        "clean_text": "You’re still using memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Maybe it can work.",
        "clean_text": "Maybe it can work.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Hopefully, ARC is going to be good enough that it’s going to be resistant to this sort of brute force attempt but you never know.",
        "clean_text": "Hopefully, ARC is going to be good enough that it’s going to be resistant to this sort of brute force attempt but you never know.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Maybe it could happen.",
        "clean_text": "Maybe it could happen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "I’m not saying it’s not going to happen.",
        "clean_text": "I’m not saying it’s not going to happen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "ARC is not a perfect benchmark.",
        "clean_text": "ARC is not a perfect benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Maybe it has flaws.",
        "clean_text": "Maybe it has flaws.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Maybe it could be hacked in that way.",
        "clean_text": "Maybe it could be hacked in that way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 4,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:02:50",
    "content": "What would GPT-5 have to do so that you would be very confident that it’s on the path to AGI?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat would GPT-5 have to do so that you would be very confident that it’s on the path to AGI?",
        "clean_text": "What would GPT-5 have to do so that you would be very confident that it’s on the path to AGI?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 5,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:02:59",
    "content": "This is what would make me change my mind about LLMs. I would need to start seeing a critical mass of cases where you show the model something it has not seen before — a task that's truly novel from the perspective of its training data — and it can actually adapt on the fly. This is true for LLMs but really this would catch my attention for any AI technique out there. If I can see the ability to adapt to novelty on the fly and pick up new skills efficiently, then I would be extremely interested. I would think this is on the path to AGI.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThis is what would make me change my mind about LLMs.",
        "clean_text": "This is what would make me change my mind about LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I would need to start seeing a critical mass of cases where you show the model something it has not seen before — a task that's truly novel from the perspective of its training data — and it can actually adapt on the fly.",
        "clean_text": "I would need to start seeing a critical mass of cases where you show the model something it has not seen before — a task that's truly novel from the perspective of its training data — and it can actually adapt on the fly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This is true for LLMs but really this would catch my attention for any AI technique out there.",
        "clean_text": "This is true for LLMs but really this would catch my attention for any AI technique out there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If I can see the ability to adapt to novelty on the fly and pick up new skills efficiently, then I would be extremely interested.",
        "clean_text": "If I can see the ability to adapt to novelty on the fly and pick up new skills efficiently, then I would be extremely interested.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I would think this is on the path to AGI.",
        "clean_text": "I would think this is on the path to AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 6,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:03:39",
    "content": "The advantage they have is that they do get to see everything. Maybe I'll take issue with how much they are relying on that, but obviously they're relying on that more than humans do. They do have so much in distribution, to the extent that we have trouble distinguishing whether an example is in distribution or not. If they have everything in distribution, then they can do everything that we can do. Maybe it's not in distribution for us. Why is it so crucial that it has to be out of distribution for them? Why can't we just leverage the fact that they do get to see everything?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThe advantage they have is that they do get to see everything.",
        "clean_text": "The advantage they have is that they do get to see everything.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Maybe I'll take issue with how much they are relying on that, but obviously they're relying on that more than humans do.",
        "clean_text": "Maybe I'll take issue with how much they are relying on that, but obviously they're relying on that more than humans do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They do have so much in distribution, to the extent that we have trouble distinguishing whether an example is in distribution or not.",
        "clean_text": "They do have so much in distribution, to the extent that we have trouble distinguishing whether an example is in distribution or not.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If they have everything in distribution, then they can do everything that we can do.",
        "clean_text": "If they have everything in distribution, then they can do everything that we can do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Maybe it's not in distribution for us.",
        "clean_text": "Maybe it's not in distribution for us.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Why is it so crucial that it has to be out of distribution for them?",
        "clean_text": "Why is it so crucial that it has to be out of distribution for them?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Why can't we just leverage the fact that they do get to see everything?",
        "clean_text": "Why can't we just leverage the fact that they do get to see everything?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 7,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:04:12",
    "content": "Basically you’re asking what's the difference between actual intelligence — the ability to adapt to things you've not been prepared for — and pure memorization, like reciting what you've seen before. It's not just some semantic difference. The big difference is that you can never pre-train on everything that you might see at test time because the world changes all the time. It's not just the fact that the space of possible tasks is infinite. If you're trained on millions of them, you've only seen zero percent of the total space. It's also the fact that the world is changing every day. This is why we, the human species, have developed intelligence in the first place. If there was such a thing as a distribution for the world — for the universe, for our lives — then we would not need intelligence at all. In fact, many creatures, many insects for instance, do not have intelligence. Instead they have hardcoded programs in their connectomes, in their genes, behavioral programs that map some stimuli to appropriate responses. They can actually navigate their lives and their environment in a way that's very evolutionarily fit without needing to learn anything. If our environment were static and predictable enough, what would have happened is that evolution would have found the perfect behavioral program: a hard-coded, static behavioral program. It would have written it into our genes. We would have a hard-coded brain connectome. That's what we would be running on. But that's not what happened. Instead, we have general intelligence. We are born with extremely little knowledge about the world. We are born with the ability to learn very efficiently and to adapt in the face of things that we've never seen before. That's what makes us unique. That's what is really, really challenging to recreate in machines.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBasically you’re asking what's the difference between actual intelligence — the ability to adapt to things you've not been prepared for — and pure memorization, like reciting what you've seen before.",
        "clean_text": "Basically you’re asking what's the difference between actual intelligence — the ability to adapt to things you've not been prepared for — and pure memorization, like reciting what you've seen before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It's not just some semantic difference.",
        "clean_text": "It's not just some semantic difference.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The big difference is that you can never [pre-train](https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/) on everything that you might see at test time because the world changes all the time.",
        "clean_text": "The big difference is that you can never pre-train on everything that you might see at test time because the world changes all the time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's not just the fact that the space of possible tasks is infinite.",
        "clean_text": "It's not just the fact that the space of possible tasks is infinite.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "If you're trained on millions of them, you've only seen zero percent of the total space.",
        "clean_text": "If you're trained on millions of them, you've only seen zero percent of the total space.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "It's also the fact that the world is changing every day.",
        "clean_text": "It's also the fact that the world is changing every day.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "This is why we, the human species, have [developed intelligence](https://en.wikipedia.org/wiki/Evolution_of_human_intelligence#:~:text=In%20fact%2C%20humans%20have%20shown,the%20social%20environment%20around%20us.)",
        "clean_text": "This is why we, the human species, have developed intelligence",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "in the first place.",
        "clean_text": "in the first place.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "If there was such a thing as a distribution for the world — for the universe, for our lives — then we would not need intelligence at all.",
        "clean_text": "If there was such a thing as a distribution for the world — for the universe, for our lives — then we would not need intelligence at all.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "In fact, many creatures, many insects for instance, do not have intelligence.",
        "clean_text": "In fact, many creatures, many insects for instance, do not have intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Instead they have hardcoded programs in their [connectomes](https://en.wikipedia.org/wiki/Connectome), in their genes, behavioral programs that map some stimuli to appropriate responses.",
        "clean_text": "Instead they have hardcoded programs in their connectomes, in their genes, behavioral programs that map some stimuli to appropriate responses.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "They can actually navigate their lives and their environment in a way that's very evolutionarily fit without needing to learn anything.",
        "clean_text": "They can actually navigate their lives and their environment in a way that's very evolutionarily fit without needing to learn anything.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "If our environment were static and predictable enough, what would have happened is that evolution would have found the perfect behavioral program: a hard-coded, static behavioral program.",
        "clean_text": "If our environment were static and predictable enough, what would have happened is that evolution would have found the perfect behavioral program: a hard-coded, static behavioral program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "It would have written it into our genes.",
        "clean_text": "It would have written it into our genes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "We would have a hard-coded brain connectome.",
        "clean_text": "We would have a hard-coded brain connectome.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "That's what we would be running on.",
        "clean_text": "That's what we would be running on.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "But that's not what happened.",
        "clean_text": "But that's not what happened.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "Instead, we have general intelligence.",
        "clean_text": "Instead, we have general intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "We are born with extremely little knowledge about the world.",
        "clean_text": "We are born with extremely little knowledge about the world.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "We are born with the ability to learn very efficiently and to adapt in the face of things that we've never seen before.",
        "clean_text": "We are born with the ability to learn very efficiently and to adapt in the face of things that we've never seen before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "That's what makes us unique.",
        "clean_text": "That's what makes us unique.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "That's what is really, really challenging to recreate in machines.",
        "clean_text": "That's what is really, really challenging to recreate in machines.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 8,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:06:12",
    "content": "Before we dive deeper into that, I'm going to overlay some examples of what an ARC-like challenge looks like for the YouTube audience. For people listening on audio, can you describe what a sample ARC challenge would look like?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBefore we dive deeper into that, I'm going to overlay some examples of what an ARC-like challenge looks like for the YouTube audience.",
        "clean_text": "Before we dive deeper into that, I'm going to overlay some examples of what an ARC-like challenge looks like for the YouTube audience.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "For people listening on audio, can you describe what a sample ARC challenge would look like?",
        "clean_text": "For people listening on audio, can you describe what a sample ARC challenge would look like?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 9,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:06:27",
    "content": "One ARC puzzle looks kind of like an IQ test puzzle. You have a number of demonstration input-output pairs. One pair is made up of two grids. One grid shows you an input, and the second grid shows you what you should produce as a response to that input. You get a couple pairs like this to demonstrate the nature of the task and what you're supposed to do with your inputs. You then get a new test input. Your job is to produce the corresponding test output. You look at the demonstration pairs and from that you figure out what you're supposed to do. You show that you've understood it on this new test pair. Importantly, the knowledge basis you need to approach these challenges is just core knowledge. It includes basic concepts like what makes an object, counting, geometry, topology, symmetries, etc. It's extremely basic knowledge. LLMs for sure possess such knowledge. Any child possesses such knowledge. What's really interesting is that each puzzle is new. It's not something you'll find elsewhere on the internet. Whether you're a human or a machine, you have to approach every puzzle from scratch and reason your way through it. You can't just fetch the response from memory.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\n[One ARC puzzle](https://lab42.global/wp-content/uploads/2022/10/ARC-Explanation2.svg) looks kind of like an IQ test puzzle.",
        "clean_text": "One ARC puzzle looks kind of like an IQ test puzzle.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You have a number of demonstration input-output pairs.",
        "clean_text": "You have a number of demonstration input-output pairs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One pair is made up of two grids.",
        "clean_text": "One pair is made up of two grids.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "One grid shows you an input, and the second grid shows you what you should produce as a response to that input.",
        "clean_text": "One grid shows you an input, and the second grid shows you what you should produce as a response to that input.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You get a couple pairs like this to demonstrate the nature of the task and what you're supposed to do with your inputs.",
        "clean_text": "You get a couple pairs like this to demonstrate the nature of the task and what you're supposed to do with your inputs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "You then get a new test input.",
        "clean_text": "You then get a new test input.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Your job is to produce the corresponding test output.",
        "clean_text": "Your job is to produce the corresponding test output.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You look at the demonstration pairs and from that you figure out what you're supposed to do.",
        "clean_text": "You look at the demonstration pairs and from that you figure out what you're supposed to do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You show that you've understood it on this new test pair.",
        "clean_text": "You show that you've understood it on this new test pair.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Importantly, the knowledge basis you need to approach these challenges is just core knowledge.",
        "clean_text": "Importantly, the knowledge basis you need to approach these challenges is just core knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "It includes basic concepts like what makes an object, counting, geometry, topology, symmetries, etc.",
        "clean_text": "It includes basic concepts like what makes an object, counting, geometry, topology, symmetries, etc.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "It's extremely basic knowledge.",
        "clean_text": "It's extremely basic knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "LLMs for sure possess such knowledge.",
        "clean_text": "LLMs for sure possess such knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Any child possesses such knowledge.",
        "clean_text": "Any child possesses such knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "What's really interesting is that each puzzle is new.",
        "clean_text": "What's really interesting is that each puzzle is new.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "It's not something you'll find elsewhere on the internet.",
        "clean_text": "It's not something you'll find elsewhere on the internet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "Whether you're a human or a machine, you have to approach every puzzle from scratch and reason your way through it.",
        "clean_text": "Whether you're a human or a machine, you have to approach every puzzle from scratch and reason your way through it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "You can't just fetch the response from memory.",
        "clean_text": "You can't just fetch the response from memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 10,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:08:04",
    "content": "One contention here is that we are only now getting multimodal models that are trained to do spatial reasoning due to the data they're trained on. Whereas not only humans but our ancestors have had to learn over billions of years of evolution how to understand abstract physical and spatial properties and recognize patterns there. One view is that in the next year, as we gain models that are natively multimodal capability rather than as an add-on, they will understand these kinds of patterns because that's something we 'd see natively. Right now, ARC sees a JSON string of 100100 and is supposed to recognize a pattern there. Even if you showed a human a sequence of these numbers, they would have a challenge making sense of the question you're asking. Why wouldn't multimodal models, which we're on the path to unlocking right now, be so much better at ARC-type spatial reasoning as soon as we get them?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOne contention here is that we are only now getting [multimodal models](https://en.wikipedia.org/wiki/Multimodal_learning) that are trained to do [spatial reasoning](https://en.wikipedia.org/wiki/Spatial_ability) due to the data they're trained on.",
        "clean_text": "One contention here is that we are only now getting multimodal models that are trained to do spatial reasoning due to the data they're trained on.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Whereas not only humans but our ancestors have had to learn over billions of years of evolution how to understand abstract physical and spatial properties and recognize patterns there.",
        "clean_text": "Whereas not only humans but our ancestors have had to learn over billions of years of evolution how to understand abstract physical and spatial properties and recognize patterns there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One view is that in the next year, as we gain models that are natively multimodal capability rather than as an add-on, they will understand these kinds of patterns because that's something we 'd see natively.",
        "clean_text": "One view is that in the next year, as we gain models that are natively multimodal capability rather than as an add-on, they will understand these kinds of patterns because that's something we 'd see natively.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Right now, ARC sees a [JSON](https://en.wikipedia.org/wiki/JSON) string of 100100 and is supposed to recognize a pattern there.",
        "clean_text": "Right now, ARC sees a JSON string of 100100 and is supposed to recognize a pattern there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Even if you showed a human a sequence of these numbers, they would have a challenge making sense of the question you're asking.",
        "clean_text": "Even if you showed a human a sequence of these numbers, they would have a challenge making sense of the question you're asking.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Why wouldn't multimodal models, which we're on the path to unlocking right now, be so much better at ARC-type spatial reasoning as soon as we get them?",
        "clean_text": "Why wouldn't multimodal models, which we're on the path to unlocking right now, be so much better at ARC-type spatial reasoning as soon as we get them?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 11,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:09:09",
    "content": "That's an empirical question. I guess we'll see the answer within a few months. My response is that our grids are just discrete 2D grids of symbols and are pretty small. If you flatten an image as a sequence of pixels for example, you get something that’s actually very difficult to parse. That’s not true for ARC because the grids are very small. You only have 10 possible symbols, They are 2D grids that are actually very easy to flatten as sequences. Transformers), LLMs, are very good at processing sequences. In fact, you can show that LLMs do fine with processing ARC-like data by simply fine-tuning) an LLM on subsets of the tasks and then testing it on small variations of these tasks. You'll see that the LLM can encode solution programs just fine for tasks it has seen before. It doesn't really have a problem parsing the input or figuring out the program. The reason LLMs don't do well on ARC is really just the unfamiliarity aspect. Each new task is different from every other task. You cannot memorize the solution programs in advance. You have to synthesize a new solution program on the fly for each new task. That's really what LLMs are struggling with.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's an empirical question.",
        "clean_text": "That's an empirical question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I guess we'll see the answer within a few months.",
        "clean_text": "I guess we'll see the answer within a few months.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "My response is that our grids are just discrete 2D grids of symbols and are pretty small.",
        "clean_text": "My response is that our grids are just discrete 2D grids of symbols and are pretty small.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If you flatten an image as a sequence of pixels for example, you get something that’s actually very difficult to parse.",
        "clean_text": "If you flatten an image as a sequence of pixels for example, you get something that’s actually very difficult to parse.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "That’s not true for ARC because the grids are very small.",
        "clean_text": "That’s not true for ARC because the grids are very small.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "You only have 10 possible symbols, They are 2D grids that are actually very easy to flatten as sequences.",
        "clean_text": "You only have 10 possible symbols, They are 2D grids that are actually very easy to flatten as sequences.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "[Transformers](https://en.wikipedia.org/wiki/Transformer_/(deep_learning_architecture/)), LLMs, are very good at processing sequences.",
        "clean_text": "Transformers), LLMs, are very good at processing sequences.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "In fact, you can show that LLMs do fine with processing ARC-like data by simply [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_/(deep_learning/)) an LLM on subsets of the tasks and then testing it on small variations of these tasks.",
        "clean_text": "In fact, you can show that LLMs do fine with processing ARC-like data by simply fine-tuning) an LLM on subsets of the tasks and then testing it on small variations of these tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You'll see that the LLM can encode solution programs just fine for tasks it has seen before.",
        "clean_text": "You'll see that the LLM can encode solution programs just fine for tasks it has seen before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It doesn't really have a problem parsing the input or figuring out the program.",
        "clean_text": "It doesn't really have a problem parsing the input or figuring out the program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "The reason LLMs don't do well on ARC is really just the unfamiliarity aspect.",
        "clean_text": "The reason LLMs don't do well on ARC is really just the unfamiliarity aspect.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "Each new task is different from every other task.",
        "clean_text": "Each new task is different from every other task.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "You cannot memorize the solution programs in advance.",
        "clean_text": "You cannot memorize the solution programs in advance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "You have to synthesize a new solution program on the fly for each new task.",
        "clean_text": "You have to synthesize a new solution program on the fly for each new task.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "That's really what LLMs are struggling with.",
        "clean_text": "That's really what LLMs are struggling with.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 12,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:10:37",
    "content": "Before I play more devil's advocate, I just want to step back and explain why I'm especially interested in having this conversation. Obviously there’s the million dollar ARC Prize and I’m excited to play around with it myself. The Vesuvius Challenge was Nat Friedman's prize for decoding scrolls from the Herculaneum library that were buried in the volcano. The winner of that was a 22-year-old who was listening to this podcast, Luke Farritor. Hopefully somebody listening to this will find this challenge intriguing and find a solution.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBefore I play more [devil's advocate](https://en.wikipedia.org/wiki/Devil%27s_advocate), I just want to step back and explain why I'm especially interested in having this conversation.",
        "clean_text": "Before I play more devil's advocate, I just want to step back and explain why I'm especially interested in having this conversation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Obviously there’s the million dollar ARC Prize and I’m excited to play around with it myself.",
        "clean_text": "Obviously there’s the million dollar ARC Prize and I’m excited to play around with it myself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The [Vesuvius Challenge](https://scrollprize.org/) was [Nat Friedman](https://www.dwarkeshpatel.com/p/nat-friedman)'s prize for decoding scrolls from the [Herculaneum library](https://en.wikipedia.org/wiki/Herculaneum_papyri) that were buried in the volcano.",
        "clean_text": "The Vesuvius Challenge was Nat Friedman's prize for decoding scrolls from the Herculaneum library that were buried in the volcano.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "The [winner](https://scrollprize.org/firstletters) of that was a 22-year-old who was listening to this podcast, [Luke Farritor](https://lukefarritor.com/about/).",
        "clean_text": "The winner of that was a 22-year-old who was listening to this podcast, Luke Farritor.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Hopefully somebody listening to this will find this challenge intriguing and find a solution.",
        "clean_text": "Hopefully somebody listening to this will find this challenge intriguing and find a solution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 13,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:11:10",
    "content": "I've recently had on a lot of people who are bullish on LLMs. I've had discussions with them before interviewing you about how we explain the fact that LLMs don't seem to be natively performing that well on ARC. I found their explanations somewhat contrived. I'll try out some of their reasons on you. It is actually an intriguing fact that some of these problems are relatively straightforward for humans to understand, yet the models struggle with them if you just input them natively.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI've recently had on a lot of people who are bullish on LLMs.",
        "clean_text": "I've recently had on a lot of people who are bullish on LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I've had discussions with them before interviewing you about how we explain the fact that LLMs don't seem to be natively performing that well on ARC.",
        "clean_text": "I've had discussions with them before interviewing you about how we explain the fact that LLMs don't seem to be natively performing that well on ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I found their explanations somewhat contrived.",
        "clean_text": "I found their explanations somewhat contrived.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I'll try out some of their reasons on you.",
        "clean_text": "I'll try out some of their reasons on you.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It is actually an intriguing fact that some of these problems are relatively straightforward for humans to understand, yet the models struggle with them if you just input them natively.",
        "clean_text": "It is actually an intriguing fact that some of these problems are relatively straightforward for humans to understand, yet the models struggle with them if you just input them natively.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 14,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:11:42",
    "content": "All of them are very easy for humans. Any smart human should be able to do 90-95% on ARC. Even a five-year-old with very, very little knowledge could definitely do over 50%.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAll of them are very easy for humans.",
        "clean_text": "All of them are very easy for humans.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Any smart human should be able to do 90-95% on ARC.",
        "clean_text": "Any smart human should be able to do 90-95% on ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Even a five-year-old with very, very little knowledge could definitely do over 50%.",
        "clean_text": "Even a five-year-old with very, very little knowledge could definitely do over 50%.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 15,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:11:57",
    "content": "I agree that smart humans will do very well on this test, but the average human will probably be mediocre.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI agree that smart humans will do very well on this test, but the average human will probably be mediocre.",
        "clean_text": "I agree that smart humans will do very well on this test, but the average human will probably be mediocre.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 16,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:12:10",
    "content": "Not really, we actually tried with average humans. They scored about 85.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNot really, we actually tried with average humans.",
        "clean_text": "Not really, we actually tried with average humans.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They scored about 85.",
        "clean_text": "They scored about 85.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 17,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:12:14",
    "content": "That was with Amazon Mechanical Turk workers, right? I honestly don't know the demographic profile of Amazon Mechanical Turk workers. Imagining them interacting with Amazon's remote work platform, I’m guessing that's not the median human across the planet. The broader point here is that we see the spectrum in humans and humans obviously have AGI. But even within humans you see a spectrum where some people are relatively dumber. They'll perform worse on IQ-like tests. For example, there’s Raven's Progressive Matrices. Look at how the average person performs on that. If you look at the kind of questions that are hit or miss — half of people will get it right, half of people will get it wrong — we might think they’re kind of trivial. Humans have AGI but from relatively small tweaks, you can go from somebody who misses these kinds of basic IQ test questions to somebody who gets them all right. We'll talk about some of the previous performances that people have tried with these models. Jack Cole with a 240 million parameter model got 35%. Doesn't that suggest that they're on this spectrum that clearly exists within humans, and they're going to be saturated pretty soon?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat was with [Amazon Mechanical Turk](https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk) workers, right?",
        "clean_text": "That was with Amazon Mechanical Turk workers, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I honestly don't know the demographic profile of Amazon Mechanical Turk workers.",
        "clean_text": "I honestly don't know the demographic profile of Amazon Mechanical Turk workers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Imagining them interacting with Amazon's remote work platform, I’m guessing that's not the median human across the planet.",
        "clean_text": "Imagining them interacting with Amazon's remote work platform, I’m guessing that's not the median human across the planet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "The broader point here is that we see the spectrum in humans and humans obviously have AGI.",
        "clean_text": "The broader point here is that we see the spectrum in humans and humans obviously have AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "But even within humans you see a spectrum where some people are relatively dumber.",
        "clean_text": "But even within humans you see a spectrum where some people are relatively dumber.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "They'll perform worse on IQ-like tests.",
        "clean_text": "They'll perform worse on IQ-like tests.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "For example, there’s [Raven's Progressive Matrices](https://en.wikipedia.org/wiki/Raven%27s_Progressive_Matrices).",
        "clean_text": "For example, there’s Raven's Progressive Matrices.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Look at how the average person performs on that.",
        "clean_text": "Look at how the average person performs on that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "If you look at the kind of questions that are hit or miss — half of people will get it right, half of people will get it wrong — we might think they’re kind of trivial.",
        "clean_text": "If you look at the kind of questions that are hit or miss — half of people will get it right, half of people will get it wrong — we might think they’re kind of trivial.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Humans have AGI but from relatively small tweaks, you can go from somebody who misses these kinds of basic IQ test questions to somebody who gets them all right.",
        "clean_text": "Humans have AGI but from relatively small tweaks, you can go from somebody who misses these kinds of basic IQ test questions to somebody who gets them all right.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "We'll talk about some of the previous performances that people have tried with these models.",
        "clean_text": "We'll talk about some of the previous performances that people have tried with these models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "[Jack Cole](https://x.com/Jcole75Cole) with a 240 million [parameter](https://www.techopedia.com/experts/what-is-the-role-of-parameters-in-ai) model got 35%.",
        "clean_text": "Jack Cole with a 240 million parameter model got 35%.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Doesn't that suggest that they're on this spectrum that clearly exists within humans, and they're going to be saturated pretty soon?",
        "clean_text": "Doesn't that suggest that they're on this spectrum that clearly exists within humans, and they're going to be saturated pretty soon?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 18,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:13:25",
    "content": "There's a bunch of interesting points here. There is indeed a branch of LLM approaches spearheaded by Jack Cole that are doing quite well. They are state-of-the art in fact.. But you have to look at what's going on there. There are two things. The first thing is that to get these numbers, you need to pre-train your LLM on millions of generated ARC tasks. Of course, compare that to a five-year-old child looking at ARC for the first time. The child has never done an IQ test before and has never seen something like an ARC test before. The only overlap between what they know and what they have to do in the test is core knowledge. It’s knowing about counting, objects, symmetries, etc. They're still going to do really well. They're going to do much better than the LLM trained on millions of similar tasks. There’s a second thing to note about the Jack Cole approach. One thing that's really critical to making the model work at all is test time fine-tuning. By the way, that's something that's really missing from LLM approaches right now. Most of the time when you're using an LLM, it's just doing static inference. The model is frozen. You're just prompting it and getting an answer. The model is not actually learning anything on the fly. Its state is not adapting to the task at hand. What Jack Cole is actually doing is that for every test problem, it’s on-the-fly fine-tuning a version of the LLM for that task. That's really what's unlocking performance. If you don't do that, you get like 1-2%, something completely negligible. If you do test time fine-tuning and you add a bunch of tricks on top, then you end up with interesting performance numbers. What it's doing is trying to address one of the key limitations of LLMs today: the lack of active inference. It's actually adding active inference to LLMs. That's working extremely well, actually. So that's fascinating to me.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere's a bunch of interesting points here.",
        "clean_text": "There's a bunch of interesting points here.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There is indeed a branch of LLM approaches spearheaded by Jack Cole that are doing quite well.",
        "clean_text": "There is indeed a branch of LLM approaches spearheaded by Jack Cole that are doing quite well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They are state-of-the art in fact.. But you have to look at what's going on there.",
        "clean_text": "They are state-of-the art in fact.. But you have to look at what's going on there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There are two things.",
        "clean_text": "There are two things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "The first thing is that to get these numbers, you need to pre-train your LLM on millions of generated ARC tasks.",
        "clean_text": "The first thing is that to get these numbers, you need to pre-train your LLM on millions of generated ARC tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Of course, compare that to a five-year-old child looking at ARC for the first time.",
        "clean_text": "Of course, compare that to a five-year-old child looking at ARC for the first time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The child has never done an IQ test before and has never seen something like an ARC test before.",
        "clean_text": "The child has never done an IQ test before and has never seen something like an ARC test before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "The only overlap between what they know and what they have to do in the test is core knowledge.",
        "clean_text": "The only overlap between what they know and what they have to do in the test is core knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It’s knowing about counting, objects, symmetries, etc.",
        "clean_text": "It’s knowing about counting, objects, symmetries, etc.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "They're still going to do really well.",
        "clean_text": "They're still going to do really well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "They're going to do much better than the LLM trained on millions of similar tasks.",
        "clean_text": "They're going to do much better than the LLM trained on millions of similar tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "There’s a second thing to note about the Jack Cole approach.",
        "clean_text": "There’s a second thing to note about the Jack Cole approach.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "One thing that's really critical to making the model work at all is test time fine-tuning.",
        "clean_text": "One thing that's really critical to making the model work at all is test time fine-tuning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "By the way, that's something that's really missing from LLM approaches right now.",
        "clean_text": "By the way, that's something that's really missing from LLM approaches right now.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "Most of the time when you're using an LLM, it's just doing static [inference](https://hazelcast.com/glossary/machine-learning-inference/).",
        "clean_text": "Most of the time when you're using an LLM, it's just doing static inference.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "The model is frozen.",
        "clean_text": "The model is frozen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "You're just prompting it and getting an answer.",
        "clean_text": "You're just prompting it and getting an answer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "The model is not actually learning anything on the fly.",
        "clean_text": "The model is not actually learning anything on the fly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "Its state is not adapting to the task at hand.",
        "clean_text": "Its state is not adapting to the task at hand.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "What Jack Cole is actually doing is that for every test problem, it’s on-the-fly fine-tuning a version of the LLM for that task.",
        "clean_text": "What Jack Cole is actually doing is that for every test problem, it’s on-the-fly fine-tuning a version of the LLM for that task.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "That's really what's unlocking performance.",
        "clean_text": "That's really what's unlocking performance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "If you don't do that, you get like 1-2%, something completely negligible.",
        "clean_text": "If you don't do that, you get like 1-2%, something completely negligible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "If you do test time fine-tuning and you add a bunch of tricks on top, then you end up with interesting performance numbers.",
        "clean_text": "If you do test time fine-tuning and you add a bunch of tricks on top, then you end up with interesting performance numbers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "What it's doing is trying to address one of the key limitations of LLMs today: the lack of active inference.",
        "clean_text": "What it's doing is trying to address one of the key limitations of LLMs today: the lack of active inference.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "It's actually adding active inference to LLMs.",
        "clean_text": "It's actually adding active inference to LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "That's working extremely well, actually.",
        "clean_text": "That's working extremely well, actually.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "So that's fascinating to me.",
        "clean_text": "So that's fascinating to me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 19,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:15:30",
    "content": "There are so many interesting rabbit holes there. A lot of the scale maximalists share your broader perspective that you need to unlock the adaptive/test time compute. They think that in addition to scaling, you need things like adaptive compute or some sort of RL to get the System 2 working. Their perspective is that this is a relatively straightforward thing that will be added atop the representations that a scaled up model has greater access to.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere are so many interesting rabbit holes there.",
        "clean_text": "There are so many interesting rabbit holes there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "A lot of the scale maximalists share your broader perspective that you need to unlock the adaptive/test time compute.",
        "clean_text": "A lot of the scale maximalists share your broader perspective that you need to unlock the adaptive/test time compute.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They think that in addition to scaling, you need things like adaptive compute or some sort of [RL](https://en.wikipedia.org/wiki/Reinforcement_learning) to get the [System 2](https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking) working.",
        "clean_text": "They think that in addition to scaling, you need things like adaptive compute or some sort of RL to get the System 2 working.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Their perspective is that this is a relatively straightforward thing that will be added atop the representations that a scaled up model has greater access to.",
        "clean_text": "Their perspective is that this is a relatively straightforward thing that will be added atop the representations that a scaled up model has greater access to.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 20,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:16:14",
    "content": "It's not just a technical detail. It's not a straightforward thing. It is everything. It is the important part. The scale maximalists refer to scaling laws, which are the empirical relationship that you can draw between how much compute you spend on training a model and the performance you're getting on benchmark. Of course the key question here is, how do you measure performance? What is it that you're actually improving by adding more compute and more data? It's benchmark performance. The way you measure performance is not a technical detail. It's not an afterthought because it's going to narrow down the set of questions that you're asking. Accordingly, it's going to narrow down the set of answers that you're looking for. If you look at the benchmarks we are using for LLMs, they are all memorization-based benchmarks. Sometimes they are literally just knowledge-based, like a school test. Even if you look at the ones that are explicitly about reasoning, if you look closely you realize that in order to solve them, it's enough to memorize a finite set of reasoning patterns. You just reapply them. They're like static programs. LLMs are very good at memorizing small static programs. They've got this sort of bank of solution programs. When you give them a new puzzle, they can just fetch the appropriate program and apply it. It looks like reasoning but it's not really doing any sort of on-the-fly program synthesis. All it's doing is program fetching. You can actually solve all these benchmarks with memorization. If you look at the models and what you're scaling up here, they are big parametric curves fitted to a data distribution. They're basically these big interpolative databases, interpolative memories. Of course, if you scale up the size of your database and cram more knowledge and patterns into it, you are going to be increasing its performance as measured by a memorization benchmark. That's kind of obvious. But as you're doing it, you are not increasing the intelligence of the system one bit. You are increasing the skill of the system. You are increasing its usefulness, its scope of applicability, but not its intelligence because skill is not intelligence. That's the fundamental confusion that people run into. They're confusing skill and intelligence.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's not just a technical detail.",
        "clean_text": "It's not just a technical detail.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It's not a straightforward thing.",
        "clean_text": "It's not a straightforward thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It is everything.",
        "clean_text": "It is everything.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It is the important part.",
        "clean_text": "It is the important part.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "The scale maximalists refer to [scaling laws](https://www.dwarkeshpatel.com/p/will-scaling-work), which are the empirical relationship that you can draw between how much compute you spend on training a model and the performance you're getting on benchmark.",
        "clean_text": "The scale maximalists refer to scaling laws, which are the empirical relationship that you can draw between how much compute you spend on training a model and the performance you're getting on benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Of course the key question here is, how do you measure performance?",
        "clean_text": "Of course the key question here is, how do you measure performance?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "What is it that you're actually improving by adding more compute and more data?",
        "clean_text": "What is it that you're actually improving by adding more compute and more data?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It's benchmark performance.",
        "clean_text": "It's benchmark performance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "The way you measure performance is not a technical detail.",
        "clean_text": "The way you measure performance is not a technical detail.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It's not an afterthought because it's going to narrow down the set of questions that you're asking.",
        "clean_text": "It's not an afterthought because it's going to narrow down the set of questions that you're asking.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Accordingly, it's going to narrow down the set of answers that you're looking for.",
        "clean_text": "Accordingly, it's going to narrow down the set of answers that you're looking for.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "If you look at the benchmarks we are using for LLMs, they are all memorization-based benchmarks.",
        "clean_text": "If you look at the benchmarks we are using for LLMs, they are all memorization-based benchmarks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Sometimes they are literally just knowledge-based, like a school test.",
        "clean_text": "Sometimes they are literally just knowledge-based, like a school test.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Even if you look at the ones that are explicitly about reasoning, if you look closely you realize that in order to solve them, it's enough to memorize a finite set of reasoning patterns.",
        "clean_text": "Even if you look at the ones that are explicitly about reasoning, if you look closely you realize that in order to solve them, it's enough to memorize a finite set of reasoning patterns.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "You just reapply them.",
        "clean_text": "You just reapply them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "They're like static programs.",
        "clean_text": "They're like static programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "LLMs are very good at memorizing small static programs.",
        "clean_text": "LLMs are very good at memorizing small static programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "They've got this sort of bank of solution programs.",
        "clean_text": "They've got this sort of bank of solution programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "When you give them a new puzzle, they can just fetch the appropriate program and apply it.",
        "clean_text": "When you give them a new puzzle, they can just fetch the appropriate program and apply it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "It looks like reasoning but it's not really doing any sort of on-the-fly program synthesis.",
        "clean_text": "It looks like reasoning but it's not really doing any sort of on-the-fly program synthesis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "All it's doing is program fetching.",
        "clean_text": "All it's doing is program fetching.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "You can actually solve all these benchmarks with memorization.",
        "clean_text": "You can actually solve all these benchmarks with memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "If you look at the models and what you're scaling up here, they are big parametric curves fitted to a data distribution.",
        "clean_text": "If you look at the models and what you're scaling up here, they are big parametric curves fitted to a data distribution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "They're basically these big interpolative databases, interpolative memories.",
        "clean_text": "They're basically these big interpolative databases, interpolative memories.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "Of course, if you scale up the size of your database and cram more knowledge and patterns into it, you are going to be increasing its performance as measured by a memorization benchmark.",
        "clean_text": "Of course, if you scale up the size of your database and cram more knowledge and patterns into it, you are going to be increasing its performance as measured by a memorization benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "That's kind of obvious.",
        "clean_text": "That's kind of obvious.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "But as you're doing it, you are not increasing the intelligence of the system one bit.",
        "clean_text": "But as you're doing it, you are not increasing the intelligence of the system one bit.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "You are increasing the skill of the system.",
        "clean_text": "You are increasing the skill of the system.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "You are increasing its usefulness, its scope of applicability, but not its intelligence because skill is not intelligence.",
        "clean_text": "You are increasing its usefulness, its scope of applicability, but not its intelligence because skill is not intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "That's the fundamental confusion that people run into.",
        "clean_text": "That's the fundamental confusion that people run into.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 30,
        "original_text": "They're confusing skill and intelligence.",
        "clean_text": "They're confusing skill and intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 21,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:19:00",
    "content": "There are a lot of fascinating things to talk about here: skill, intelligence, interpolation. Let’s talk about the point that they’re fitting some manifold that maps the input data. A reductionist way to talk about the human brain is that it's just axons firing at each other. But we don't care about the reductionist explanation. We care about what happens at the macroscopic level when these things combine. As far as interpolation goes, let's look at one of the benchmarks. There's a benchmark that does grade school math. These are problems that a smart high schooler would be able to solve. It's called GSM8K. These models get 95% on it. Basically, they always nail it.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere are a lot of fascinating things to talk about here: skill, intelligence, interpolation.",
        "clean_text": "There are a lot of fascinating things to talk about here: skill, intelligence, interpolation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Let’s talk about the point that they’re fitting some [manifold](https://en.wikipedia.org/wiki/Manifold_alignment) that maps the input data.",
        "clean_text": "Let’s talk about the point that they’re fitting some manifold that maps the input data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "A reductionist way to talk about the human brain is that it's just axons firing at each other.",
        "clean_text": "A reductionist way to talk about the human brain is that it's just axons firing at each other.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "But we don't care about the reductionist explanation.",
        "clean_text": "But we don't care about the reductionist explanation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "We care about what happens at the macroscopic level when these things combine.",
        "clean_text": "We care about what happens at the macroscopic level when these things combine.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "As far as interpolation goes, let's look at one of the benchmarks.",
        "clean_text": "As far as interpolation goes, let's look at one of the benchmarks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There's a benchmark that does grade school math.",
        "clean_text": "There's a benchmark that does grade school math.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "These are problems that a smart high schooler would be able to solve.",
        "clean_text": "These are problems that a smart high schooler would be able to solve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It's called [GSM8K](https://paperswithcode.com/dataset/gsm8k).",
        "clean_text": "It's called GSM8K.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "These models get 95% on it.",
        "clean_text": "These models get 95% on it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Basically, they always nail it.",
        "clean_text": "Basically, they always nail it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 22,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:19:50",
    "content": "Sure, that's a memorization benchmark.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSure, that's a memorization benchmark.",
        "clean_text": "Sure, that's a memorization benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 23,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:19:51",
    "content": "Let's talk about what that means. Here's one question from that benchmark: \"30 students are in a class. One-fifth of them are 12-year-olds, One-third are 13-year-olds, One-tenth are 11-year-olds. How many of them are not 11, 12, or 13 years old? I agree this is not rocket science. You can write down on paper how you go through this problem. A smart high school kid should be able to solve it. About memorization, it still has to reason through how to think about fractions, the context of the whole problem, and then combine different calculations to write the final answer.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet's talk about what that means.",
        "clean_text": "Let's talk about what that means.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Here's one question from that benchmark:\n\n\"30 students are in a class.",
        "clean_text": "Here's one question from that benchmark: \"30 students are in a class.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One-fifth of them are 12-year-olds, One-third are 13-year-olds, One-tenth are 11-year-olds.",
        "clean_text": "One-fifth of them are 12-year-olds, One-third are 13-year-olds, One-tenth are 11-year-olds.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "How many of them are not 11, 12, or 13 years old?",
        "clean_text": "How many of them are not 11, 12, or 13 years old?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I agree this is not rocket science.",
        "clean_text": "I agree this is not rocket science.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "You can write down on paper how you go through this problem.",
        "clean_text": "You can write down on paper how you go through this problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "A smart high school kid should be able to solve it.",
        "clean_text": "A smart high school kid should be able to solve it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "About memorization, it still has to reason through how to think about fractions, the context of the whole problem, and then combine different calculations to write the final answer.",
        "clean_text": "About memorization, it still has to reason through how to think about fractions, the context of the whole problem, and then combine different calculations to write the final answer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 24,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:20:24",
    "content": "It depends on how you want to define reasoning. There are two definitions you can use. One is, I have available a set of program templates. It’s the structure of the puzzle, which can also generate its solution. I'm going to identify the right template, which is in my memory, input the new values into the template, run the program, and get the solution. You could say this is reasoning. I say, “yeah sure, okay.” Here’s another definition of reasoning. When you're faced with a puzzle and you don't already have a program in memory to solve it, it’s the ability to synthesize on the fly a new program based on bits and pieces of existing programs that you have. You have to do on-the-fly program synthesis. That's actually dramatically harder than just fetching the right memorized program and reapplying it.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt depends on how you want to define reasoning.",
        "clean_text": "It depends on how you want to define reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There are two definitions you can use.",
        "clean_text": "There are two definitions you can use.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One is, I have available a set of program templates.",
        "clean_text": "One is, I have available a set of program templates.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It’s the structure of the puzzle, which can also generate its solution.",
        "clean_text": "It’s the structure of the puzzle, which can also generate its solution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I'm going to identify the right template, which is in my memory, input the new values into the template, run the program, and get the solution.",
        "clean_text": "I'm going to identify the right template, which is in my memory, input the new values into the template, run the program, and get the solution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "You could say this is reasoning.",
        "clean_text": "You could say this is reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I say, “yeah sure, okay.”\n\nHere’s another definition of reasoning.",
        "clean_text": "I say, “yeah sure, okay.” Here’s another definition of reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "When you're faced with a puzzle and you don't already have a program in memory to solve it, it’s the ability to synthesize on the fly a new program based on bits and pieces of existing programs that you have.",
        "clean_text": "When you're faced with a puzzle and you don't already have a program in memory to solve it, it’s the ability to synthesize on the fly a new program based on bits and pieces of existing programs that you have.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You have to do on-the-fly program synthesis.",
        "clean_text": "You have to do on-the-fly program synthesis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "That's actually dramatically harder than just fetching the right memorized program and reapplying it.",
        "clean_text": "That's actually dramatically harder than just fetching the right memorized program and reapplying it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 25,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:21:18",
    "content": "Maybe we are overestimating the extent to which humans are so sample efficient. They also need training in this way. They have to drill in these pathways of reasoning through certain kinds of problems. Let's take math, for example. It's not like you can just show a baby the axioms of set theory and now they know math. When they're growing up, you have to teach them years of pre-algebra. Then you have a year of teaching them drills and going through the same kind of problem in algebra, then geometry, pre-calculus, calculus. Isn't that like the same kind of thing? You can't just see one example and now you have the program. You actually have to drill it. These models also had to drill it with a bunch of pre-training data.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nMaybe we are overestimating the extent to which humans are so [sample efficient](https://ai.stackexchange.com/questions/5246/what-is-sample-efficiency-and-how-can-importance-sampling-be-used-to-achieve-it).",
        "clean_text": "Maybe we are overestimating the extent to which humans are so sample efficient.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They also need training in this way.",
        "clean_text": "They also need training in this way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They have to drill in these pathways of reasoning through certain kinds of problems.",
        "clean_text": "They have to drill in these pathways of reasoning through certain kinds of problems.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Let's take math, for example.",
        "clean_text": "Let's take math, for example.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It's not like you can just show a baby the axioms of [set theory](https://en.wikipedia.org/wiki/Set_theory) and now they know math.",
        "clean_text": "It's not like you can just show a baby the axioms of set theory and now they know math.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "When they're growing up, you have to teach them years of pre-algebra.",
        "clean_text": "When they're growing up, you have to teach them years of pre-algebra.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Then you have a year of teaching them drills and going through the same kind of problem in algebra, then geometry, pre-calculus, calculus.",
        "clean_text": "Then you have a year of teaching them drills and going through the same kind of problem in algebra, then geometry, pre-calculus, calculus.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Isn't that like the same kind of thing?",
        "clean_text": "Isn't that like the same kind of thing?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You can't just see one example and now you have the program.",
        "clean_text": "You can't just see one example and now you have the program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You actually have to drill it.",
        "clean_text": "You actually have to drill it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "These models also had to drill it with a bunch of pre-training data.",
        "clean_text": "These models also had to drill it with a bunch of pre-training data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 26,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:22:02",
    "content": "Sure. In order to do on-the-fly program synthesis, you actually need building blocks to work from. Knowledge and memory are tremendously important in the process. I'm not saying it's memory vs. reasoning. In order to do effective reasoning, you need memory.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSure.",
        "clean_text": "Sure.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "In order to do on-the-fly program synthesis, you actually need building blocks to work from.",
        "clean_text": "In order to do on-the-fly program synthesis, you actually need building blocks to work from.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Knowledge and memory are tremendously important in the process.",
        "clean_text": "Knowledge and memory are tremendously important in the process.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I'm not saying it's memory vs.",
        "clean_text": "I'm not saying it's memory vs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "reasoning.",
        "clean_text": "reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "In order to do effective reasoning, you need memory.",
        "clean_text": "In order to do effective reasoning, you need memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 27,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:22:21",
    "content": "But it sounds compatible with your story. Through seeing a lot of different kinds of examples, these things can learn to reason within the context of those examples. We can also see it within bigger and bigger models. That was an example of a high school-level math problem. Let's say a model that's smaller than GPT-3 couldn't do that at all. As these models get bigger, they seem to be able to pick up bigger and bigger patterns.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut it sounds compatible with your story.",
        "clean_text": "But it sounds compatible with your story.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Through seeing a lot of different kinds of examples, these things can learn to reason within the context of those examples.",
        "clean_text": "Through seeing a lot of different kinds of examples, these things can learn to reason within the context of those examples.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We can also see it within bigger and bigger models.",
        "clean_text": "We can also see it within bigger and bigger models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "That was an example of a high school-level math problem.",
        "clean_text": "That was an example of a high school-level math problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Let's say a model that's smaller than [GPT-3](https://en.wikipedia.org/wiki/GPT-3) couldn't do that at all.",
        "clean_text": "Let's say a model that's smaller than GPT-3 couldn't do that at all.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "As these models get bigger, they seem to be able to pick up bigger and bigger patterns.",
        "clean_text": "As these models get bigger, they seem to be able to pick up bigger and bigger patterns.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 28,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:22:43",
    "content": "It's not really a size issue. It's more like a training data issue in this case.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's not really a size issue.",
        "clean_text": "It's not really a size issue.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It's more like a training data issue in this case.",
        "clean_text": "It's more like a training data issue in this case.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 29,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:22:47",
    "content": "Well, bigger models can pick up these kinds of circuits. Smaller models apparently don't do a good job of doing that even if you were to train them on this kind of data. Doesn't that just suggest that as you have bigger and bigger models, they can pick up bigger and bigger pathways or more general ways of reasoning?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWell, bigger models can pick up these kinds of circuits.",
        "clean_text": "Well, bigger models can pick up these kinds of circuits.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Smaller models apparently don't do a good job of doing that even if you were to train them on this kind of data.",
        "clean_text": "Smaller models apparently don't do a good job of doing that even if you were to train them on this kind of data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Doesn't that just suggest that as you have bigger and bigger models, they can pick up bigger and bigger pathways or more general ways of reasoning?",
        "clean_text": "Doesn't that just suggest that as you have bigger and bigger models, they can pick up bigger and bigger pathways or more general ways of reasoning?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 30,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:23:01",
    "content": "Absolutely.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAbsolutely.",
        "clean_text": "Absolutely.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 31,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:23:02",
    "content": "But then isn't that intelligence?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut then isn't that intelligence?",
        "clean_text": "But then isn't that intelligence?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 32,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:23:03",
    "content": "No, it's not. If you scale up your database and keep adding more knowledge and program templates to it, then sure it becomes more and more skillful. You can apply it to more and more tasks. But general intelligence is not task-specific skill scaled up to many skills, because there is an infinite space of possible skills. General intelligence is the ability to approach any problem, any skill, and very quickly master it using very little data. This is what makes you able to face anything you might ever encounter. This is the definition of generality. Generality is not specificity scaled up. It is the ability to apply your mind to anything at all, to arbitrary things. This fundamentally requires the ability to adapt, to learn on the fly efficiently.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNo, it's not.",
        "clean_text": "No, it's not.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you scale up your database and keep adding more knowledge and program templates to it, then sure it becomes more and more skillful.",
        "clean_text": "If you scale up your database and keep adding more knowledge and program templates to it, then sure it becomes more and more skillful.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You can apply it to more and more tasks.",
        "clean_text": "You can apply it to more and more tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "But general intelligence is not task-specific skill scaled up to many skills, because there is an infinite space of possible skills.",
        "clean_text": "But general intelligence is not task-specific skill scaled up to many skills, because there is an infinite space of possible skills.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "General intelligence is the ability to approach any problem, any skill, and very quickly master it using very little data.",
        "clean_text": "General intelligence is the ability to approach any problem, any skill, and very quickly master it using very little data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "This is what makes you able to face anything you might ever encounter.",
        "clean_text": "This is what makes you able to face anything you might ever encounter.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "This is the definition of generality.",
        "clean_text": "This is the definition of generality.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Generality is not specificity scaled up.",
        "clean_text": "Generality is not specificity scaled up.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It is the ability to apply your mind to anything at all, to arbitrary things.",
        "clean_text": "It is the ability to apply your mind to anything at all, to arbitrary things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "This fundamentally requires the ability to adapt, to learn on the fly efficiently.",
        "clean_text": "This fundamentally requires the ability to adapt, to learn on the fly efficiently.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 33,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:23:54",
    "content": "My claim is that by doing pre-training on bigger and bigger models, you are gaining that capacity to generalize very efficiently. Let me give you an example. Your own company Google, in their paper on Gemini 1.5, had this very interesting example. They would give the model, in context%20learns%20a%20new%20task%20from,objective%20of%20next%20token%20prediction. ), the grammar book and the dictionary of a language that has fewer than 200 living speakers. It's not in the pre-training data. You just give it the dictionary and it basically is able to speak this language and translate to it, including the complex and organic ways in which languages are structured. If you showed me a dictionary from English to Spanish, I'm not going to be able to pick up how to structure sentences and how to say things in Spanish. Because of the representations that it has gained through this pre-training, it is able to now learn a new language extremely efficiently. Doesn't that show that this kind of pre-training actually does increase your ability to learn new tasks?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nMy claim is that by doing pre-training on bigger and bigger models, you are gaining that capacity to generalize very efficiently.",
        "clean_text": "My claim is that by doing pre-training on bigger and bigger models, you are gaining that capacity to generalize very efficiently.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Let me give you an example.",
        "clean_text": "Let me give you an example.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Your own company Google, in their paper on [Gemini 1.5](https://arxiv.org/abs/2403.05530), had this very interesting example.",
        "clean_text": "Your own company Google, in their paper on Gemini 1.5, had this very interesting example.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "They would give the model, [in context](https://www.hopsworks.ai/dictionary/in-context-learning-icl#:~:text=In%2Dcontext%20learning%20\\(ICL\\)%20learns%20a%20new%20task%20from,objective%20of%20next%20token%20prediction.",
        "clean_text": "They would give the model, in context%20learns%20a%20new%20task%20from,objective%20of%20next%20token%20prediction.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "), the grammar book and the dictionary of a language that has fewer than 200 living speakers.",
        "clean_text": "), the grammar book and the dictionary of a language that has fewer than 200 living speakers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "It's not in the pre-training data.",
        "clean_text": "It's not in the pre-training data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "You just give it the dictionary and it basically is able to speak this language and translate to it, including the complex and organic ways in which languages are structured.",
        "clean_text": "You just give it the dictionary and it basically is able to speak this language and translate to it, including the complex and organic ways in which languages are structured.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "If you showed me a dictionary from English to Spanish, I'm not going to be able to pick up how to structure sentences and how to say things in Spanish.",
        "clean_text": "If you showed me a dictionary from English to Spanish, I'm not going to be able to pick up how to structure sentences and how to say things in Spanish.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Because of the representations that it has gained through this pre-training, it is able to now learn a new language extremely efficiently.",
        "clean_text": "Because of the representations that it has gained through this pre-training, it is able to now learn a new language extremely efficiently.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Doesn't that show that this kind of pre-training actually does increase your ability to learn new tasks?",
        "clean_text": "Doesn't that show that this kind of pre-training actually does increase your ability to learn new tasks?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 34,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:25:58",
    "content": "If you were right, LLMs would do really well on ARC puzzles because ARC puzzles are not complex. Each one of them requires very little knowledge. Each one of them is very low on complexity. You don't need to think very hard about it. They're actually extremely obvious for human Even children can do them but LLMs cannot. Even LLMs that have 100,000x more knowledge than you do still cannot. The only thing that makes ARC special is that it was designed with this intent to resist memorization. This is the only thing. This is the huge blocker for LLM performance. If you look at LLMs closely, it's pretty obvious that they're not really synthesizing new programs on the fly to solve the task that they're faced with. They're very much reapplying things that they've stored in memory. For instance, one thing that's very striking is that LLMs can solve a Caesar cipher, transposing letters to code a message. That’s a very complex algorithm, but it comes up quite a bit on the internet. They've basically memorized it. What's really interesting is that they can do it for a transposition length of like three or five, because those are very common numbers in examples provided on the internet. If you try to do it with an arbitrary number like nine, it's going to fail. It does not encode the generalized form of the algorithm, but only specific cases. It has memorized specific cases of the algorithm. If it could actually synthesize on the fly the solver algorithm, then the value of n would not matter at all, because it does not increase the problem complexity.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf you were right, LLMs would do really well on ARC puzzles because ARC puzzles are not complex.",
        "clean_text": "If you were right, LLMs would do really well on ARC puzzles because ARC puzzles are not complex.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Each one of them requires very little knowledge.",
        "clean_text": "Each one of them requires very little knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Each one of them is very low on complexity.",
        "clean_text": "Each one of them is very low on complexity.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You don't need to think very hard about it.",
        "clean_text": "You don't need to think very hard about it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "They're actually extremely obvious for human\n\nEven children can do them but LLMs cannot.",
        "clean_text": "They're actually extremely obvious for human Even children can do them but LLMs cannot.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Even LLMs that have 100,000x more knowledge than you do still cannot.",
        "clean_text": "Even LLMs that have 100,000x more knowledge than you do still cannot.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The only thing that makes ARC special is that it was designed with this intent to resist memorization.",
        "clean_text": "The only thing that makes ARC special is that it was designed with this intent to resist memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "This is the only thing.",
        "clean_text": "This is the only thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "This is the huge blocker for LLM performance.",
        "clean_text": "This is the huge blocker for LLM performance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "If you look at LLMs closely, it's pretty obvious that they're not really synthesizing new programs on the fly to solve the task that they're faced with.",
        "clean_text": "If you look at LLMs closely, it's pretty obvious that they're not really synthesizing new programs on the fly to solve the task that they're faced with.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "They're very much reapplying things that they've stored in memory.",
        "clean_text": "They're very much reapplying things that they've stored in memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "For instance, one thing that's very striking is that LLMs can solve a [Caesar cipher](https://en.wikipedia.org/wiki/Caesar_cipher), transposing letters to code a message.",
        "clean_text": "For instance, one thing that's very striking is that LLMs can solve a Caesar cipher, transposing letters to code a message.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "That’s a very complex algorithm, but it comes up quite a bit on the internet.",
        "clean_text": "That’s a very complex algorithm, but it comes up quite a bit on the internet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "They've basically memorized it.",
        "clean_text": "They've basically memorized it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "What's really interesting is that they can do it for a transposition length of like three or five, because those are very common numbers in examples provided on the internet.",
        "clean_text": "What's really interesting is that they can do it for a transposition length of like three or five, because those are very common numbers in examples provided on the internet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "If you try to do it with an arbitrary number like nine, it's going to fail.",
        "clean_text": "If you try to do it with an arbitrary number like nine, it's going to fail.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "It does not encode the generalized form of the algorithm, but only specific cases.",
        "clean_text": "It does not encode the generalized form of the algorithm, but only specific cases.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "It has memorized specific cases of the algorithm.",
        "clean_text": "It has memorized specific cases of the algorithm.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "If it could actually synthesize on the fly the solver algorithm, then the value of _n_ would not matter at all, because it does not increase the problem complexity.",
        "clean_text": "If it could actually synthesize on the fly the solver algorithm, then the value of n would not matter at all, because it does not increase the problem complexity.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 35,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:26:48",
    "content": "I think this is true of humans as well.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think this is true of humans as well.",
        "clean_text": "I think this is true of humans as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 36,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:26:51",
    "content": "Humans use memorization pattern matching all the time, of course, but humans are not limited to memorization pattern matching. They have this very unique ability to adapt to new situations on the fly. This is exactly what enables you to navigate every new day in your life.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nHumans use memorization pattern matching all the time, of course, but humans are not limited to memorization pattern matching.",
        "clean_text": "Humans use memorization pattern matching all the time, of course, but humans are not limited to memorization pattern matching.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They have this very unique ability to adapt to new situations on the fly.",
        "clean_text": "They have this very unique ability to adapt to new situations on the fly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This is exactly what enables you to navigate every new day in your life.",
        "clean_text": "This is exactly what enables you to navigate every new day in your life.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 37,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:27:07",
    "content": "There was some study that chess grandmasters will perform very well within the context of the moves that—",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere was some study that chess grandmasters will perform very well within the context of the moves that—",
        "clean_text": "There was some study that chess grandmasters will perform very well within the context of the moves that—",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 38,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:27:14",
    "content": "That’s an excellent example because chess, at the highest level, is all about memorization, chess memorization.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat’s an excellent example because chess, at the highest level, is all about memorization, chess memorization.",
        "clean_text": "That’s an excellent example because chess, at the highest level, is all about memorization, chess memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 39,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:27:19",
    "content": "What is your explanation for the original question of why Gemini 1.5 was able, in context, to learn a language, including the complex grammar structure? Doesn't that show that they can pick up new knowledge?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat is your explanation for the original question of why Gemini 1.5 was able, in context, to learn a language, including the complex grammar structure?",
        "clean_text": "What is your explanation for the original question of why Gemini 1.5 was able, in context, to learn a language, including the complex grammar structure?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Doesn't that show that they can pick up new knowledge?",
        "clean_text": "Doesn't that show that they can pick up new knowledge?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 40,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:27:35",
    "content": "I would assume that it has simply mined from its extremely extensive, unimaginably vast training data. It has mined the required template and then it's just reusing it. We know that LLMs have a very poor ability to synthesize new program templates like this on the fly or even adapt existing ones. They're very much limited to fetching.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI would assume that it has simply mined from its extremely extensive, unimaginably vast training data.",
        "clean_text": "I would assume that it has simply mined from its extremely extensive, unimaginably vast training data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It has mined the required template and then it's just reusing it.",
        "clean_text": "It has mined the required template and then it's just reusing it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We know that LLMs have a very poor ability to synthesize new program templates like this on the fly or even adapt existing ones.",
        "clean_text": "We know that LLMs have a very poor ability to synthesize new program templates like this on the fly or even adapt existing ones.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "They're very much limited to fetching.",
        "clean_text": "They're very much limited to fetching.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 41,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:27:55",
    "content": "Suppose there's a programmer at Google. They go into the office in the morning. At what point are they doing something that 100% cannot be due to fetching some template? Suppose they were an LLM. What could they not do if they had only fetched some template from their program? At what point do they have to use this so-called extreme generalization capability?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSuppose there's a programmer at Google.",
        "clean_text": "Suppose there's a programmer at Google.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They go into the office in the morning.",
        "clean_text": "They go into the office in the morning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "At what point are they doing something that 100% cannot be due to fetching some template?",
        "clean_text": "At what point are they doing something that 100% cannot be due to fetching some template?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Suppose they were an LLM.",
        "clean_text": "Suppose they were an LLM.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "What could they not do if they had only fetched some template from their program?",
        "clean_text": "What could they not do if they had only fetched some template from their program?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "At what point do they have to use this so-called extreme generalization capability?",
        "clean_text": "At what point do they have to use this so-called extreme generalization capability?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 42,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:28:12",
    "content": "Forget about Google software developers. For every human, every day of their lives is full of novel things that they've not been prepared for. You cannot navigate your life based on memorization alone. It's impossible.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nForget about Google software developers.",
        "clean_text": "Forget about Google software developers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "For every human, every day of their lives is full of novel things that they've not been prepared for.",
        "clean_text": "For every human, every day of their lives is full of novel things that they've not been prepared for.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You cannot navigate your life based on memorization alone.",
        "clean_text": "You cannot navigate your life based on memorization alone.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's impossible.",
        "clean_text": "It's impossible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 43,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:28:25",
    "content": "It seems like you also agree they're not doing just “memorization.” It seems like you're saying they're less capable of generalization. I'm just curious about the kind of generalization they do. If you get into the office and you try to do this kind of generalization, you're going to fail at your job. Let’s say you're a programmer. What is the first point when you try to do that kind of generalization, you would lose your job because you can't do the extreme generalization?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt seems like you also agree they're not doing just “memorization.” It seems like you're saying they're less capable of generalization.",
        "clean_text": "It seems like you also agree they're not doing just “memorization.” It seems like you're saying they're less capable of generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm just curious about the kind of generalization they do.",
        "clean_text": "I'm just curious about the kind of generalization they do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If you get into the office and you try to do this kind of generalization, you're going to fail at your job.",
        "clean_text": "If you get into the office and you try to do this kind of generalization, you're going to fail at your job.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Let’s say you're a programmer.",
        "clean_text": "Let’s say you're a programmer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "What is the first point when you try to do that kind of generalization, you would lose your job because you can't do the extreme generalization?",
        "clean_text": "What is the first point when you try to do that kind of generalization, you would lose your job because you can't do the extreme generalization?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 44,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:28:51",
    "content": "Take this situation, for instance. You've never been here in this room. Maybe you've been in this city a few times. There's a fair amount of novelty. You've never been interviewing me. There's a fair amount of novelty in every hour of every day in your life. By and large, it’s in fact more novelty than any LLM could handle. If you just put an LLM in a robot, it could not be doing all the things that you've been doing today. Take self-driving cars, for instance. You take a self-driving car operating in the Bay Area. Do you think you could just drop it in New York City or drop it in London, where people drive on the left? No, it's going to fail. Not only can it not generalize to a change in driving rules, but you cannot even make it generalize to a new city. It needs to be trained on each specific environment.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nTake this situation, for instance.",
        "clean_text": "Take this situation, for instance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You've never been here in this room.",
        "clean_text": "You've never been here in this room.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Maybe you've been in this city a few times.",
        "clean_text": "Maybe you've been in this city a few times.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There's a fair amount of novelty.",
        "clean_text": "There's a fair amount of novelty.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You've never been interviewing me.",
        "clean_text": "You've never been interviewing me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "There's a fair amount of novelty in every hour of every day in your life.",
        "clean_text": "There's a fair amount of novelty in every hour of every day in your life.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "By and large, it’s in fact more novelty than any LLM could handle.",
        "clean_text": "By and large, it’s in fact more novelty than any LLM could handle.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "If you just put an LLM in a robot, it could not be doing all the things that you've been doing today.",
        "clean_text": "If you just put an LLM in a robot, it could not be doing all the things that you've been doing today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Take [self-driving cars](https://en.wikipedia.org/wiki/Self-driving_car#:~:text=The%20Union%20of%20Concerned%20Scientists,%2C%20and%20drive%20the%20vehicle.%22), for instance.",
        "clean_text": "Take self-driving cars, for instance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You take a self-driving car operating in the Bay Area.",
        "clean_text": "You take a self-driving car operating in the Bay Area.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Do you think you could just drop it in New York City or drop it in London, where people drive on the left?",
        "clean_text": "Do you think you could just drop it in New York City or drop it in London, where people drive on the left?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "No, it's going to fail.",
        "clean_text": "No, it's going to fail.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Not only can it not generalize to a change in driving rules, but you cannot even make it generalize to a new city.",
        "clean_text": "Not only can it not generalize to a change in driving rules, but you cannot even make it generalize to a new city.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "It needs to be trained on each specific environment.",
        "clean_text": "It needs to be trained on each specific environment.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 45,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:29:55",
    "content": "I agree that self-driving cars aren't AGI.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI agree that self-driving cars aren't AGI.",
        "clean_text": "I agree that self-driving cars aren't AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 46,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:29:58",
    "content": "But it's the same type of model. They're transformers as well. It's the same architecture.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut it's the same type of model.",
        "clean_text": "But it's the same type of model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They're transformers as well.",
        "clean_text": "They're transformers as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It's the same architecture.",
        "clean_text": "It's the same architecture.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 47,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:30:02",
    "content": "I don’t know. Apes also have brains with neurons in them, but they're less intelligent because they're smaller. We can get into that. I still don't understand this concrete thing. We also need training. That's why education exists. That's why we had to spend the first 18 years of our life doing drills.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI don’t know.",
        "clean_text": "I don’t know.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Apes also have brains with neurons in them, but they're less intelligent because they're smaller.",
        "clean_text": "Apes also have brains with neurons in them, but they're less intelligent because they're smaller.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We can get into that.",
        "clean_text": "We can get into that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I still don't understand this concrete thing.",
        "clean_text": "I still don't understand this concrete thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "We also need training.",
        "clean_text": "We also need training.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "That's why education exists.",
        "clean_text": "That's why education exists.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "That's why we had to spend the first 18 years of our life doing drills.",
        "clean_text": "That's why we had to spend the first 18 years of our life doing drills.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 48,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:30:19",
    "content": "We have a memory, but we are not a memory. We are not limited to just a memory.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe have a memory, but we are not a memory.",
        "clean_text": "We have a memory, but we are not a memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We are not limited to just a memory.",
        "clean_text": "We are not limited to just a memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 49,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:30:24",
    "content": "I’m denying the premise that that's the only thing these models are necessarily doing. Suppose you just subbed out a remote work with an LLM and they're a programmer. What is the first point at which you realize this is not a human, this is an LLM?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI’m denying the premise that that's the only thing these models are necessarily doing.",
        "clean_text": "I’m denying the premise that that's the only thing these models are necessarily doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Suppose you just subbed out a remote work with an LLM and they're a programmer.",
        "clean_text": "Suppose you just subbed out a remote work with an LLM and they're a programmer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "What is the first point at which you realize this is not a human, this is an LLM?",
        "clean_text": "What is the first point at which you realize this is not a human, this is an LLM?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 50,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:30:40",
    "content": "How about I just send them an ARC puzzle and see how they do?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nHow about I just send them an ARC puzzle and see how they do?",
        "clean_text": "How about I just send them an ARC puzzle and see how they do?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 51,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:30:44",
    "content": "No, like part of their job.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNo, like part of their job.",
        "clean_text": "No, like part of their job.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 52,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:30:46",
    "content": "You have to deal with novelty all the time.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYou have to deal with novelty all the time.",
        "clean_text": "You have to deal with novelty all the time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 53,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:30:49",
    "content": "Is there a world in which all the programmers are replaced and we're still saying, \"ah, but they're only doing memorization-laden programming tasks.\" In that world, are they still producing a trillion dollars worth of output in the form of code?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIs there a world in which all the programmers are replaced and we're still saying, \"ah, but they're only doing memorization-laden programming tasks.\"",
        "clean_text": "Is there a world in which all the programmers are replaced and we're still saying, \"ah, but they're only doing memorization-laden programming tasks.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "In that world, are they still producing a trillion dollars worth of output in the form of code?",
        "clean_text": "In that world, are they still producing a trillion dollars worth of output in the form of code?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 54,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:31:03",
    "content": "Software development is actually a pretty good example of a job where you're dealing with novelty all the time. If you're not, I'm not sure what you're doing. I personally use generative AI very little in my software development job. Before LLMs, I was also using Stack Overflow very little. Some people maybe are just copy-pasting stuff from Stack Overflow, or nowadays copy-pasting stuff from an LLM. Personally, I try to focus on problem-solving. The syntax is just a technical detail. What's really important is problem-solving. The essence of programming is engineering mental models and mental representations of the problem you're trying to solve.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSoftware development is actually a pretty good example of a job where you're dealing with novelty all the time.",
        "clean_text": "Software development is actually a pretty good example of a job where you're dealing with novelty all the time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you're not, I'm not sure what you're doing.",
        "clean_text": "If you're not, I'm not sure what you're doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I personally use generative AI very little in my software development job.",
        "clean_text": "I personally use generative AI very little in my software development job.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Before LLMs, I was also using [Stack Overflow](https://stackoverflow.com/) very little.",
        "clean_text": "Before LLMs, I was also using Stack Overflow very little.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Some people maybe are just copy-pasting stuff from Stack Overflow, or nowadays copy-pasting stuff from an LLM.",
        "clean_text": "Some people maybe are just copy-pasting stuff from Stack Overflow, or nowadays copy-pasting stuff from an LLM.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Personally, I try to focus on problem-solving.",
        "clean_text": "Personally, I try to focus on problem-solving.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The syntax is just a technical detail.",
        "clean_text": "The syntax is just a technical detail.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "What's really important is problem-solving.",
        "clean_text": "What's really important is problem-solving.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "The essence of programming is engineering mental models and mental representations of the problem you're trying to solve.",
        "clean_text": "The essence of programming is engineering mental models and mental representations of the problem you're trying to solve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 55,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:31:46",
    "content": "We have many people who can interact with these systems themselves. You can go to ChatGPT and say, \"here's a specification of the kind of program I want.\" They'll build it for you.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe have many people who can interact with these systems themselves.",
        "clean_text": "We have many people who can interact with these systems themselves.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You can go to [ChatGPT](https://openai.com/index/chatgpt/) and say, \"here's a specification of the kind of program I want.\"",
        "clean_text": "You can go to ChatGPT and say, \"here's a specification of the kind of program I want.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They'll build it for you.",
        "clean_text": "They'll build it for you.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 56,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:31:56",
    "content": "As long as there are many examples of this program on GitHub, Stack Overflow, and so on, sure they will fetch the program for you from their memory.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAs long as there are many examples of this program on [GitHub](https://github.com/), Stack Overflow, and so on, sure they will fetch the program for you from their memory.",
        "clean_text": "As long as there are many examples of this program on GitHub, Stack Overflow, and so on, sure they will fetch the program for you from their memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 57,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:32:03",
    "content": "But you can change arbitrary details. You can say, \"I need it to work on this different kind of server.\"",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut you can change arbitrary details.",
        "clean_text": "But you can change arbitrary details.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You can say, \"I need it to work on this different kind of server.\"",
        "clean_text": "You can say, \"I need it to work on this different kind of server.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 58,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:32:09",
    "content": "If that were true, there would be no software engineers today.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf that were true, there would be no software engineers today.",
        "clean_text": "If that were true, there would be no software engineers today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 59,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:32:12",
    "content": "I agree we're not at a full AGI yet. These models have fewer than a trillion parameters. A human brain has somewhere on the order of 10-30 trillion synapses. If you were just doing some naive math, you're at least 10x underparameterized. I agree we're not there yet, but I'm confused about why we're not on the spectrum. Yes, I agree that there are many kinds of generalization they can't do. But it seems like they're on this kind of smooth spectrum that we see even within humans. Some humans would have a hard time doing an ARC-type test. We see that based on the performance on Raven's progressive matrices-type IQ tests.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI agree we're not at a full AGI yet.",
        "clean_text": "I agree we're not at a full AGI yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "These models have fewer than a trillion parameters.",
        "clean_text": "These models have fewer than a trillion parameters.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "A human brain has somewhere on the order of 10-30 trillion [synapses](https://en.wikipedia.org/wiki/Synapse).",
        "clean_text": "A human brain has somewhere on the order of 10-30 trillion synapses.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If you were just doing some naive math, you're at least 10x underparameterized.",
        "clean_text": "If you were just doing some naive math, you're at least 10x underparameterized.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I agree we're not there yet, but I'm confused about why we're not on the spectrum.",
        "clean_text": "I agree we're not there yet, but I'm confused about why we're not on the spectrum.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Yes, I agree that there are many kinds of generalization they can't do.",
        "clean_text": "Yes, I agree that there are many kinds of generalization they can't do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "But it seems like they're on this kind of smooth spectrum that we see even within humans.",
        "clean_text": "But it seems like they're on this kind of smooth spectrum that we see even within humans.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Some humans would have a hard time doing an ARC-type test.",
        "clean_text": "Some humans would have a hard time doing an ARC-type test.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "We see that based on the performance on Raven's progressive matrices-type IQ tests.",
        "clean_text": "We see that based on the performance on Raven's progressive matrices-type IQ tests.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 60,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:32:48",
    "content": "I'm not a fan of IQ tests because, for the most part, you can train on IQ tests and get better at them. They're very much memorization-based. This is actually the main pitfall that ARC tries not to fall for.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'm not a fan of IQ tests because, for the most part, you can train on IQ tests and get better at them.",
        "clean_text": "I'm not a fan of IQ tests because, for the most part, you can train on IQ tests and get better at them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They're very much memorization-based.",
        "clean_text": "They're very much memorization-based.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This is actually the main pitfall that ARC tries not to fall for.",
        "clean_text": "This is actually the main pitfall that ARC tries not to fall for.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 61,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:33:02",
    "content": "Let’s say all remote jobs are automated in the next five years. I mean at least the remote jobs that don't require you to be a sort of a service, like a salesperson, where you want the human to be talking. I mean more like programming. In that world, would you say that that's not possible because a programmer needs to do many things that definitely require things that would not be in any pre-training corpus?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet’s say all remote jobs are automated in the next five years.",
        "clean_text": "Let’s say all remote jobs are automated in the next five years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I mean at least the remote jobs that don't require you to be a sort of a service, like a salesperson, where you want the human to be talking.",
        "clean_text": "I mean at least the remote jobs that don't require you to be a sort of a service, like a salesperson, where you want the human to be talking.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I mean more like programming.",
        "clean_text": "I mean more like programming.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "In that world, would you say that that's not possible because a programmer needs to do many things that definitely require things that would not be in any pre-training corpus?",
        "clean_text": "In that world, would you say that that's not possible because a programmer needs to do many things that definitely require things that would not be in any pre-training corpus?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 62,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:33:25",
    "content": "Sure. In five years, there will be more software engineers than there are today, not fewer.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSure.",
        "clean_text": "Sure.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "In five years, there will be more software engineers than there are today, not fewer.",
        "clean_text": "In five years, there will be more software engineers than there are today, not fewer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 63,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:33:30",
    "content": "I'm still not sure. I studied computer science. If I had become a code monkey out of college, what would I be doing? I go to my job. My boss tells me to do something? When does he realize I'm an LLM, if I were an LLM?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'm still not sure.",
        "clean_text": "I'm still not sure.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I studied computer science.",
        "clean_text": "I studied computer science.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If I had become a code monkey out of college, what would I be doing?",
        "clean_text": "If I had become a code monkey out of college, what would I be doing?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I go to my job.",
        "clean_text": "I go to my job.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "My boss tells me to do something?",
        "clean_text": "My boss tells me to do something?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "When does he realize I'm an LLM, if I were an LLM?",
        "clean_text": "When does he realize I'm an LLM, if I were an LLM?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 64,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:33:46",
    "content": "Probably on the first day. Again, if it were true that LLMs could generalize to novel problems like this — actually develop software to solve a problem they've never seen before — you would not need software engineers anymore. If I look at how people are using LLMs in their software engineering job today, they're using it as a Stack Overflow replacement. They're using it as a way to copy-paste code snippets to perform very common actions. What they actually need is a database of code snippets. They don't actually need any of the abilities that actually make them software engineers.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nProbably on the first day.",
        "clean_text": "Probably on the first day.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Again, if it were true that LLMs could generalize to novel problems like this — actually develop software to solve a problem they've never seen before — you would not need software engineers anymore.",
        "clean_text": "Again, if it were true that LLMs could generalize to novel problems like this — actually develop software to solve a problem they've never seen before — you would not need software engineers anymore.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If I look at how people are using LLMs in their software engineering job today, they're using it as a Stack Overflow replacement.",
        "clean_text": "If I look at how people are using LLMs in their software engineering job today, they're using it as a Stack Overflow replacement.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "They're using it as a way to copy-paste code snippets to perform very common actions.",
        "clean_text": "They're using it as a way to copy-paste code snippets to perform very common actions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "What they actually need is a database of code snippets.",
        "clean_text": "What they actually need is a database of code snippets.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "They don't actually need any of the abilities that actually make them software engineers.",
        "clean_text": "They don't actually need any of the abilities that actually make them software engineers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 65,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:34:27",
    "content": "Let's step back on interpolation. Why isn't creativity just interpolation in a higher dimension where — if we're going to use the ML language — a bigger model can learn a more complex manifold? If you read a biography of a scientist, they’re not zero-shotting new scientific theories. They're playing with existing ideas. They're trying to juxtapose them in their head. In the tree of intellectual descendants, they try out some slightly different evolutionary path. You sort of run the experiment there in terms of publishing the paper or whatever. It seems like a similar kind of thing to what humans are doing. There's a higher level of generalization. Bigger and bigger models seem to be approaching higher and higher levels of generalization. GPT-2 couldn't do grade school-level math problems that required more generalization than it had the capability to do. GPT-3 and GPT-4 can.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet's step back on interpolation.",
        "clean_text": "Let's step back on interpolation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Why isn't creativity just interpolation in a higher dimension where —  if we're going to use the [ML](https://en.wikipedia.org/wiki/Machine_learning) language — a bigger model can learn a more complex manifold?",
        "clean_text": "Why isn't creativity just interpolation in a higher dimension where — if we're going to use the ML language — a bigger model can learn a more complex manifold?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If you read a biography of a scientist, they’re not [zero-shotting](https://campus.datacamp.com/courses/chatgpt-prompt-engineering-for-developers/advanced-prompt-engineering-strategies?ex=1#:~:text=Few%2Dshot%20prompting%20is%20a,the%20model%20to%20respond%20to.)",
        "clean_text": "If you read a biography of a scientist, they’re not zero-shotting",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "new scientific theories.",
        "clean_text": "new scientific theories.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "They're playing with existing ideas.",
        "clean_text": "They're playing with existing ideas.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "They're trying to juxtapose them in their head.",
        "clean_text": "They're trying to juxtapose them in their head.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "In the tree of intellectual descendants, they try out some slightly different evolutionary path.",
        "clean_text": "In the tree of intellectual descendants, they try out some slightly different evolutionary path.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You sort of run the experiment there in terms of publishing the paper or whatever.",
        "clean_text": "You sort of run the experiment there in terms of publishing the paper or whatever.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It seems like a similar kind of thing to what humans are doing.",
        "clean_text": "It seems like a similar kind of thing to what humans are doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "There's a higher level of generalization.",
        "clean_text": "There's a higher level of generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Bigger and bigger models seem to be approaching higher and higher levels of generalization.",
        "clean_text": "Bigger and bigger models seem to be approaching higher and higher levels of generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "[GPT-2](https://en.wikipedia.org/wiki/GPT-2) couldn't do grade school-level math problems that required more generalization than it had the capability to do.",
        "clean_text": "GPT-2 couldn't do grade school-level math problems that required more generalization than it had the capability to do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "GPT-3 and GPT-4 can.",
        "clean_text": "GPT-3 and GPT-4 can.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 66,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:35:32",
    "content": "Not quite. GPT-4 has a higher degree of skill and a higher range of skills. It has the same degree of generalization.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNot quite.",
        "clean_text": "Not quite.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "[GPT-4](https://openai.com/index/gpt-4-research/) has a higher degree of skill and a higher range of skills.",
        "clean_text": "GPT-4 has a higher degree of skill and a higher range of skills.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It has the same degree of generalization.",
        "clean_text": "It has the same degree of generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 67,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:35:39",
    "content": "I don't want to get into semantics here. Why can't creativity just be interpolation on a higher dimension?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI don't want to get into semantics here.",
        "clean_text": "I don't want to get into semantics here.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Why can't creativity just be interpolation on a higher dimension?",
        "clean_text": "Why can't creativity just be interpolation on a higher dimension?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 68,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:35:49",
    "content": "Interpolation can absolutely be creative. To your point, I do think that on some level humans also do a lot of memorization, reciting, pattern matching, and interpolation as well. It's very much a spectrum between pattern matching and true reasoning. Humans are never really at one end of the spectrum. They're never really doing pure pattern matching or pure reasoning. They're usually doing some mixture of both. This is true even if you're doing something that seems very reasoning-heavy, like proving a mathematical theorem. As you're doing it, you're doing quite a bit of discrete search in your mind and quite a bit of actual reasoning. You're also very much guided by intuition and pattern matching. You’re guided by the shape of proofs that you've seen before, by your knowledge of mathematics. All of our thoughts, everything we do, is a mixture of interpolated memorization-based thinking, Type 1 thinking, and Type 2 thinking.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nInterpolation can absolutely be creative.",
        "clean_text": "Interpolation can absolutely be creative.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "To your point, I do think that on some level humans also do a lot of memorization, reciting, pattern matching, and interpolation as well.",
        "clean_text": "To your point, I do think that on some level humans also do a lot of memorization, reciting, pattern matching, and interpolation as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It's very much a spectrum between pattern matching and true reasoning.",
        "clean_text": "It's very much a spectrum between pattern matching and true reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Humans are never really at one end of the spectrum.",
        "clean_text": "Humans are never really at one end of the spectrum.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "They're never really doing pure pattern matching or pure reasoning.",
        "clean_text": "They're never really doing pure pattern matching or pure reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "They're usually doing some mixture of both.",
        "clean_text": "They're usually doing some mixture of both.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "This is true even if you're doing something that seems very reasoning-heavy, like proving a mathematical theorem.",
        "clean_text": "This is true even if you're doing something that seems very reasoning-heavy, like proving a mathematical theorem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "As you're doing it, you're doing quite a bit of discrete [search](https://en.wikipedia.org/wiki/Search_algorithm) in your mind and quite a bit of actual reasoning.",
        "clean_text": "As you're doing it, you're doing quite a bit of discrete search in your mind and quite a bit of actual reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You're also very much guided by intuition and pattern matching.",
        "clean_text": "You're also very much guided by intuition and pattern matching.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You’re guided by the shape of proofs that you've seen before, by your knowledge of mathematics.",
        "clean_text": "You’re guided by the shape of proofs that you've seen before, by your knowledge of mathematics.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "All of our thoughts, everything we do, is a mixture of interpolated memorization-based thinking, [Type 1 thinking, and Type 2 thinking](https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking).",
        "clean_text": "All of our thoughts, everything we do, is a mixture of interpolated memorization-based thinking, Type 1 thinking, and Type 2 thinking.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 69,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:36:55",
    "content": "Why are bigger models more sample efficient?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhy are bigger models more sample efficient?",
        "clean_text": "Why are bigger models more sample efficient?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 70,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:36:59",
    "content": "Because they have more reusable building blocks that they can lean on to pick up new patterns in their training data.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBecause they have more reusable building blocks that they can lean on to pick up new patterns in their training data.",
        "clean_text": "Because they have more reusable building blocks that they can lean on to pick up new patterns in their training data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 71,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:37:09",
    "content": "Does that pattern keep continuing as you keep getting bigger and bigger?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nDoes that pattern keep continuing as you keep getting bigger and bigger?",
        "clean_text": "Does that pattern keep continuing as you keep getting bigger and bigger?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 72,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:37:12",
    "content": "It does to the extent that the new patterns you’re giving the model to learn are a good match for what it has learned before. If you present something that’s actually novel that is not in a steady distribution, like an ARC puzzle for instance, it will fail.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt does to the extent that the new patterns you’re giving the model to learn are a good match for what it has learned before.",
        "clean_text": "It does to the extent that the new patterns you’re giving the model to learn are a good match for what it has learned before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you present something that’s actually novel that is not in a steady distribution, like an ARC puzzle for instance, it will fail.",
        "clean_text": "If you present something that’s actually novel that is not in a steady distribution, like an ARC puzzle for instance, it will fail.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 73,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:37:25",
    "content": "Let me make this claim. The program synthesis is a very useful intuition pump. Why can’t this be the case for what’s happening in the transformer? The early layers are figuring out how to represent the inputting tokens. The middle layers do this kind of program search, program synthesis, and they combine the inputs to all the circuits in the model. They go from the low-level representation to a higher-level representation near the middle of the model. They use these programs. They combine these concepts. What comes out the other end is the reasoning based on that high-level intelligence.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet me make this claim.",
        "clean_text": "Let me make this claim.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The program synthesis is a very useful [intuition pump](https://en.wikipedia.org/wiki/Intuition_pump).",
        "clean_text": "The program synthesis is a very useful intuition pump.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Why can’t this be the case for what’s happening in the transformer?",
        "clean_text": "Why can’t this be the case for what’s happening in the transformer?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "The early layers are figuring out how to represent the inputting tokens.",
        "clean_text": "The early layers are figuring out how to represent the inputting tokens.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "The middle layers do this kind of program search, program synthesis, and they combine the inputs to all the circuits in the model.",
        "clean_text": "The middle layers do this kind of program search, program synthesis, and they combine the inputs to all the circuits in the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "They go from the low-level representation to a higher-level representation near the middle of the model.",
        "clean_text": "They go from the low-level representation to a higher-level representation near the middle of the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "They use these programs.",
        "clean_text": "They use these programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "They combine these concepts.",
        "clean_text": "They combine these concepts.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "What comes out the other end is the reasoning based on that high-level intelligence.",
        "clean_text": "What comes out the other end is the reasoning based on that high-level intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 74,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:38:01",
    "content": "Possibly. Why not? But if these models were actually capable of synthesizing novel programs, however simple, they should be able to do ARC. Because for any ARC task, if you write down the solution program in Python), it’s not a complex program. It’s extremely simple. Humans can figure it out. Why can’t LLMs do it?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nPossibly.",
        "clean_text": "Possibly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Why not?",
        "clean_text": "Why not?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "But if these models were actually capable of synthesizing novel programs, however simple, they should be able to do ARC.",
        "clean_text": "But if these models were actually capable of synthesizing novel programs, however simple, they should be able to do ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Because for any ARC task, if you write down the solution program in [Python](https://en.wikipedia.org/wiki/Python_/(programming_language/)), it’s not a complex program.",
        "clean_text": "Because for any ARC task, if you write down the solution program in Python), it’s not a complex program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It’s extremely simple.",
        "clean_text": "It’s extremely simple.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Humans can figure it out.",
        "clean_text": "Humans can figure it out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Why can’t LLMs do it?",
        "clean_text": "Why can’t LLMs do it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 75,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:38:26",
    "content": "That’s a fair point. To turn the question around to you, suppose it’s the case that in a year a multimodal model can solve ARC. Let’s say it gets 80% or whatever the average human would get. Are we then on track for AGI?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat’s a fair point.",
        "clean_text": "That’s a fair point.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "To turn the question around to you, suppose it’s the case that in a year a multimodal model can solve ARC.",
        "clean_text": "To turn the question around to you, suppose it’s the case that in a year a multimodal model can solve ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Let’s say it gets 80% or whatever the average human would get.",
        "clean_text": "Let’s say it gets 80% or whatever the average human would get.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Are we then on track for AGI?",
        "clean_text": "Are we then on track for AGI?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 76,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:38:43",
    "content": "Quite possibly, yes. Honestly, what I would like to see is an LLM-type model solving ARC at 80%, but after having only been trained on core knowledge-related stuff.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nQuite possibly, yes.",
        "clean_text": "Quite possibly, yes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Honestly, what I would like to see is an LLM-type model solving ARC at 80%, but after having only been trained on core knowledge-related stuff.",
        "clean_text": "Honestly, what I would like to see is an LLM-type model solving ARC at 80%, but after having only been trained on core knowledge-related stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 77,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:38:59",
    "content": "But human kids, we’re necessarily just trained on what we have in our genes…",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut human kids, we’re necessarily just trained on what we have in our genes…",
        "clean_text": "But human kids, we’re necessarily just trained on what we have in our genes…",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 78,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:39:04",
    "content": "Let me rephrase that. I want it to be only trained on information that is not explicitly trying to anticipate what’s going to be in the ARC test set.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet me rephrase that.",
        "clean_text": "Let me rephrase that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I want it to be only trained on information that is not explicitly trying to anticipate what’s going to be in the ARC test set.",
        "clean_text": "I want it to be only trained on information that is not explicitly trying to anticipate what’s going to be in the ARC test set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 79,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:39:15",
    "content": "Isn’t the whole point of ARC that you can’t? It’s a new type of intelligence test every single time?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIsn’t the whole point of ARC that you can’t?",
        "clean_text": "Isn’t the whole point of ARC that you can’t?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It’s a new type of intelligence test every single time?",
        "clean_text": "It’s a new type of intelligence test every single time?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 80,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:39:21",
    "content": "Yes, that is the point. If ARC were a perfect, flawless benchmark, it would be impossible to anticipate what’s in the test set. ARC was released more than four years ago and so far it’s been resistant to memorization. It has, to some extent, passed the test of time. But it’s not perfect. Let’s say you try to make by hand hundreds of thousands of ARC tasks. You try to multiply them by programmatically generating variations. You end up with maybe hundreds of millions of tasks. Just by brute forcing the task space, there will be enough overlap between what you’re trained on and what’s in the test set that you can actually score very highly. With enough scale, you can always cheat.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYes, that is the point.",
        "clean_text": "Yes, that is the point.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If ARC were a perfect, flawless benchmark, it would be impossible to anticipate what’s in the test set.",
        "clean_text": "If ARC were a perfect, flawless benchmark, it would be impossible to anticipate what’s in the test set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "ARC was released more than four years ago and so far it’s been resistant to memorization.",
        "clean_text": "ARC was released more than four years ago and so far it’s been resistant to memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It has, to some extent, passed the test of time.",
        "clean_text": "It has, to some extent, passed the test of time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "But it’s not perfect.",
        "clean_text": "But it’s not perfect.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Let’s say you try to make by hand hundreds of thousands of ARC tasks.",
        "clean_text": "Let’s say you try to make by hand hundreds of thousands of ARC tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "You try to multiply them by programmatically generating variations.",
        "clean_text": "You try to multiply them by programmatically generating variations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You end up with maybe hundreds of millions of tasks.",
        "clean_text": "You end up with maybe hundreds of millions of tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Just by brute forcing the task space, there will be enough overlap between what you’re trained on and what’s in the test set that you can actually score very highly.",
        "clean_text": "Just by brute forcing the task space, there will be enough overlap between what you’re trained on and what’s in the test set that you can actually score very highly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "With enough scale, you can always cheat.",
        "clean_text": "With enough scale, you can always cheat.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 81,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:40:05",
    "content": "If you can do this for every single thing that supposedly requires intelligence, then what good is intelligence? Apparently, you can just brute force intelligence.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf you can do this for every single thing that supposedly requires intelligence, then what good is intelligence?",
        "clean_text": "If you can do this for every single thing that supposedly requires intelligence, then what good is intelligence?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Apparently, you can just brute force intelligence.",
        "clean_text": "Apparently, you can just brute force intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 82,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:40:12",
    "content": "If the world, if your life, were a static distribution then sure, you could just brute force the space of possible behaviors. There are several metaphors for intelligence I like to use. One is that you can think of intelligence as a pathfinding algorithm in future situation space. I don't know if you're familiar with RTS game development. You have a map, a 2D map, and you have partial information about it. There is some fog of war on your map. There are areas that you haven't explored yet. You know nothing about them. There are also areas that you've explored but you only know what they were like in the past. You don't know how they are like today. Now, instead of thinking about a 2D map, think about the space of possible future situations that you might encounter and how they're connected to each other. Intelligence is a pathfinding algorithm. Once you set a goal, it will tell you how to get there optimally. Of course, it's constrained by the information you have. It cannot pathfind in an area that you know nothing about. It also cannot anticipate changes. If you had complete information about the map, then you could solve the pathfinding problem by simply memorizing every possible path, every mapping from point A to point B. You could solve the problem with pure memory. The reason you cannot do that in real life is because you don't actually know what's going to happen in the future. Life is ever changing.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf the world, if your life, were a static distribution then sure, you could just brute force the space of possible behaviors.",
        "clean_text": "If the world, if your life, were a static distribution then sure, you could just brute force the space of possible behaviors.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There are several metaphors for intelligence I like to use.",
        "clean_text": "There are several metaphors for intelligence I like to use.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One is that you can think of intelligence as a [pathfinding algorithm](https://en.wikipedia.org/wiki/Pathfinding) in future situation space.",
        "clean_text": "One is that you can think of intelligence as a pathfinding algorithm in future situation space.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I don't know if you're familiar with [RTS](https://en.wikipedia.org/wiki/Real-time_strategy) game development.",
        "clean_text": "I don't know if you're familiar with RTS game development.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You have a map, a 2D map, and you have partial information about it.",
        "clean_text": "You have a map, a 2D map, and you have partial information about it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "There is some [fog of war](https://en.wikipedia.org/wiki/Fog_of_war) on your map.",
        "clean_text": "There is some fog of war on your map.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There are areas that you haven't explored yet.",
        "clean_text": "There are areas that you haven't explored yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You know nothing about them.",
        "clean_text": "You know nothing about them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "There are also areas that you've explored but you only know what they were like in the past.",
        "clean_text": "There are also areas that you've explored but you only know what they were like in the past.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You don't know how they are like today.",
        "clean_text": "You don't know how they are like today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Now, instead of thinking about a 2D map, think about the space of possible future situations that you might encounter and how they're connected to each other.",
        "clean_text": "Now, instead of thinking about a 2D map, think about the space of possible future situations that you might encounter and how they're connected to each other.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "Intelligence is a pathfinding algorithm.",
        "clean_text": "Intelligence is a pathfinding algorithm.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Once you set a goal, it will tell you how to get there optimally.",
        "clean_text": "Once you set a goal, it will tell you how to get there optimally.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Of course, it's constrained by the information you have.",
        "clean_text": "Of course, it's constrained by the information you have.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "It cannot pathfind in an area that you know nothing about.",
        "clean_text": "It cannot pathfind in an area that you know nothing about.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "It also cannot anticipate changes.",
        "clean_text": "It also cannot anticipate changes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "If you had complete information about the map, then you could solve the pathfinding problem by simply memorizing every possible path, every mapping from point A to point B. You could solve the problem with pure memory.",
        "clean_text": "If you had complete information about the map, then you could solve the pathfinding problem by simply memorizing every possible path, every mapping from point A to point B. You could solve the problem with pure memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "The reason you cannot do that in real life is because you don't actually know what's going to happen in the future.",
        "clean_text": "The reason you cannot do that in real life is because you don't actually know what's going to happen in the future.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "Life is ever changing.",
        "clean_text": "Life is ever changing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 83,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:41:56",
    "content": "I feel like you're using words like “memorization,” which we would never use for human children. If your kid learns to do algebra and then learns to do calculus, you wouldn't say they've memorized calculus. If they can solve any arbitrary algebraic problem, you wouldn't say they've memorized algebra. You’d say they've learned algebra.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI feel like you're using words like “memorization,” which we would never use for human children.",
        "clean_text": "I feel like you're using words like “memorization,” which we would never use for human children.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If your kid learns to do algebra and then learns to do calculus, you wouldn't say they've memorized calculus.",
        "clean_text": "If your kid learns to do algebra and then learns to do calculus, you wouldn't say they've memorized calculus.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If they can solve any arbitrary algebraic problem, you wouldn't say they've memorized algebra.",
        "clean_text": "If they can solve any arbitrary algebraic problem, you wouldn't say they've memorized algebra.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You’d say they've learned algebra.",
        "clean_text": "You’d say they've learned algebra.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 84,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:42:11",
    "content": "Humans are never really doing pure memorization or pure reasoning.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nHumans are never really doing pure memorization or pure reasoning.",
        "clean_text": "Humans are never really doing pure memorization or pure reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 85,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:42:15",
    "content": "That's only because you're semantically labeling what the human does as skill. But it's a memorization when the exact same skill is done by the LLM, as you can measure by these benchmarks. You can just plug in any sort of math problem.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's only because you're semantically labeling what the human does as skill.",
        "clean_text": "That's only because you're semantically labeling what the human does as skill.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "But it's a memorization when the exact same skill is done by the LLM, as you can measure by these benchmarks.",
        "clean_text": "But it's a memorization when the exact same skill is done by the LLM, as you can measure by these benchmarks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You can just plug in any sort of math problem.",
        "clean_text": "You can just plug in any sort of math problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 86,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:42:22",
    "content": "Sometimes humans are doing the exact same as the LLM is doing. For instance, if you learn to add numbers you're memorizing an algorithm. You're memorizing a program and then you can reapply it. You are not synthesizing on the fly the addition program.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSometimes humans are doing the exact same as the LLM is doing.",
        "clean_text": "Sometimes humans are doing the exact same as the LLM is doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "For instance, if you learn to add numbers you're memorizing an algorithm.",
        "clean_text": "For instance, if you learn to add numbers you're memorizing an algorithm.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You're memorizing a program and then you can reapply it.",
        "clean_text": "You're memorizing a program and then you can reapply it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You are not synthesizing on the fly the addition program.",
        "clean_text": "You are not synthesizing on the fly the addition program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 87,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:42:38",
    "content": "Obviously at some point, some human had to figure out how to do addition. A kid doesn’t figure it out by starting from the axioms of set theory and going to how to do addition.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nObviously at some point, some human had to figure out how to do addition.",
        "clean_text": "Obviously at some point, some human had to figure out how to do addition.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "A kid doesn’t figure it out by starting from the axioms of set theory and going to how to do addition.",
        "clean_text": "A kid doesn’t figure it out by starting from the axioms of set theory and going to how to do addition.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 88,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:42:47",
    "content": "What you learn in school is mostly memorization.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat you learn in school is mostly memorization.",
        "clean_text": "What you learn in school is mostly memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 89,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:42:50",
    "content": "My claim is that these models are vastly underparameterized relative to how many flops, how many parameters, you have in the human brain. So it makes sense that they're not going to be coming up with new theorems like the smartest humans can. Most humans can't do that either. What most humans do sounds like something similar to what you are calling memorization, which is memorizing skills or memorizing techniques that you've learned. So it sounds like it's compatible. Tell me if this is wrong. Is it compatible in your world if all the remote workers are gone but they're doing skills which we can potentially make synthetic data out of? We record every single remote worker's screen. We sort of understand the skills they're performing there. Now we've trained a model that can do all this. All the remote workers are unemployed. We're generating trillions of dollars of economic activity from AI remote workers. In that world, are we still in the memorization regime?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nMy claim is that these models are vastly underparameterized relative to how many [flops](https://en.wikipedia.org/wiki/FLOPS), how many parameters, you have in the human brain.",
        "clean_text": "My claim is that these models are vastly underparameterized relative to how many flops, how many parameters, you have in the human brain.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "So it makes sense that they're not going to be coming up with new theorems like the smartest humans can.",
        "clean_text": "So it makes sense that they're not going to be coming up with new theorems like the smartest humans can.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Most humans can't do that either.",
        "clean_text": "Most humans can't do that either.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "What most humans do sounds like something similar to what you are calling memorization, which is memorizing skills or memorizing techniques that you've learned.",
        "clean_text": "What most humans do sounds like something similar to what you are calling memorization, which is memorizing skills or memorizing techniques that you've learned.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "So it sounds like it's compatible.",
        "clean_text": "So it sounds like it's compatible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Tell me if this is wrong.",
        "clean_text": "Tell me if this is wrong.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Is it compatible in your world if all the remote workers are gone but they're doing skills which we can potentially make [synthetic data](https://en.wikipedia.org/wiki/Synthetic_data) out of?",
        "clean_text": "Is it compatible in your world if all the remote workers are gone but they're doing skills which we can potentially make synthetic data out of?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "We record every single remote worker's screen.",
        "clean_text": "We record every single remote worker's screen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "We sort of understand the skills they're performing there.",
        "clean_text": "We sort of understand the skills they're performing there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Now we've trained a model that can do all this.",
        "clean_text": "Now we've trained a model that can do all this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "All the remote workers are unemployed.",
        "clean_text": "All the remote workers are unemployed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "We're generating trillions of dollars of economic activity from AI remote workers.",
        "clean_text": "We're generating trillions of dollars of economic activity from AI remote workers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "In that world, are we still in the memorization regime?",
        "clean_text": "In that world, are we still in the memorization regime?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 90,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:43:45",
    "content": "Sure, with memorization you can automate almost anything as long as it's a static distribution, as long as you don't have to deal with change.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSure, with memorization you can automate almost anything as long as it's a static distribution, as long as you don't have to deal with change.",
        "clean_text": "Sure, with memorization you can automate almost anything as long as it's a static distribution, as long as you don't have to deal with change.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 91,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:43:54",
    "content": "Are most jobs part of such a static distribution?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAre most jobs part of such a static distribution?",
        "clean_text": "Are most jobs part of such a static distribution?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 92,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:43:57",
    "content": "Potentially, there are lots of things that you can automate. LLMs are an excellent tool for automation. But you have to understand that automation is not the same as intelligence. I'm not saying that LLMs are useless. I've been a huge proponent of deep learning for many years. For many years, I've been saying two things. I've been saying that if you keep scaling up deep learning, it will keep paying off. At the same time I've been saying if you keep scaling up deep learning, this will not lead to AGI. We can automate more and more things. Yes, this is economically valuable. Yes, potentially there are many jobs you could automate away like this. That would be economically valuable. You're still not going to have intelligence. So you can ask, what does it matter if we can generate all this economic value? Maybe we don't need intelligence after all. You need intelligence the moment you have to deal with change, novelty, and uncertainty. As long as you're in a space that can be exactly described in advance, you can just rely on pure memorization. In fact, you can always solve any problem. You can always display arbitrary levels of skills on any task without leveraging any intelligence whatsoever, as long as it is possible to describe the problem and its solution very, very precisely.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nPotentially, there are lots of things that you can automate.",
        "clean_text": "Potentially, there are lots of things that you can automate.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "LLMs are an excellent tool for automation.",
        "clean_text": "LLMs are an excellent tool for automation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "But you have to understand that automation is not the same as intelligence.",
        "clean_text": "But you have to understand that automation is not the same as intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I'm not saying that LLMs are useless.",
        "clean_text": "I'm not saying that LLMs are useless.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I've been a huge proponent of [deep learning](https://en.wikipedia.org/wiki/Deep_learning) for many years.",
        "clean_text": "I've been a huge proponent of deep learning for many years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "For many years, I've been saying two things.",
        "clean_text": "For many years, I've been saying two things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I've been saying that if you keep scaling up deep learning, it will keep paying off.",
        "clean_text": "I've been saying that if you keep scaling up deep learning, it will keep paying off.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "At the same time I've been saying if you keep scaling up deep learning, this will not lead to AGI.",
        "clean_text": "At the same time I've been saying if you keep scaling up deep learning, this will not lead to AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "We can automate more and more things.",
        "clean_text": "We can automate more and more things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Yes, this is economically valuable.",
        "clean_text": "Yes, this is economically valuable.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Yes, potentially there are many jobs you could automate away like this.",
        "clean_text": "Yes, potentially there are many jobs you could automate away like this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "That would be economically valuable.",
        "clean_text": "That would be economically valuable.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "You're still not going to have intelligence.",
        "clean_text": "You're still not going to have intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "So you can ask, what does it matter if we can generate all this economic value?",
        "clean_text": "So you can ask, what does it matter if we can generate all this economic value?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "Maybe we don't need intelligence after all.",
        "clean_text": "Maybe we don't need intelligence after all.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "You need intelligence the moment you have to deal with change, novelty, and uncertainty.",
        "clean_text": "You need intelligence the moment you have to deal with change, novelty, and uncertainty.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "As long as you're in a space that can be exactly described in advance, you can just rely on pure memorization.",
        "clean_text": "As long as you're in a space that can be exactly described in advance, you can just rely on pure memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "In fact, you can always solve any problem.",
        "clean_text": "In fact, you can always solve any problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "You can always display arbitrary levels of skills on any task without leveraging any intelligence whatsoever, as long as it is possible to describe the problem and its solution very, very precisely.",
        "clean_text": "You can always display arbitrary levels of skills on any task without leveraging any intelligence whatsoever, as long as it is possible to describe the problem and its solution very, very precisely.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 93,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:45:17",
    "content": "When they do deal with novelty, then you just call it interpolation.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhen they do deal with novelty, then you just call it interpolation.",
        "clean_text": "When they do deal with novelty, then you just call it interpolation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 94,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:45:21",
    "content": "No, interpolation is not enough to deal with all kinds of novelty. If it were, then LLMs would be AGI.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNo, interpolation is not enough to deal with all kinds of novelty.",
        "clean_text": "No, interpolation is not enough to deal with all kinds of novelty.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If it were, then LLMs would be AGI.",
        "clean_text": "If it were, then LLMs would be AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 95,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:45:30",
    "content": "I agree they're not AGI. I'm just trying to figure out if we’re on the path to AGI. The crux here is that it seems to me that these things are on a spectrum and we're clearly covering the earliest part of the spectrum with LLMs.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI agree they're not AGI.",
        "clean_text": "I agree they're not AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm just trying to figure out if we’re on the path to AGI.",
        "clean_text": "I'm just trying to figure out if we’re on the path to AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The crux here is that it seems to me that these things are on a spectrum and we're clearly covering the earliest part of the spectrum with LLMs.",
        "clean_text": "The crux here is that it seems to me that these things are on a spectrum and we're clearly covering the earliest part of the spectrum with LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 96,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:45:43",
    "content": "I think so.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think so.",
        "clean_text": "I think so.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 97,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:45:44",
    "content": "Okay, interesting. Here's another thing that I think is evidence for this: grokking. Clearly, even within deep learning, there's a difference between the memorization regime and the generalization regime. At first they'll just memorize the data set. If you're doing modular addition it’s how to add digits. At some point, if you keep training on that, they'll learn the skill. The fact that there is that distinction suggests that for the generalized circuit that deep learning can learn, there is a regime where it generalizes if you have an overparameterized model. We don't have that in comparison to all the tasks we want these models to do right now.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOkay, interesting.",
        "clean_text": "Okay, interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Here's another thing that I think is evidence for this: [grokking](https://arxiv.org/abs/2201.02177).",
        "clean_text": "Here's another thing that I think is evidence for this: grokking.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Clearly, even within deep learning, there's a difference between the memorization regime and the generalization regime.",
        "clean_text": "Clearly, even within deep learning, there's a difference between the memorization regime and the generalization regime.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "At first they'll just memorize the data set.",
        "clean_text": "At first they'll just memorize the data set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "If you're doing modular addition it’s how to add digits.",
        "clean_text": "If you're doing modular addition it’s how to add digits.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "At some point, if you keep training on that, they'll learn the skill.",
        "clean_text": "At some point, if you keep training on that, they'll learn the skill.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The fact that there is that distinction suggests that for the generalized circuit that deep learning can learn, there is a regime where it generalizes if you have an overparameterized model.",
        "clean_text": "The fact that there is that distinction suggests that for the generalized circuit that deep learning can learn, there is a regime where it generalizes if you have an overparameterized model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "We don't have that in comparison to all the tasks we want these models to do right now.",
        "clean_text": "We don't have that in comparison to all the tasks we want these models to do right now.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 98,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:46:20",
    "content": "Grokking is a very, very old phenomenon. We've been observing it for decades. It's basically an instance of the minimum description length principle. Given a problem, you can just memorize a pointwise input-to-output mapping, which is completely overfit. It does not generalize at all, but it solves the problem on the trained data. From there, you can actually keep pruning it and making your mapping simpler and more compressed. At some point, it will start generalizing. That's something called the minimum description length principle. It's this idea that the program that will generalize best is the shortest. It doesn't mean that you're doing anything other than memorization. You're doing memorization plus regularization.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nGrokking is a very, very old phenomenon.",
        "clean_text": "Grokking is a very, very old phenomenon.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We've been observing it for decades.",
        "clean_text": "We've been observing it for decades.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It's basically an instance of the [minimum description length](https://en.wikipedia.org/wiki/Minimum_description_length) principle.",
        "clean_text": "It's basically an instance of the minimum description length principle.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Given a problem, you can just memorize a pointwise input-to-output mapping, which is completely [overfit](https://en.wikipedia.org/wiki/Overfitting).",
        "clean_text": "Given a problem, you can just memorize a pointwise input-to-output mapping, which is completely overfit.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It does not generalize at all, but it solves the problem on the trained data.",
        "clean_text": "It does not generalize at all, but it solves the problem on the trained data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "From there, you can actually keep pruning it and making your mapping simpler and more compressed.",
        "clean_text": "From there, you can actually keep pruning it and making your mapping simpler and more compressed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "At some point, it will start generalizing.",
        "clean_text": "At some point, it will start generalizing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "That's something called the minimum description length principle.",
        "clean_text": "That's something called the minimum description length principle.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It's this idea that the program that will generalize best is the shortest.",
        "clean_text": "It's this idea that the program that will generalize best is the shortest.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It doesn't mean that you're doing anything other than memorization.",
        "clean_text": "It doesn't mean that you're doing anything other than memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You're doing memorization plus regularization.",
        "clean_text": "You're doing memorization plus regularization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 99,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:47:15",
    "content": "A.k.a. generalization?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nA.k.a.",
        "clean_text": "A.k.a.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "generalization?",
        "clean_text": "generalization?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 100,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:47:17",
    "content": "Yeah, that absolutely leads to generalization.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYeah, that absolutely leads to generalization.",
        "clean_text": "Yeah, that absolutely leads to generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 101,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:47:20",
    "content": "So you do that within one skill. The pattern you see here of meta-learning) is that it's more efficient to store a program that can perform many skills rather than one skill. This is what we might call fluid intelligence. So as you get bigger and bigger in models, you would expect it to go up this hierarchy of generalization. It generalizes to a skill, then it generalizes across multiple skills.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSo you do that within one skill.",
        "clean_text": "So you do that within one skill.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The pattern you see here of [meta-learning](https://en.wikipedia.org/wiki/Meta-learning_/(computer_science/)) is that it's more efficient to store a program that can perform many skills rather than one skill.",
        "clean_text": "The pattern you see here of meta-learning) is that it's more efficient to store a program that can perform many skills rather than one skill.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This is what we might call [fluid intelligence](https://en.wikipedia.org/wiki/Fluid_and_crystallized_intelligence).",
        "clean_text": "This is what we might call fluid intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "So as you get bigger and bigger in models, you would expect it to go up this hierarchy of generalization.",
        "clean_text": "So as you get bigger and bigger in models, you would expect it to go up this hierarchy of generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It generalizes to a skill, then it generalizes across multiple skills.",
        "clean_text": "It generalizes to a skill, then it generalizes across multiple skills.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 102,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:47:38",
    "content": "That's correct. LLMs are not infinitely large. They have only a fixed number of parameters. They have to compress their knowledge as much as possible. In practice, LLMs are mostly storing reusable bits of programs like vector programs. Because they have this need for compression, every time they're learning a new program they're going to try to express it in terms of existing bits and pieces of programs that they've already learned before.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's correct.",
        "clean_text": "That's correct.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "LLMs are not infinitely large.",
        "clean_text": "LLMs are not infinitely large.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They have only a fixed number of parameters.",
        "clean_text": "They have only a fixed number of parameters.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "They have to compress their knowledge as much as possible.",
        "clean_text": "They have to compress their knowledge as much as possible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "In practice, LLMs are mostly storing reusable bits of programs like vector programs.",
        "clean_text": "In practice, LLMs are mostly storing reusable bits of programs like vector programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Because they have this need for compression, every time they're learning a new program they're going to try to express it in terms of existing bits and pieces of programs that they've already learned before.",
        "clean_text": "Because they have this need for compression, every time they're learning a new program they're going to try to express it in terms of existing bits and pieces of programs that they've already learned before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 103,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:48:08",
    "content": "Isn't this generalization?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIsn't this generalization?",
        "clean_text": "Isn't this generalization?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 104,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:48:10",
    "content": "Absolutely. Clearly LLMs have some degree of generalization. This is precisely why. It's because they have to compress.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAbsolutely.",
        "clean_text": "Absolutely.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Clearly LLMs have some degree of generalization.",
        "clean_text": "Clearly LLMs have some degree of generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This is precisely why.",
        "clean_text": "This is precisely why.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's because they have to compress.",
        "clean_text": "It's because they have to compress.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 105,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:48:19",
    "content": "Why is that intrinsically limited? At some point it has to learn a higher level of generalization and a higher level, and then the highest level is the fluid intelligence.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhy is that intrinsically limited?",
        "clean_text": "Why is that intrinsically limited?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "At some point it has to learn a higher level of generalization and a higher level, and then the highest level is the fluid intelligence.",
        "clean_text": "At some point it has to learn a higher level of generalization and a higher level, and then the highest level is the fluid intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 106,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:48:28",
    "content": "It's intrinsically limited because the substrate of your model is a big parametric curve. All you can do with this is local generalization. If you want to go beyond this towards broader or even extreme generalization, you have to move to a different type of model. My paradigm of choice is discrete program search, program synthesis. If you want to understand that, you can sort of compare and contrast it with deep learning. In deep learning your model is a differentiable parametric curve. In program synthesis, your model is a discrete graph of operators. You've got a set of logical operators, like a domain-specific language. You're picking instances of it. You're structuring that into a graph that's a program. That's actually very similar to a program you might write in Python or C++ and so on. We are doing machine learning here. We're trying to automatically learn these models. In deep learning your learning engine is gradient descent. Gradient descent is very compute efficient because you have this very strong informative feedback signal about where the solution is. You can get to the solution very quickly, but it is very data inefficient. In order to make it work, you need a dense sampling of the operating space. You need a dense sampling of the data distribution. Then you're limited to only generalizing within that data distribution. The reason why you have this limitation is because your model is a curve. Meanwhile, if you look at discrete program search, the learning engine is combinatorial search. You're just trying a bunch of programs until you find one that actually meets your spec. This process is extremely data efficient. You can learn a generalizable program from just one example, two examples. This is why it works so well on ARC, by the way. The big limitation is that it's extremely compute inefficient because you're running into combinatorial explosion, of course. You can sort of see here how deep learning and discrete program search have very complementary strengths, and limitations as well. Every limitation of deep learning has a corresponding strength in program synthesis and inversely. The path forward is going to be to merge the two. Here’s another way you can think about it. These parametric curves trained with gradient descent are great fits for everything that's System 1-type thinking: pattern recognition, intuition, memorization, etc. Discrete program search is a great fit for Type 2 thinking: planning, reasoning. It’s quickly figuring out a generalizable model that matches just one or two examples, like for an ARC puzzle for instance. Humans are never doing pure System 1 or pure System 2. They're always mixing and matching both. Right now, we have all the tools for System 1. We have almost nothing for System 2. The way forward is to create a hybrid system. The form it's going to take is mostly System 2. The outer structure is going to be a discrete program search system. You're going to fix the fundamental limitation of discrete program search, which is combinatorial explosion, with deep learning. You're going to leverage deep learning to guide and to provide intuition in program space, to guide the program search. That's very similar to what you see when you're playing chess or when you're trying to prove a theorem, for instance. It's mostly a reasoning thing, but you start out with some intuition about the shape of the solution. That's very much something you can get via a deep learning model. Deep learning models are very much like intuition machines. They're pattern matching machines. You start from this shape of the solution, and then you're going to do actual explicit discrete program search. But you're not going to do it via brute force. You're not going to try things randomly. You're actually going to ask another deep learning model for suggestions. It’ll be like, “here's the most likely next step. Here's where in the graph you should be going.” You can also use yet another deep learning model for feedback like “well, here's what I have so far. Is it looking good? Should I just backtrack and try something new?” Discrete program search is going to be the key but you want to make it dramatically better, orders of magnitude more efficient, by leveraging deep learning. By the way, another thing that you can use deep learning for is of course things like common sense knowledge and knowledge in general. You're going to end up with this sort of system where you have this on-the-fly synthesis engine that can adapt to new situations. The way it adapts is that it's going to fetch from a bank of patterns, modules that could be themselves curves, differentiable modules, and some others that could be algorithmic in nature. It's going to assemble them via this intuition-guided process. For every new situation you might be faced with, it's going to give you a generalizable model that was synthesized using very, very little data. Something like this would solve ARC.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's intrinsically limited because the substrate of your model is a big parametric curve.",
        "clean_text": "It's intrinsically limited because the substrate of your model is a big parametric curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "All you can do with this is local generalization.",
        "clean_text": "All you can do with this is local generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If you want to go beyond this towards broader or even extreme generalization, you have to move to a different type of model.",
        "clean_text": "If you want to go beyond this towards broader or even extreme generalization, you have to move to a different type of model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "My paradigm of choice is discrete program search, program synthesis.",
        "clean_text": "My paradigm of choice is discrete program search, program synthesis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "If you want to understand that, you can sort of compare and contrast it with deep learning.",
        "clean_text": "If you want to understand that, you can sort of compare and contrast it with deep learning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "In deep learning your model is a differentiable parametric curve.",
        "clean_text": "In deep learning your model is a differentiable parametric curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "In program synthesis, your model is a discrete graph of operators.",
        "clean_text": "In program synthesis, your model is a discrete graph of operators.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You've got a set of logical operators, like a domain-specific language.",
        "clean_text": "You've got a set of logical operators, like a domain-specific language.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You're picking instances of it.",
        "clean_text": "You're picking instances of it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You're structuring that into a graph that's a program.",
        "clean_text": "You're structuring that into a graph that's a program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "That's actually very similar to a program you might write in Python or [C++](https://en.wikipedia.org/wiki/C%2B%2B) and so on.",
        "clean_text": "That's actually very similar to a program you might write in Python or C++ and so on.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "We are doing machine learning here.",
        "clean_text": "We are doing machine learning here.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "We're trying to automatically learn these models.",
        "clean_text": "We're trying to automatically learn these models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "In deep learning your learning engine is [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent).",
        "clean_text": "In deep learning your learning engine is gradient descent.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "Gradient descent is very compute efficient because you have this very strong informative feedback signal about where the solution is.",
        "clean_text": "Gradient descent is very compute efficient because you have this very strong informative feedback signal about where the solution is.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "You can get to the solution very quickly, but it is very data inefficient.",
        "clean_text": "You can get to the solution very quickly, but it is very data inefficient.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "In order to make it work, you need a dense sampling of the operating space.",
        "clean_text": "In order to make it work, you need a dense sampling of the operating space.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "You need a dense sampling of the data distribution.",
        "clean_text": "You need a dense sampling of the data distribution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "Then you're limited to only generalizing within that data distribution.",
        "clean_text": "Then you're limited to only generalizing within that data distribution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "The reason why you have this limitation is because your model is a curve.",
        "clean_text": "The reason why you have this limitation is because your model is a curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "Meanwhile, if you look at discrete program search, the learning engine is [combinatorial search](https://en.wikipedia.org/wiki/Combinatorial_search).",
        "clean_text": "Meanwhile, if you look at discrete program search, the learning engine is combinatorial search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "You're just trying a bunch of programs until you find one that actually meets your spec.",
        "clean_text": "You're just trying a bunch of programs until you find one that actually meets your spec.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "This process is extremely data efficient.",
        "clean_text": "This process is extremely data efficient.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "You can learn a generalizable program from just one example, two examples.",
        "clean_text": "You can learn a generalizable program from just one example, two examples.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "This is why it works so well on ARC, by the way.",
        "clean_text": "This is why it works so well on ARC, by the way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "The big limitation is that it's extremely compute inefficient because you're running into combinatorial explosion, of course.",
        "clean_text": "The big limitation is that it's extremely compute inefficient because you're running into combinatorial explosion, of course.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "You can sort of see here how deep learning and discrete program search have very complementary strengths, and limitations as well.",
        "clean_text": "You can sort of see here how deep learning and discrete program search have very complementary strengths, and limitations as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "Every limitation of deep learning has a corresponding strength in program synthesis and inversely.",
        "clean_text": "Every limitation of deep learning has a corresponding strength in program synthesis and inversely.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "The path forward is going to be to merge the two.",
        "clean_text": "The path forward is going to be to merge the two.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "Here’s another way you can think about it.",
        "clean_text": "Here’s another way you can think about it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 30,
        "original_text": "These parametric curves trained with gradient descent are great fits for everything that's System 1-type thinking: pattern recognition, intuition, memorization, etc.",
        "clean_text": "These parametric curves trained with gradient descent are great fits for everything that's System 1-type thinking: pattern recognition, intuition, memorization, etc.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 31,
        "original_text": "Discrete program search is a great fit for Type 2 thinking: planning, reasoning.",
        "clean_text": "Discrete program search is a great fit for Type 2 thinking: planning, reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 32,
        "original_text": "It’s quickly figuring out a generalizable model that matches just one or two examples, like for an ARC puzzle for instance.",
        "clean_text": "It’s quickly figuring out a generalizable model that matches just one or two examples, like for an ARC puzzle for instance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 33,
        "original_text": "Humans are never doing pure System 1 or pure System 2.",
        "clean_text": "Humans are never doing pure System 1 or pure System 2.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 34,
        "original_text": "They're always mixing and matching both.",
        "clean_text": "They're always mixing and matching both.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 35,
        "original_text": "Right now, we have all the tools for System 1.",
        "clean_text": "Right now, we have all the tools for System 1.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 36,
        "original_text": "We have almost nothing for System 2.",
        "clean_text": "We have almost nothing for System 2.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 37,
        "original_text": "The way forward is to create a hybrid system.",
        "clean_text": "The way forward is to create a hybrid system.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 38,
        "original_text": "The form it's going to take is mostly System 2.",
        "clean_text": "The form it's going to take is mostly System 2.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 39,
        "original_text": "The outer structure is going to be a discrete program search system.",
        "clean_text": "The outer structure is going to be a discrete program search system.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 40,
        "original_text": "You're going to fix the fundamental limitation of discrete program search, which is combinatorial explosion, with deep learning.",
        "clean_text": "You're going to fix the fundamental limitation of discrete program search, which is combinatorial explosion, with deep learning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 41,
        "original_text": "You're going to leverage deep learning to guide and to provide intuition in program space, to guide the program search.",
        "clean_text": "You're going to leverage deep learning to guide and to provide intuition in program space, to guide the program search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 42,
        "original_text": "That's very similar to what you see when you're playing chess or when you're trying to prove a theorem, for instance.",
        "clean_text": "That's very similar to what you see when you're playing chess or when you're trying to prove a theorem, for instance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 43,
        "original_text": "It's mostly a reasoning thing, but you start out with some intuition about the shape of the solution.",
        "clean_text": "It's mostly a reasoning thing, but you start out with some intuition about the shape of the solution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 44,
        "original_text": "That's very much something you can get via a deep learning model.",
        "clean_text": "That's very much something you can get via a deep learning model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 45,
        "original_text": "Deep learning models are very much like intuition machines.",
        "clean_text": "Deep learning models are very much like intuition machines.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 46,
        "original_text": "They're pattern matching machines.",
        "clean_text": "They're pattern matching machines.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 47,
        "original_text": "You start from this shape of the solution, and then you're going to do actual explicit discrete program search.",
        "clean_text": "You start from this shape of the solution, and then you're going to do actual explicit discrete program search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 48,
        "original_text": "But you're not going to do it via brute force.",
        "clean_text": "But you're not going to do it via brute force.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 49,
        "original_text": "You're not going to try things randomly.",
        "clean_text": "You're not going to try things randomly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 50,
        "original_text": "You're actually going to ask another deep learning model for suggestions.",
        "clean_text": "You're actually going to ask another deep learning model for suggestions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 51,
        "original_text": "It’ll be like, “here's the most likely next step.",
        "clean_text": "It’ll be like, “here's the most likely next step.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 52,
        "original_text": "Here's where in the graph you should be going.” You can also use yet another deep learning model for feedback like “well, here's what I have so far.",
        "clean_text": "Here's where in the graph you should be going.” You can also use yet another deep learning model for feedback like “well, here's what I have so far.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 53,
        "original_text": "Is it looking good?",
        "clean_text": "Is it looking good?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 54,
        "original_text": "Should I just backtrack and try something new?” Discrete program search is going to be the key but you want to make it dramatically better, orders of magnitude more efficient, by leveraging deep learning.",
        "clean_text": "Should I just backtrack and try something new?” Discrete program search is going to be the key but you want to make it dramatically better, orders of magnitude more efficient, by leveraging deep learning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 55,
        "original_text": "By the way, another thing that you can use deep learning for is of course things like common sense knowledge and knowledge in general.",
        "clean_text": "By the way, another thing that you can use deep learning for is of course things like common sense knowledge and knowledge in general.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 56,
        "original_text": "You're going to end up with this sort of system where you have this on-the-fly synthesis engine that can adapt to new situations.",
        "clean_text": "You're going to end up with this sort of system where you have this on-the-fly synthesis engine that can adapt to new situations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 57,
        "original_text": "The way it adapts is that it's going to fetch from a bank of patterns, modules that could be themselves curves, differentiable modules, and some others that could be algorithmic in nature.",
        "clean_text": "The way it adapts is that it's going to fetch from a bank of patterns, modules that could be themselves curves, differentiable modules, and some others that could be algorithmic in nature.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 58,
        "original_text": "It's going to assemble them via this intuition-guided process.",
        "clean_text": "It's going to assemble them via this intuition-guided process.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 59,
        "original_text": "For every new situation you might be faced with, it's going to give you a generalizable model that was synthesized using very, very little data.",
        "clean_text": "For every new situation you might be faced with, it's going to give you a generalizable model that was synthesized using very, very little data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 60,
        "original_text": "Something like this would solve ARC.",
        "clean_text": "Something like this would solve ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 107,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:54:18",
    "content": "That's actually a really interesting prompt. There’s an interesting crux here. I talk to my friends who are extremely optimistic about LLMs and expect AGI within the next couple of years. In some sense, they also agree that scaling is not all you need but that the rest of the progress is undergirded and enabled by scaling. You still need to add the System 2 and the test time compute on top of these models. Their perspective is that it's relatively straightforward to do that because you have this library of representations that you built up from pre-training. It's almost like it's just skimming through textbooks. You need some more deliberate way in which it engages with the material it learns. In-context learning is extremely sample efficient. To actually distill that into the weights, you need the model to talk through the things it sees and then add it back to the weights. As far as the System 2 goes, they talk about adding some kind of RL setup so that it is encouraged to proceed on the reasoning traces that end up being correct. They think this is relatively straightforward stuff that will be added within the next couple of years.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's actually a really interesting prompt.",
        "clean_text": "That's actually a really interesting prompt.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There’s an interesting crux here.",
        "clean_text": "There’s an interesting crux here.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I talk to my friends who are extremely optimistic about LLMs and expect AGI within the next couple of years.",
        "clean_text": "I talk to my friends who are extremely optimistic about LLMs and expect AGI within the next couple of years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "In some sense, they also agree that scaling is not all you need but that the rest of the progress is undergirded and enabled by scaling.",
        "clean_text": "In some sense, they also agree that scaling is not all you need but that the rest of the progress is undergirded and enabled by scaling.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You still need to add the System 2 and the test time compute on top of these models.",
        "clean_text": "You still need to add the System 2 and the test time compute on top of these models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Their perspective is that it's relatively straightforward to do that because you have this library of representations that you built up from pre-training.",
        "clean_text": "Their perspective is that it's relatively straightforward to do that because you have this library of representations that you built up from pre-training.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "It's almost like it's just skimming through textbooks.",
        "clean_text": "It's almost like it's just skimming through textbooks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You need some more deliberate way in which it engages with the material it learns.",
        "clean_text": "You need some more deliberate way in which it engages with the material it learns.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "In-context learning is extremely sample efficient.",
        "clean_text": "In-context learning is extremely sample efficient.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "To actually [distill](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.)",
        "clean_text": "To actually distill",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "that into the [weights](https://deepai.org/machine-learning-glossary-and-terms/weight-artificial-neural-network), you need the model to talk through the things it sees and then add it back to the weights.",
        "clean_text": "that into the weights, you need the model to talk through the things it sees and then add it back to the weights.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "As far as the System 2 goes, they talk about adding some kind of RL setup so that it is encouraged to proceed on the reasoning traces that end up being correct.",
        "clean_text": "As far as the System 2 goes, they talk about adding some kind of RL setup so that it is encouraged to proceed on the reasoning traces that end up being correct.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "They think this is relatively straightforward stuff that will be added within the next couple of years.",
        "clean_text": "They think this is relatively straightforward stuff that will be added within the next couple of years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 108,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:55:32",
    "content": "That's an empirical question so we’ll see.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's an empirical question so we’ll see.",
        "clean_text": "That's an empirical question so we’ll see.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 109,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:55:35",
    "content": "I assume your intuition is not that. I'm curious why.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI assume your intuition is not that.",
        "clean_text": "I assume your intuition is not that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm curious why.",
        "clean_text": "I'm curious why.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 110,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:55:37",
    "content": "My intuition is that this whole System 2 architecture is the hard part. It’s the very hard and unobvious part. Scaling up the interpolative memory is the easy part. It's literally just a big curve. All you need is more data. It's an interpolative representation of a data set. That's the easy part. The hard part is the architecture of intelligence. Memory and intelligence are separate components. We have the memory. We don't have the intelligence yet. I agree with you that having the memory is actually very useful. If you just had the intelligence but it was not hooked up to an extensive memory, it would not be that useful because it would not have enough material to work from.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nMy intuition is that this whole System 2 architecture is the hard part.",
        "clean_text": "My intuition is that this whole System 2 architecture is the hard part.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It’s the very hard and unobvious part.",
        "clean_text": "It’s the very hard and unobvious part.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Scaling up the interpolative memory is the easy part.",
        "clean_text": "Scaling up the interpolative memory is the easy part.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's literally just a big curve.",
        "clean_text": "It's literally just a big curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "All you need is more data.",
        "clean_text": "All you need is more data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "It's an interpolative representation of a data set.",
        "clean_text": "It's an interpolative representation of a data set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "That's the easy part.",
        "clean_text": "That's the easy part.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "The hard part is the architecture of intelligence.",
        "clean_text": "The hard part is the architecture of intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Memory and intelligence are separate components.",
        "clean_text": "Memory and intelligence are separate components.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "We have the memory.",
        "clean_text": "We have the memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "We don't have the intelligence yet.",
        "clean_text": "We don't have the intelligence yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "I agree with you that having the memory is actually very useful.",
        "clean_text": "I agree with you that having the memory is actually very useful.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "If you just had the intelligence but it was not hooked up to an extensive memory, it would not be that useful because it would not have enough material to work from.",
        "clean_text": "If you just had the intelligence but it was not hooked up to an extensive memory, it would not be that useful because it would not have enough material to work from.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 111,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:56:21",
    "content": "Former guest Trenton Bricken advanced an alternative hypothesis that intelligence is just hierarchically associated memory. When Sherlock Holmes goes into a crime scene he's extremely sample efficient. He can just look at a few clues and figure out who was the murderer. He's able to do that because he has learned higher level associations. It's memory in some fundamental sense. Here's one way to ask the question. In the brain, supposedly we do program synthesis, but it is just synapses connected to each other. Physically, it's got to be that you just query the right circuit, right?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nFormer guest [Trenton Bricken](https://www.dwarkeshpatel.com/p/sholto-douglas-trenton-bricken) advanced an alternative hypothesis that intelligence is just hierarchically associated memory.",
        "clean_text": "Former guest Trenton Bricken advanced an alternative hypothesis that intelligence is just hierarchically associated memory.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "When Sherlock Holmes goes into a crime scene he's extremely sample efficient.",
        "clean_text": "When Sherlock Holmes goes into a crime scene he's extremely sample efficient.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "He can just look at a few clues and figure out who was the murderer.",
        "clean_text": "He can just look at a few clues and figure out who was the murderer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "He's able to do that because he has learned higher level associations.",
        "clean_text": "He's able to do that because he has learned higher level associations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It's memory in some fundamental sense.",
        "clean_text": "It's memory in some fundamental sense.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Here's one way to ask the question.",
        "clean_text": "Here's one way to ask the question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "In the brain, supposedly we do program synthesis, but it is just synapses connected to each other.",
        "clean_text": "In the brain, supposedly we do program synthesis, but it is just synapses connected to each other.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Physically, it's got to be that you just query the right circuit, right?",
        "clean_text": "Physically, it's got to be that you just query the right circuit, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 112,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:57:01",
    "content": "You are, yeah. It's a matter of degree.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYou are, yeah.",
        "clean_text": "You are, yeah.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It's a matter of degree.",
        "clean_text": "It's a matter of degree.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 113,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:57:04",
    "content": "Training in the environment that human ancestors were trained in means you learn those circuits. If you train on the same kinds of outputs that humans produce — which to replicate, requires these kinds of circuits — wouldn't that train the same thing that is whatever humans have?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nTraining in the environment that human ancestors were trained in means you learn those circuits.",
        "clean_text": "Training in the environment that human ancestors were trained in means you learn those circuits.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you train on the same kinds of outputs that humans produce — which to replicate, requires these kinds of circuits — wouldn't that train the same thing that is whatever humans have?",
        "clean_text": "If you train on the same kinds of outputs that humans produce — which to replicate, requires these kinds of circuits — wouldn't that train the same thing that is whatever humans have?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 114,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:57:19",
    "content": "It's a matter of degree. If you have a system that has a memory and is only capable of doing local generalization from that, it's not going to be very adaptable. To be really general, you need the memory plus the ability to search to quite some depth to achieve broader and even extreme generalization. One of my favorite psychologists is Jean Piaget, the founder of developmental psychology. He had a very good quote about intelligence. He said, \"intelligence is what you use when you don't know what to do.\" As a human living your life, in most situations you already know what to do because you've been in this situation before. You already have the answer. You're only going to need to use intelligence when you're faced with novelty, with something you didn't expect. It’s something that you weren't prepared for, either by your own life experience or your evolutionary history. This day that you're living right now is different in some important ways from every day you've lived before. It's also different from any day ever lived by any of your ancestors. You're still capable of being functional. How is that possible?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's a matter of degree.",
        "clean_text": "It's a matter of degree.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you have a system that has a memory and is only capable of doing local generalization from that, it's not going to be very adaptable.",
        "clean_text": "If you have a system that has a memory and is only capable of doing local generalization from that, it's not going to be very adaptable.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "To be really general, you need the memory plus the ability to search to quite some depth to achieve broader and even extreme generalization.",
        "clean_text": "To be really general, you need the memory plus the ability to search to quite some depth to achieve broader and even extreme generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "One of my favorite psychologists is [Jean Piaget](https://en.wikipedia.org/wiki/Jean_Piaget), the founder of [developmental psychology](https://en.wikipedia.org/wiki/Developmental_psychology).",
        "clean_text": "One of my favorite psychologists is Jean Piaget, the founder of developmental psychology.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "He had a very good quote about intelligence.",
        "clean_text": "He had a very good quote about intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "He said, \"intelligence is what you use when you don't know what to do.\"",
        "clean_text": "He said, \"intelligence is what you use when you don't know what to do.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "As a human living your life, in most situations you already know what to do because you've been in this situation before.",
        "clean_text": "As a human living your life, in most situations you already know what to do because you've been in this situation before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You already have the answer.",
        "clean_text": "You already have the answer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You're only going to need to use intelligence when you're faced with novelty, with something you didn't expect.",
        "clean_text": "You're only going to need to use intelligence when you're faced with novelty, with something you didn't expect.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It’s something that you weren't prepared for, either by your own life experience or your evolutionary history.",
        "clean_text": "It’s something that you weren't prepared for, either by your own life experience or your evolutionary history.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "This day that you're living right now is different in some important ways from every day you've lived before.",
        "clean_text": "This day that you're living right now is different in some important ways from every day you've lived before.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "It's also different from any day ever lived by any of your ancestors.",
        "clean_text": "It's also different from any day ever lived by any of your ancestors.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "You're still capable of being functional.",
        "clean_text": "You're still capable of being functional.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "How is that possible?",
        "clean_text": "How is that possible?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 115,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:58:39",
    "content": "I'm not denying that generalization is extremely important and the basis for intelligence. That's not the crux. The crux is how much of that is happening in the models. Okay, let me ask a separate question about the differences in intelligence between humans. Maybe because of the reasons you mentioned, the intelligence tests are not measuring it well. But clearly there's differences in intelligence between different humans. What is your explanation for what's going on there? That's sort of compatible with my story. There's a spectrum of generality and these models are climbing up to a human level. Even some humans haven't even climbed up to the Einstein level or the François level.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'm not denying that generalization is extremely important and the basis for intelligence.",
        "clean_text": "I'm not denying that generalization is extremely important and the basis for intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "That's not the crux.",
        "clean_text": "That's not the crux.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The crux is how much of that is happening in the models.",
        "clean_text": "The crux is how much of that is happening in the models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Okay, let me ask a separate question about the differences in intelligence between humans.",
        "clean_text": "Okay, let me ask a separate question about the differences in intelligence between humans.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Maybe because of the reasons you mentioned, the intelligence tests  are not measuring it well.",
        "clean_text": "Maybe because of the reasons you mentioned, the intelligence tests are not measuring it well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "But clearly there's differences in intelligence between different humans.",
        "clean_text": "But clearly there's differences in intelligence between different humans.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "What is your explanation for what's going on there?",
        "clean_text": "What is your explanation for what's going on there?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "That's sort of compatible with my story.",
        "clean_text": "That's sort of compatible with my story.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "There's a spectrum of generality and these models are climbing up to a human level.",
        "clean_text": "There's a spectrum of generality and these models are climbing up to a human level.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Even some humans haven't even climbed up to the Einstein level or the François level.",
        "clean_text": "Even some humans haven't even climbed up to the Einstein level or the François level.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 116,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "00:59:18",
    "content": "That's a great question. There is extensive evidence that differences in intelligence are mostly genetic in nature. That means that if you take someone who is not very intelligent, there is no amount of training data you can expose that person to that would make them become Einstein. This points to the fact that you really need a better architecture. You need a better algorithm. More training data is not in fact all you need.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's a great question.",
        "clean_text": "That's a great question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There is extensive [evidence](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6220331/) that [differences in intelligence are mostly genetic](https://en.wikipedia.org/wiki/Heritability_of_IQ) in nature.",
        "clean_text": "There is extensive evidence that differences in intelligence are mostly genetic in nature.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "That means that if you take someone who is not very intelligent, there is no amount of training data you can expose that person to that would make them become Einstein.",
        "clean_text": "That means that if you take someone who is not very intelligent, there is no amount of training data you can expose that person to that would make them become Einstein.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "This points to the fact that you really need a better architecture.",
        "clean_text": "This points to the fact that you really need a better architecture.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You need a better algorithm.",
        "clean_text": "You need a better algorithm.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "More training data is not in fact all you need.",
        "clean_text": "More training data is not in fact all you need.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 117,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:59:50",
    "content": "I think I agree with that. I might phrase it in this way. The people who are smarter have, in ML language, better initializations. If you look at the neural wiring, it's more efficient. Maybe they have greater density of firing. Some part of the story is scaling. There is some correlation between brain size and intelligence. Within the context of “scaling” LLMs, people talk about architectural improvements. A model like Gemini 1.5 Flash performs as well as GPT-4 did when GPT-4 was released a year ago, but is 57 times cheaper on output. Part of the scaling story is that we're in like extremely low-hanging fruit territory when it comes to those architectural improvements.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think I agree with that.",
        "clean_text": "I think I agree with that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I might phrase it in this way.",
        "clean_text": "I might phrase it in this way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The people who are smarter have, in ML language, better [initializations](https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/).",
        "clean_text": "The people who are smarter have, in ML language, better initializations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If you look at the neural wiring, it's more efficient.",
        "clean_text": "If you look at the neural wiring, it's more efficient.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Maybe they have greater density of firing.",
        "clean_text": "Maybe they have greater density of firing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Some part of the story is scaling.",
        "clean_text": "Some part of the story is scaling.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There is [some correlation between brain size and intelligence](https://en.wikipedia.org/wiki/Brain_size#Intelligence).",
        "clean_text": "There is some correlation between brain size and intelligence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Within the context of “scaling” LLMs, people talk about architectural improvements.",
        "clean_text": "Within the context of “scaling” LLMs, people talk about architectural improvements.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "A model like [Gemini 1.5 Flash](https://deepmind.google/technologies/gemini/flash/) performs as well as GPT-4 did when GPT-4 was released a year ago, but is 57 times cheaper on output.",
        "clean_text": "A model like Gemini 1.5 Flash performs as well as GPT-4 did when GPT-4 was released a year ago, but is 57 times cheaper on output.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Part of the scaling story is that we're in like extremely low-hanging fruit territory when it comes to those architectural improvements.",
        "clean_text": "Part of the scaling story is that we're in like extremely low-hanging fruit territory when it comes to those architectural improvements.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 118,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:00:40",
    "content": "We're back now with the co-founder of Zapier, Mike Knoop. You're funding this prize and you're running this prize with François. Tell me about how this came together. What prompted you guys to launch this prize?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe're back now with the co-founder of [Zapier](https://zapier.com/), [Mike Knoop](https://zapier.com/blog/author/mike-knoop/).",
        "clean_text": "We're back now with the co-founder of Zapier, Mike Knoop.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You're funding this prize and you're running this prize with François.",
        "clean_text": "You're funding this prize and you're running this prize with François.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Tell me about how this came together.",
        "clean_text": "Tell me about how this came together.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "What prompted you guys to launch this prize?",
        "clean_text": "What prompted you guys to launch this prize?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 119,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:00:58",
    "content": "I've been AI curious for 13 years. I co-founded Zapier and I’ve been running it for the last 13 years. I first got introduced to your work during COVID. I went down the rabbit hole. I had a lot of free time. It was right after you'd published your paper, \"On the Measure of Intelligence”. You introduced the concept of AGI and that this efficiency of skill acquisition is the right definition, and the ARC puzzles. I don't think the first Kaggle contest had been done yet. It was still running. It was interesting but I just parked the idea. I had bigger fish to fry at Zapier. We were in the middle of this big turnaround of trying to get to our second product. It was January 2022 when the chain-of-thought paper came out. That really awoke me to the progress. I even gave a whole presentation to Zapier on the GPT-3 paper. I felt like I had priced in everything that LLMs could do. That paper was really shocking to me in terms of all these latent capabilities that LLMs have that I didn't expect they had. I actually gave up my exec team role. I was running half the company at that point. I went back to being an individual contributor and just doing AI research alongside Bryan, my co-founder. Ultimately, that led me back towards ARC. I was looking into it again. I had expected to see this saturation effect that MMLU and GMS8K have. When I looked at the scores and the progress over the last four years, I was really shocked to see that we'd made very little objective progress towards it. It felt like a really important eval. As I spent the last year quizzing people about it in my network and community, very few people even knew it existed. If it's right that this is a really globally, singularly unique AGI eval — and it's different from every other eval that exists that more narrowly measures AI skill — then more people should know about this thing. I had my own ideas on how to beat ARC as well. I was working nights and weekends on that. I flew up to meet François earlier this year to quiz him and show him my ideas. Ultimately I asked him why more people didn’t know about ARC? You should actually answer that. It's a really interesting question. Why don't you think more people know about ARC?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI've been AI curious for 13 years.",
        "clean_text": "I've been AI curious for 13 years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I co-founded Zapier and I’ve been running it for the last 13 years.",
        "clean_text": "I co-founded Zapier and I’ve been running it for the last 13 years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I first got introduced to your work during COVID.",
        "clean_text": "I first got introduced to your work during COVID.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I went down the rabbit hole.",
        "clean_text": "I went down the rabbit hole.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I had a lot of free time.",
        "clean_text": "I had a lot of free time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "It was right after you'd published your paper, [\"On the Measure of Intelligence”](https://arxiv.org/pdf/1911.01547).",
        "clean_text": "It was right after you'd published your paper, \"On the Measure of Intelligence”.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "You introduced the concept of AGI and that this efficiency of skill acquisition is the right definition, and the ARC puzzles.",
        "clean_text": "You introduced the concept of AGI and that this efficiency of skill acquisition is the right definition, and the ARC puzzles.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "I don't think the first [Kaggle contest](https://www.kaggle.com/c/abstraction-and-reasoning-challenge) had been done yet.",
        "clean_text": "I don't think the first Kaggle contest had been done yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It was still running.",
        "clean_text": "It was still running.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It was interesting but I just parked the idea.",
        "clean_text": "It was interesting but I just parked the idea.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "I had bigger fish to fry at Zapier.",
        "clean_text": "I had bigger fish to fry at Zapier.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "We were in the middle of this big turnaround of trying to get to our second product.",
        "clean_text": "We were in the middle of this big turnaround of trying to get to our second product.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "It was January 2022 when the [chain-of-thought paper](https://arxiv.org/abs/2201.11903) came out.",
        "clean_text": "It was January 2022 when the chain-of-thought paper came out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "That really awoke me to the progress.",
        "clean_text": "That really awoke me to the progress.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "I even gave a whole presentation to Zapier on the [GPT-3 paper](https://arxiv.org/abs/2005.14165).",
        "clean_text": "I even gave a whole presentation to Zapier on the GPT-3 paper.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "I felt like I had priced in everything that LLMs could do.",
        "clean_text": "I felt like I had priced in everything that LLMs could do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "That paper was really shocking to me in terms of all these latent capabilities that LLMs have that I didn't expect they had.",
        "clean_text": "That paper was really shocking to me in terms of all these latent capabilities that LLMs have that I didn't expect they had.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "I actually gave up my exec team role.",
        "clean_text": "I actually gave up my exec team role.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "I was running half the company at that point.",
        "clean_text": "I was running half the company at that point.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "I went back to being an individual contributor and just doing AI research alongside [Bryan](https://zapier.com/blog/author/bryan-helmig/), my co-founder.",
        "clean_text": "I went back to being an individual contributor and just doing AI research alongside Bryan, my co-founder.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "Ultimately, that led me back towards ARC.",
        "clean_text": "Ultimately, that led me back towards ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "I was looking into it again.",
        "clean_text": "I was looking into it again.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "I had expected to see this saturation effect that [MMLU](https://arxiv.org/abs/2009.03300) and GMS8K have.",
        "clean_text": "I had expected to see this saturation effect that MMLU and GMS8K have.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "When I looked at the scores and the progress over the last four years, I was really shocked to see that we'd made very little objective progress towards it.",
        "clean_text": "When I looked at the scores and the progress over the last four years, I was really shocked to see that we'd made very little objective progress towards it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "It felt like a really important eval.",
        "clean_text": "It felt like a really important eval.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "As I spent the last year quizzing people about it in my network and community, very few people even knew it existed.",
        "clean_text": "As I spent the last year quizzing people about it in my network and community, very few people even knew it existed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "If it's right that this is a really globally, singularly unique AGI eval — and it's different from every other eval that exists that more narrowly measures AI skill — then more people should know about this thing.",
        "clean_text": "If it's right that this is a really globally, singularly unique AGI eval — and it's different from every other eval that exists that more narrowly measures AI skill — then more people should know about this thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "I had my own ideas on how to beat ARC as well.",
        "clean_text": "I had my own ideas on how to beat ARC as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "I was working nights and weekends on that.",
        "clean_text": "I was working nights and weekends on that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "I flew up to meet François earlier this year to quiz him and show him my ideas.",
        "clean_text": "I flew up to meet François earlier this year to quiz him and show him my ideas.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 30,
        "original_text": "Ultimately I asked him why more people didn’t know about ARC?",
        "clean_text": "Ultimately I asked him why more people didn’t know about ARC?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 31,
        "original_text": "You should actually answer that.",
        "clean_text": "You should actually answer that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 32,
        "original_text": "It's a really interesting question.",
        "clean_text": "It's a really interesting question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 33,
        "original_text": "Why don't you think more people know about ARC?",
        "clean_text": "Why don't you think more people know about ARC?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 120,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:03:17",
    "content": "Benchmarks that gain traction in the research community are benchmarks that are already fairly tractable. The dynamic is that some research group is going to make some initial breakthrough and then this is going to catch the attention of everyone else. You're going to get follow-up papers with people trying to beat the first team and so on. This has not really happened for ARC because ARC is actually very hard for existing AI techniques. ARC requires you to try new ideas. That's very much the point. The point is not that you should just be able to apply existing technology and solve ARC. The point is that existing technology has reached a plateau. If you want to go beyond that and start being able to tackle problems that you haven't memorized or seen before, you need to try new ideas. ARC is not just meant to be this sort of measure of how close we are to AGI. It's also meant to be a source of inspiration. I want researchers to look at these puzzles and be like, \"hey, it's really strange that these puzzles are so simple and most humans can just do them very quickly. Why is it so hard for existing AI systems? Why is it so hard for LLMs and so on?\" This is true for LLMs, but ARC was actually released before LLMs were really a thing. The only thing that made it special at the time was that it was designed to be resistant to memorization. The fact that it has survived LLMs so well, and GenAI in general, shows that it is actually resistant to memorization.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBenchmarks that gain traction in the research community are benchmarks that are already fairly tractable.",
        "clean_text": "Benchmarks that gain traction in the research community are benchmarks that are already fairly tractable.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The dynamic is that some research group is going to make some initial breakthrough and then this is going to catch the attention of everyone else.",
        "clean_text": "The dynamic is that some research group is going to make some initial breakthrough and then this is going to catch the attention of everyone else.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You're going to get follow-up papers with people trying to beat the first team and so on.",
        "clean_text": "You're going to get follow-up papers with people trying to beat the first team and so on.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "This has not really happened for ARC because ARC is actually very hard for existing AI techniques.",
        "clean_text": "This has not really happened for ARC because ARC is actually very hard for existing AI techniques.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "ARC requires you to try new ideas.",
        "clean_text": "ARC requires you to try new ideas.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "That's very much the point.",
        "clean_text": "That's very much the point.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The point is not that you should just be able to apply existing technology and solve ARC.",
        "clean_text": "The point is not that you should just be able to apply existing technology and solve ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "The point is that existing technology has reached a plateau.",
        "clean_text": "The point is that existing technology has reached a plateau.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "If you want to go beyond that and start being able to tackle problems that you haven't memorized or seen before, you need to try new ideas.",
        "clean_text": "If you want to go beyond that and start being able to tackle problems that you haven't memorized or seen before, you need to try new ideas.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "ARC is not just meant to be this sort of measure of how close we are to AGI.",
        "clean_text": "ARC is not just meant to be this sort of measure of how close we are to AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "It's also meant to be a source of inspiration.",
        "clean_text": "It's also meant to be a source of inspiration.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "I want researchers to look at these puzzles and be like, \"hey, it's really strange that these puzzles are so simple and most humans can just do them very quickly.",
        "clean_text": "I want researchers to look at these puzzles and be like, \"hey, it's really strange that these puzzles are so simple and most humans can just do them very quickly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Why is it so hard for existing AI systems?",
        "clean_text": "Why is it so hard for existing AI systems?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Why is it so hard for LLMs and so on?\"",
        "clean_text": "Why is it so hard for LLMs and so on?\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "This is true for LLMs, but ARC was actually released before LLMs were really a thing.",
        "clean_text": "This is true for LLMs, but ARC was actually released before LLMs were really a thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "The only thing that made it special at the time was that it was designed to be resistant to memorization.",
        "clean_text": "The only thing that made it special at the time was that it was designed to be resistant to memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "The fact that it has survived LLMs so well, and [GenAI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence) in general, shows that it is actually resistant to memorization.",
        "clean_text": "The fact that it has survived LLMs so well, and GenAI in general, shows that it is actually resistant to memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 121,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:04:56",
    "content": "This is what nerd-sniped me. I went and took a bunch of the puzzles myself. I've shown it to all my friends and family too. They're all like, \"oh yeah, this is super easy. Are you sure AI can't solve this?\" That's the reaction and the same one for me as well. The more you dig in, you realize there's not just empirical evidence over the last four years that it's unbeaten, but there are theoretical concepts behind why. I completely agree at this point that new ideas are needed to beat ARC. There’s a lot of current trends in the world that are actually working against that happening. We’re actually less likely to generate new ideas right now. One of the trends is the closing up of frontier research, right? The GPT-4 paper from OpenAI had no technical detail shared. The Gemini paper had no technical detail shared, like the longer context part of that work. Yet that open innovation and progress and sharing is what got us to transformers in the first place. That's what got us to LLMs in the first place. So it's actually a little bit disappointing that so much frontier work has gone closed. It's really making a bet that these individual labs are going to be the ones to have the breakthrough and not the ecosystem. The internet and open source has shown that it's the most powerful innovation ecosystem that's ever existed, probably in the entire world.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThis is what [nerd-sniped](https://xkcd.com/356/) me.",
        "clean_text": "This is what nerd-sniped me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I went and took a bunch of the puzzles myself.",
        "clean_text": "I went and took a bunch of the puzzles myself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I've shown it to all my friends and family too.",
        "clean_text": "I've shown it to all my friends and family too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "They're all like, \"oh yeah, this is super easy.",
        "clean_text": "They're all like, \"oh yeah, this is super easy.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Are you sure AI can't solve this?\"",
        "clean_text": "Are you sure AI can't solve this?\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "That's the reaction and the same one for me as well.",
        "clean_text": "That's the reaction and the same one for me as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The more you dig in, you realize there's not just empirical evidence over the last four years that it's unbeaten, but there are theoretical concepts behind why.",
        "clean_text": "The more you dig in, you realize there's not just empirical evidence over the last four years that it's unbeaten, but there are theoretical concepts behind why.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "I completely agree at this point that new ideas are needed to beat ARC.",
        "clean_text": "I completely agree at this point that new ideas are needed to beat ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "There’s a lot of current trends in the world that are actually working against that happening.",
        "clean_text": "There’s a lot of current trends in the world that are actually working against that happening.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "We’re actually less likely to generate new ideas right now.",
        "clean_text": "We’re actually less likely to generate new ideas right now.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "One of the trends is the closing up of frontier research, right?",
        "clean_text": "One of the trends is the closing up of frontier research, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "The [GPT-4 paper](https://arxiv.org/abs/2303.08774) from OpenAI had no technical detail shared.",
        "clean_text": "The GPT-4 paper from OpenAI had no technical detail shared.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "The [Gemini paper](https://arxiv.org/abs/2403.05530) had no technical detail shared, like the [longer context](https://blog.google/technology/ai/long-context-window-ai-models/) part of that work.",
        "clean_text": "The Gemini paper had no technical detail shared, like the longer context part of that work.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Yet that open innovation and progress and sharing is what got us to [transformers in the first place](https://arxiv.org/abs/1706.03762).",
        "clean_text": "Yet that open innovation and progress and sharing is what got us to transformers in the first place.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "That's what got us to LLMs in the first place.",
        "clean_text": "That's what got us to LLMs in the first place.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "So it's actually a little bit disappointing that so much frontier work has gone closed.",
        "clean_text": "So it's actually a little bit disappointing that so much frontier work has gone closed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "It's really making a bet that these individual labs are going to be the ones to have the breakthrough and not the ecosystem.",
        "clean_text": "It's really making a bet that these individual labs are going to be the ones to have the breakthrough and not the ecosystem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "The internet and [open source](https://en.wikipedia.org/wiki/Open-source_artificial_intelligence) has shown that it's the most powerful innovation ecosystem that's ever existed, probably in the entire world.",
        "clean_text": "The internet and open source has shown that it's the most powerful innovation ecosystem that's ever existed, probably in the entire world.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 122,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:06:08",
    "content": "It's actually really sad that frontier research is no longer being published. If you look back four years ago, everything was just openly shared. All of the state-of-the-art results were published. This is no longer the case. OpenAI single-handedly changed the game. OpenAI basically set back progress towards AGI by quite a few years, probably like 5-10 years. That’s for two reasons. One is that they caused this complete closing down of frontier research publishing. But they also triggered this initial burst of hype around LLMs. Now LLMs have sucked the oxygen out of the room. Everyone is just doing LLMs. I see LLMs as more of an off-ramp on the path to AGI actually. All these new resources are actually going to LLMs instead of everything else they could be going to. If you look further into the past to like 2015 or 2016, there were like a thousand times fewer people doing AI back then. Yet the rate of progress was higher because people were exploring more directions. The world felt more open-ended. You could just go and try. You could have a cool idea of a launch, try it, and get some interesting results. There was this energy. Now everyone is very much doing some variation of the same thing. The big labs also tried their hand on ARC, but because they got bad results they didn't publish anything. People only publish positive results.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's actually really sad that frontier research is no longer being published.",
        "clean_text": "It's actually really sad that frontier research is no longer being published.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you look back four years ago, everything was just openly shared.",
        "clean_text": "If you look back four years ago, everything was just openly shared.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "All of the state-of-the-art results were published.",
        "clean_text": "All of the state-of-the-art results were published.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "This is no longer the case.",
        "clean_text": "This is no longer the case.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "OpenAI single-handedly changed the game.",
        "clean_text": "OpenAI single-handedly changed the game.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "OpenAI basically set back progress towards AGI by quite a few years, probably like 5-10 years.",
        "clean_text": "OpenAI basically set back progress towards AGI by quite a few years, probably like 5-10 years.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "That’s for two reasons.",
        "clean_text": "That’s for two reasons.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "One is that they caused this complete closing down of frontier research publishing.",
        "clean_text": "One is that they caused this complete closing down of frontier research publishing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "But they also triggered this initial burst of hype around LLMs.",
        "clean_text": "But they also triggered this initial burst of hype around LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Now LLMs have sucked the oxygen out of the room.",
        "clean_text": "Now LLMs have sucked the oxygen out of the room.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Everyone is just doing LLMs.",
        "clean_text": "Everyone is just doing LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "I see LLMs as more of an off-ramp on the path to AGI actually.",
        "clean_text": "I see LLMs as more of an off-ramp on the path to AGI actually.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "All these new resources are actually going to LLMs instead of everything else they could be going to.",
        "clean_text": "All these new resources are actually going to LLMs instead of everything else they could be going to.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "If you look further into the past to like 2015 or 2016, there were like a thousand times fewer people doing AI back then.",
        "clean_text": "If you look further into the past to like 2015 or 2016, there were like a thousand times fewer people doing AI back then.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "Yet the rate of progress was higher because people were exploring more directions.",
        "clean_text": "Yet the rate of progress was higher because people were exploring more directions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "The world felt more open-ended.",
        "clean_text": "The world felt more open-ended.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "You could just go and try.",
        "clean_text": "You could just go and try.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "You could have a cool idea of a launch, try it, and get some interesting results.",
        "clean_text": "You could have a cool idea of a launch, try it, and get some interesting results.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "There was this energy.",
        "clean_text": "There was this energy.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "Now everyone is very much doing some variation of the same thing.",
        "clean_text": "Now everyone is very much doing some variation of the same thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "The big labs also tried their hand on ARC, but because they got bad results they didn't publish anything.",
        "clean_text": "The big labs also tried their hand on ARC, but because they got bad results they didn't publish anything.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "People only publish positive results.",
        "clean_text": "People only publish positive results.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 123,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:07:55",
    "content": "I wonder how much effort people have put into trying to prompt or scaffold, do some Devin\\-type approach, into getting the frontier models to produce good solutions on ARC. I mean the frontier models of today, not just a year ago. A lot of post-training has gone into making them better. There’s Claude 3 Opus or GPT-4o. I hope that one of the things this episode does is get people to try out this open competition. They have to put in an open source model to compete, but we could also figure out if maybe the capability is latent in Claude and just see if you can show that. That would be super interesting.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI wonder how much effort people have put into trying to prompt or scaffold, do some [Devin](https://en.wikipedia.org/wiki/Devin_AI)\\-type approach, into getting the frontier models to produce good solutions on ARC.",
        "clean_text": "I wonder how much effort people have put into trying to prompt or scaffold, do some Devin\\-type approach, into getting the frontier models to produce good solutions on ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I mean the frontier models of today, not just a year ago.",
        "clean_text": "I mean the frontier models of today, not just a year ago.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "A lot of post-training has gone into making them better.",
        "clean_text": "A lot of post-training has gone into making them better.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There’s [Claude 3 Opus](https://www.anthropic.com/news/claude-3-family) or [GPT-4o](https://openai.com/index/hello-gpt-4o/).",
        "clean_text": "There’s Claude 3 Opus or GPT-4o.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I hope that one of the things this episode does is get people to try out this open competition.",
        "clean_text": "I hope that one of the things this episode does is get people to try out this open competition.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "They have to put in an open source model to compete, but we could also figure out if maybe the capability is latent in Claude and just see if you can show that.",
        "clean_text": "They have to put in an open source model to compete, but we could also figure out if maybe the capability is latent in Claude and just see if you can show that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "That would be super interesting.",
        "clean_text": "That would be super interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 124,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:08:37",
    "content": "Let's talk about the prize. How much do you win if you solve it? Let’s say you get whatever percent on ARC. How much do you get if you get the best submission but don't crack it?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet's talk about the prize.",
        "clean_text": "Let's talk about the prize.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "How much do you win if you solve it?",
        "clean_text": "How much do you win if you solve it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Let’s say you get whatever percent on ARC.",
        "clean_text": "Let’s say you get whatever percent on ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "How much do you get if you get the best submission but don't crack it?",
        "clean_text": "How much do you get if you get the best submission but don't crack it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 125,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:08:47",
    "content": "We have a little over a million dollars in the prize pool. We’re running the contest on an annual basis. We're starting today through the middle of November. The goal is to get 85%. That's the lower bound of the human average that you guys talked about earlier. There's a $500,000 prize for the first team that can get to the 85% benchmark. We don't expect that to happen this year. One of the early statisticians at Zapier gave me this line that has always stuck with me: \"the longer it takes, the longer it takes.\" My prior is that ARC is going to take years to solve. We're also going to break down and do a progress prize this year. There's a $100,000 progress prize which we will pay out to the top scores. $50,000 is going to go to the top objective scores this year on the Kaggle leaderboard. We're hosting it on Kaggle. We're then going to have a $50,000 pot set for the best paper that explains conceptually the scores that they were able to achieve. One of the interesting things is we're also going to be requiring that in order to win the prize money, you put the solution or your paper out into the public domain. Typically with contests, you see a lot of closed-up sharing. People are private and secret. They want to hold their alpha to themselves during the contest period. Because we expect it's going to be multiple years, we want an interactive game here. The plan is that at the end of November we will award the $100,000 prize money to the top progress prize. We’ll use the down time between December through February to share out all the knowledge from the top scores and the approaches folks were taking. That way we’ll re-baseline the community up to whatever the state of the art is and then run the contest again next year. We’ll keep doing that on a yearly basis until we get 85%.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe have a little over a million dollars in the prize pool.",
        "clean_text": "We have a little over a million dollars in the prize pool.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We’re running the contest on an annual basis.",
        "clean_text": "We’re running the contest on an annual basis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We're starting today through the middle of November.",
        "clean_text": "We're starting today through the middle of November.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "The goal is to get 85%.",
        "clean_text": "The goal is to get 85%.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "That's the lower bound of the human average that you guys talked about earlier.",
        "clean_text": "That's the lower bound of the human average that you guys talked about earlier.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "There's a $500,000 prize for the first team that can get to the 85% benchmark.",
        "clean_text": "There's a $500,000 prize for the first team that can get to the 85% benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "We don't expect that to happen this year.",
        "clean_text": "We don't expect that to happen this year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "One of the early statisticians at Zapier gave me this line that has always stuck with me: \"the longer it takes, the longer it takes.\"",
        "clean_text": "One of the early statisticians at Zapier gave me this line that has always stuck with me: \"the longer it takes, the longer it takes.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "My prior is that ARC is going to take years to solve.",
        "clean_text": "My prior is that ARC is going to take years to solve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "We're also going to break down and do a progress prize this year.",
        "clean_text": "We're also going to break down and do a progress prize this year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "There's a $100,000 progress prize which we will pay out to the top scores.",
        "clean_text": "There's a $100,000 progress prize which we will pay out to the top scores.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "$50,000 is going to go to the top objective scores this year on the Kaggle leaderboard.",
        "clean_text": "$50,000 is going to go to the top objective scores this year on the Kaggle leaderboard.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "We're hosting it on Kaggle.",
        "clean_text": "We're hosting it on Kaggle.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "We're then going to have a $50,000 pot set for the best paper that explains conceptually the scores that they were able to achieve.",
        "clean_text": "We're then going to have a $50,000 pot set for the best paper that explains conceptually the scores that they were able to achieve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "One of the interesting things is we're also going to be requiring that in order to win the prize money, you put the solution or your paper out into the public domain.",
        "clean_text": "One of the interesting things is we're also going to be requiring that in order to win the prize money, you put the solution or your paper out into the public domain.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "Typically with contests, you see a lot of closed-up sharing.",
        "clean_text": "Typically with contests, you see a lot of closed-up sharing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "People are private and secret.",
        "clean_text": "People are private and secret.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "They want to hold their alpha to themselves during the contest period.",
        "clean_text": "They want to hold their alpha to themselves during the contest period.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "Because we expect it's going to be multiple years, we want an interactive game here.",
        "clean_text": "Because we expect it's going to be multiple years, we want an interactive game here.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "The plan is that at the end of November we will award the $100,000 prize money to the top progress prize.",
        "clean_text": "The plan is that at the end of November we will award the $100,000 prize money to the top progress prize.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "We’ll use the down time between December through February to share out all the knowledge from the top scores and the approaches folks were taking.",
        "clean_text": "We’ll use the down time between December through February to share out all the knowledge from the top scores and the approaches folks were taking.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "That way we’ll re-baseline the community up to whatever the state of the art is and then run the contest again next year.",
        "clean_text": "That way we’ll re-baseline the community up to whatever the state of the art is and then run the contest again next year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "We’ll keep doing that on a yearly basis until we get 85%.",
        "clean_text": "We’ll keep doing that on a yearly basis until we get 85%.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 126,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:10:33",
    "content": "I'll give people some context on why I think this prize is very interesting. I was having conversations with my friends who are very much believers in models as they exist today. First of all, it was intriguing to me that they didn't know about ARC. These are experienced ML researchers. This happened a couple nights ago. We went to dinner and I showed them an example problem. They said, \"of course, an LLM would be able to solve something like this.\" We took a screenshot of it. We just put it into our ChatGPT app. It didn’t get the pattern. So it's very interesting. It is a notable fact. I was playing devil's advocate against you on these kinds of questions but this is a very intriguing fact. This prize is extremely interesting because we're going to learn something fascinating one way or another. With regards to the 85%, separate from this prize, I'd be very curious if somebody could replicate that result. Obviously in psychology and other kinds of fields, which this result seems to be analogous to, when you run tests on some small sample of people they're often hard to replicate. I'd be very curious to know, if you try to replicate this, how does the average human perform on ARC? I’m also curious about the difficulty of how long it will take to crack this benchmark. It's very interesting thinking of the other benchmarks that are now fully saturated, like MMLU and MATH. Dan Hendrycks and Collin Burns who did MMLU and MATH, they were grad students or college students when they made it. The goal when they made it just a couple of years ago was that it would be a test of AGI. Of course they got totally saturated. I know you'll argue that these are tests of memorization. But there’s been a pattern we’ve seen. In fact, Epoch AI has a very interesting graph where you see this almost exponential curve. It gets 5%, 10%, 30%, 40% as you increase the compute across models, and then it just shoots up. In the GPT-4 technical report, they had this interesting graph of the HumanEval problem set, which was 22 coding problems. They had to graph it on the mean log pass curve. Early on in training, or even with smaller models, they can have the right idea of how to solve this problem. It takes a lot of reliability to make sure they stay on track to solve the whole problem. You really want to upweight the signal where they get it right at least some of the time, maybe 1/100 or 1/1000. They go from 1/1000 to 1/100 and 1/10 and then they just totally saturate it. Here’s the question this is all leading up to. Why won't the same thing happen with ARC? People had to try really hard with bigger models. Now they figured out these techniques like the ones Jack Cole has figured out that can get 35% with only a 240 million parameter language model. Shouldn't we see the same pattern we saw across all these other benchmarks? You just eke out and then once you get the general idea, you just go all the way to a hundred?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'll give people some context on why I think this prize is very interesting.",
        "clean_text": "I'll give people some context on why I think this prize is very interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I was having conversations with my friends who are very much believers in models as they exist today.",
        "clean_text": "I was having conversations with my friends who are very much believers in models as they exist today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "First of all, it was intriguing to me that they didn't know about ARC.",
        "clean_text": "First of all, it was intriguing to me that they didn't know about ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "These are experienced ML researchers.",
        "clean_text": "These are experienced ML researchers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "This happened a couple nights ago.",
        "clean_text": "This happened a couple nights ago.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "We went to dinner and I showed them an example problem.",
        "clean_text": "We went to dinner and I showed them an example problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "They said, \"of course, an LLM would be able to solve something like this.\"",
        "clean_text": "They said, \"of course, an LLM would be able to solve something like this.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "We took a screenshot of it.",
        "clean_text": "We took a screenshot of it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "We just put it into our ChatGPT app.",
        "clean_text": "We just put it into our ChatGPT app.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "It didn’t get the pattern.",
        "clean_text": "It didn’t get the pattern.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "So it's very interesting.",
        "clean_text": "So it's very interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "It is a notable fact.",
        "clean_text": "It is a notable fact.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "I was playing devil's advocate against you on these kinds of questions but this is a very intriguing fact.",
        "clean_text": "I was playing devil's advocate against you on these kinds of questions but this is a very intriguing fact.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "This prize is extremely interesting because we're going to learn something fascinating one way or another.",
        "clean_text": "This prize is extremely interesting because we're going to learn something fascinating one way or another.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "With regards to the 85%, separate from this prize, I'd be very curious if somebody could replicate that result.",
        "clean_text": "With regards to the 85%, separate from this prize, I'd be very curious if somebody could replicate that result.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "Obviously in psychology and other kinds of fields, which this result seems to be analogous to, when you run tests on some small sample of people they're often hard to replicate.",
        "clean_text": "Obviously in psychology and other kinds of fields, which this result seems to be analogous to, when you run tests on some small sample of people they're often hard to replicate.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "I'd be very curious to know, if you try to replicate this, how does the average human perform on ARC?",
        "clean_text": "I'd be very curious to know, if you try to replicate this, how does the average human perform on ARC?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "I’m also curious about the difficulty of how long it will take to crack this benchmark.",
        "clean_text": "I’m also curious about the difficulty of how long it will take to crack this benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "It's very interesting thinking of the other benchmarks that are now fully saturated, like MMLU and [MATH](https://arxiv.org/abs/2103.03874).",
        "clean_text": "It's very interesting thinking of the other benchmarks that are now fully saturated, like MMLU and MATH.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "[Dan Hendrycks](https://people.eecs.berkeley.edu/~hendrycks/) and [Collin Burns](https://collinpburns.com/) who did MMLU and MATH, they were grad students or college students when they made it.",
        "clean_text": "Dan Hendrycks and Collin Burns who did MMLU and MATH, they were grad students or college students when they made it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "The goal when they made it just a couple of years ago was that it would be a test of AGI.",
        "clean_text": "The goal when they made it just a couple of years ago was that it would be a test of AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "Of course they got totally saturated.",
        "clean_text": "Of course they got totally saturated.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "I know you'll argue that these are tests of memorization.",
        "clean_text": "I know you'll argue that these are tests of memorization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "But there’s been a pattern we’ve seen.",
        "clean_text": "But there’s been a pattern we’ve seen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "In fact, Epoch AI has a [very interesting graph](https://epochai.org/blog/how-predictable-is-language-model-benchmark-performance) where you see this almost exponential curve.",
        "clean_text": "In fact, Epoch AI has a very interesting graph where you see this almost exponential curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "It gets 5%, 10%, 30%, 40% as you increase the compute across models, and then it just shoots up.",
        "clean_text": "It gets 5%, 10%, 30%, 40% as you increase the compute across models, and then it just shoots up.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "In the [GPT-4 technical report](https://arxiv.org/pdf/2303.08774), they had this interesting graph of the [HumanEval](https://arxiv.org/abs/2107.03374) problem set, which was 22 coding problems.",
        "clean_text": "In the GPT-4 technical report, they had this interesting graph of the HumanEval problem set, which was 22 coding problems.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "They had to graph it on the mean log pass curve.",
        "clean_text": "They had to graph it on the mean log pass curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "Early on in training, or even with smaller models, they can have the right idea of how to solve this problem.",
        "clean_text": "Early on in training, or even with smaller models, they can have the right idea of how to solve this problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "It takes a lot of reliability to make sure they stay on track to solve the whole problem.",
        "clean_text": "It takes a lot of reliability to make sure they stay on track to solve the whole problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 30,
        "original_text": "You really want to upweight the signal where they get it right at least some of the time, maybe 1/100 or 1/1000.",
        "clean_text": "You really want to upweight the signal where they get it right at least some of the time, maybe 1/100 or 1/1000.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 31,
        "original_text": "They go from 1/1000 to 1/100 and 1/10 and then they just totally saturate it.",
        "clean_text": "They go from 1/1000 to 1/100 and 1/10 and then they just totally saturate it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 32,
        "original_text": "Here’s the question this is all leading up to.",
        "clean_text": "Here’s the question this is all leading up to.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 33,
        "original_text": "Why won't the same thing happen with ARC?",
        "clean_text": "Why won't the same thing happen with ARC?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 34,
        "original_text": "People had to try really hard with bigger models.",
        "clean_text": "People had to try really hard with bigger models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 35,
        "original_text": "Now they figured out these techniques like the ones Jack Cole has figured out that can get 35% with only a 240 million parameter language model.",
        "clean_text": "Now they figured out these techniques like the ones Jack Cole has figured out that can get 35% with only a 240 million parameter language model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 36,
        "original_text": "Shouldn't we see the same pattern we saw across all these other benchmarks?",
        "clean_text": "Shouldn't we see the same pattern we saw across all these other benchmarks?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 37,
        "original_text": "You just eke out and then once you get the general idea, you just go all the way to a hundred?",
        "clean_text": "You just eke out and then once you get the general idea, you just go all the way to a hundred?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 127,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:13:27",
    "content": "That's an empirical question. We'll see in practice what happens. What Jack Cole is doing is actually very unique. It's not just pre-training an LLM and then prompting it. He's actually trying to do active inference.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's an empirical question.",
        "clean_text": "That's an empirical question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We'll see in practice what happens.",
        "clean_text": "We'll see in practice what happens.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "What Jack Cole is doing is actually very unique.",
        "clean_text": "What Jack Cole is doing is actually very unique.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's not just pre-training an LLM and then prompting it.",
        "clean_text": "It's not just pre-training an LLM and then prompting it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "He's actually trying to do active inference.",
        "clean_text": "He's actually trying to do active inference.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 128,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:13:40",
    "content": "He's doing test-time, right? He's doing test-time fine-tuning.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nHe's doing test-time, right?",
        "clean_text": "He's doing test-time, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "He's doing test-time fine-tuning.",
        "clean_text": "He's doing test-time fine-tuning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 129,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:13:42",
    "content": "Exactly, he’s doing test-time fine-tuning. This is actually trying to lift one of the key limitations of LLMs. At inference time, they cannot learn anything new. They cannot adapt on the fly to what they're seeing. He's actually trying to learn. What he's doing is effectively a form of program synthesis. LLMs contain a lot of useful building blocks, programming building blocks. By fine-tuning it on the task at test time, you are trying to assemble these building blocks into the right pattern that matches the task. This is exactly what program synthesis is about. I would contrast this approach with discrete program search. In discrete program search, you're trying to assemble a program from a set of primitives. You have very few primitives. For instance, people working on discrete program search on ARC tend to work with DSLs that have 100 to 200 primitive programs. It’s a very small DSL but they're trying to combine these primitives into very complex programs. There's a very deep depth of search. On the other hand, is what Jack Cole is doing with LLMs. He's got this vector program database DSL of millions of building blocks in the LLM. They’re mined by pre-training the LLM, not just on a ton of programming problems, but also on millions of generated ARC-like tasks. You have an extraordinarily large DSL and the fine-tuning is very shallow recombination of these primitives. Discrete program search is very deep recombination with a very small set of primitive programs. The LLM approach is the same but on the complete opposite end of that spectrum. You scale up the memorization by a massive factor and you're doing very shallow search. They are the same thing, just different ends of the spectrum. I think where you're going to get the most value for your compute cycles is somewhere in between. You want to leverage memorization to build up a richer, more useful bank of primitive programs. You don't want them to be hard-coded like what we saw for the typical RTS. You want them to be learned from examples. You also want to do some degree of deep search. As long as you're only doing very shallow search, you are limited to local generalization. If you want to generalize further and more broadly, depth of search is going to be critical.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nExactly, he’s doing test-time fine-tuning.",
        "clean_text": "Exactly, he’s doing test-time fine-tuning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "This is actually trying to lift one of the key limitations of LLMs.",
        "clean_text": "This is actually trying to lift one of the key limitations of LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "At inference time, they cannot learn anything new.",
        "clean_text": "At inference time, they cannot learn anything new.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "They cannot adapt on the fly to what they're seeing.",
        "clean_text": "They cannot adapt on the fly to what they're seeing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "He's actually trying to learn.",
        "clean_text": "He's actually trying to learn.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "What he's doing is effectively a form of program synthesis.",
        "clean_text": "What he's doing is effectively a form of program synthesis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "LLMs contain a lot of useful building blocks, programming building blocks.",
        "clean_text": "LLMs contain a lot of useful building blocks, programming building blocks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "By fine-tuning it on the task at test time, you are trying to assemble these building blocks into the right pattern that matches the task.",
        "clean_text": "By fine-tuning it on the task at test time, you are trying to assemble these building blocks into the right pattern that matches the task.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "This is exactly what program synthesis is about.",
        "clean_text": "This is exactly what program synthesis is about.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I would contrast this approach with discrete program search.",
        "clean_text": "I would contrast this approach with discrete program search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "In discrete program search, you're trying to assemble a program from a set of primitives.",
        "clean_text": "In discrete program search, you're trying to assemble a program from a set of primitives.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "You have very few primitives.",
        "clean_text": "You have very few primitives.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "For instance, people working on discrete program search on ARC tend to work with [DSLs](https://en.wikipedia.org/wiki/Domain-specific_language) that have 100 to 200 primitive programs.",
        "clean_text": "For instance, people working on discrete program search on ARC tend to work with DSLs that have 100 to 200 primitive programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "It’s a very small DSL but they're trying to combine these primitives into very complex programs.",
        "clean_text": "It’s a very small DSL but they're trying to combine these primitives into very complex programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "There's a very deep depth of search.",
        "clean_text": "There's a very deep depth of search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "On the other hand, is what Jack Cole is doing with LLMs.",
        "clean_text": "On the other hand, is what Jack Cole is doing with LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "He's got this vector program database DSL of millions of building blocks in the LLM.",
        "clean_text": "He's got this vector program database DSL of millions of building blocks in the LLM.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "They’re mined by pre-training the LLM, not just on a ton of programming problems, but also on millions of generated ARC-like tasks.",
        "clean_text": "They’re mined by pre-training the LLM, not just on a ton of programming problems, but also on millions of generated ARC-like tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "You have an extraordinarily large DSL and the fine-tuning is very shallow recombination of these primitives.",
        "clean_text": "You have an extraordinarily large DSL and the fine-tuning is very shallow recombination of these primitives.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "Discrete program search is very deep recombination with a very small set of primitive programs.",
        "clean_text": "Discrete program search is very deep recombination with a very small set of primitive programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "The LLM approach is the same but on the complete opposite end of that spectrum.",
        "clean_text": "The LLM approach is the same but on the complete opposite end of that spectrum.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "You scale up the memorization by a massive factor and you're doing very shallow search.",
        "clean_text": "You scale up the memorization by a massive factor and you're doing very shallow search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "They are the same thing, just different ends of the spectrum.",
        "clean_text": "They are the same thing, just different ends of the spectrum.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "I think where you're going to get the most value for your compute cycles is somewhere in between.",
        "clean_text": "I think where you're going to get the most value for your compute cycles is somewhere in between.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "You want to leverage memorization to build up a richer, more useful bank of primitive programs.",
        "clean_text": "You want to leverage memorization to build up a richer, more useful bank of primitive programs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "You don't want them to be hard-coded like what we saw for the typical RTS.",
        "clean_text": "You don't want them to be hard-coded like what we saw for the typical RTS.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "You want them to be learned from examples.",
        "clean_text": "You want them to be learned from examples.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "You also want to do some degree of deep search.",
        "clean_text": "You also want to do some degree of deep search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "As long as you're only doing very shallow search, you are limited to local generalization.",
        "clean_text": "As long as you're only doing very shallow search, you are limited to local generalization.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "If you want to generalize further and more broadly, depth of search is going to be critical.",
        "clean_text": "If you want to generalize further and more broadly, depth of search is going to be critical.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 130,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:16:26",
    "content": "I might argue that the reason that he had to rely so heavily on the synthetic data was because he used a 240 million parameter model. The Kaggle competition at the time required him to use a P100 GPU which has like a tenth or something of the flops of an H100. For context for the listeners, the frontier models today are literally a thousand times bigger than that. For your competition, submissions can't make any API calls, can't go online, and have to run on NVIDIA Tesla P100. It's significantly less powerful.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI might argue that the reason that he had to rely so heavily on the synthetic data was because he used a 240 million parameter model.",
        "clean_text": "I might argue that the reason that he had to rely so heavily on the synthetic data was because he used a 240 million parameter model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The Kaggle competition at the time required him to use a [P100 GPU](https://www.nvidia.com/en-us/data-center/tesla-p100/) which has like a tenth or something of the flops of an [H100](https://www.nvidia.com/en-us/data-center/h100/).",
        "clean_text": "The Kaggle competition at the time required him to use a P100 GPU which has like a tenth or something of the flops of an H100.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "For context for the listeners, the frontier models today are literally a thousand times bigger than that.",
        "clean_text": "For context for the listeners, the frontier models today are literally a thousand times bigger than that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "For your competition, submissions can't make any API calls, can't go online, and have to run on NVIDIA Tesla P100.",
        "clean_text": "For your competition, submissions can't make any API calls, can't go online, and have to run on NVIDIA Tesla P100.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It's significantly less powerful.",
        "clean_text": "It's significantly less powerful.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 131,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:17:20",
    "content": "There's basically a 12 hour runtime limit. There's a forcing function of efficiency in the eval.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere's basically a 12 hour runtime limit.",
        "clean_text": "There's basically a 12 hour runtime limit.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There's a forcing function of efficiency in the eval.",
        "clean_text": "There's a forcing function of efficiency in the eval.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 132,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:17:24",
    "content": "But here's the thing, you only have 100 test tasks. The amount of computing available for each task is actually quite a bit, especially if you contrast that with the simplicity of each task.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut here's the thing, you only have 100 test tasks.",
        "clean_text": "But here's the thing, you only have 100 test tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The amount of computing available for each task is actually quite a bit, especially if you contrast that with the simplicity of each task.",
        "clean_text": "The amount of computing available for each task is actually quite a bit, especially if you contrast that with the simplicity of each task.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 133,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:17:35",
    "content": "Basically, it would be 7 minutes per task. People who have tried to do these estimates of how many flops does a human brain have. You can take them with a grain of salt but as a sort of anchor, it's basically the amount of flops an H100 has. Maybe you would argue that a human brain can solve this question in faster than 7.2 minutes. Even with a tenth of the compute, you should be able to do it in seven minutes. Obviously we have less than petabytes of fast access memory in the brain and these 29 GB or whatever in the H100.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBasically, it would be 7 minutes per task.",
        "clean_text": "Basically, it would be 7 minutes per task.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "People who have tried to do these estimates of how many flops does a human brain have.",
        "clean_text": "People who have tried to do these estimates of how many flops does a human brain have.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You can take them with a grain of salt but as a sort of anchor, it's basically the amount of flops an H100 has.",
        "clean_text": "You can take them with a grain of salt but as a sort of anchor, it's basically the amount of flops an H100 has.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Maybe you would argue that a human brain can solve this question in faster than 7.2 minutes.",
        "clean_text": "Maybe you would argue that a human brain can solve this question in faster than 7.2 minutes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Even with a tenth of the compute, you should be able to do it in seven minutes.",
        "clean_text": "Even with a tenth of the compute, you should be able to do it in seven minutes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Obviously we have less than petabytes of fast access memory in the brain and these 29 GB or whatever in the H100.",
        "clean_text": "Obviously we have less than petabytes of fast access memory in the brain and these 29 GB or whatever in the H100.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 134,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:18:08",
    "content": "The broader point is that I wish there were a way to also test this prize with some sort of scaffolding on the biggest models, as a way to test whether scaling is the path to solving ARC.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThe broader point is that I wish there were a way to also test this prize with some sort of scaffolding on the biggest models, as a way to test whether scaling is the path to solving ARC.",
        "clean_text": "The broader point is that I wish there were a way to also test this prize with some sort of scaffolding on the biggest models, as a way to test whether scaling is the path to solving ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 135,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:18:26",
    "content": "Absolutely. In the context of the competition, we want to see how much progress we can do with limited resources. But you're entirely right that it's a super interesting open question, what could the biggest model out there actually do on ARC? We actually also want to make available a private, one-off track where you can submit to us a VM. You can put on it any model you want. You can take one of the largest open source models out there, fine-tune it, do whatever you want, and just give us an image. Then we run it on the H100 for 24 hours or something. You see what you get.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAbsolutely.",
        "clean_text": "Absolutely.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "In the context of the competition, we want to see how much progress we can do with limited resources.",
        "clean_text": "In the context of the competition, we want to see how much progress we can do with limited resources.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "But you're entirely right that it's a super interesting open question, what could the biggest model out there actually do on ARC?",
        "clean_text": "But you're entirely right that it's a super interesting open question, what could the biggest model out there actually do on ARC?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We actually also want to make available a private, one-off track where you can submit to us a [VM](https://en.wikipedia.org/wiki/Virtual_machine).",
        "clean_text": "We actually also want to make available a private, one-off track where you can submit to us a VM.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You can put on it any model you want.",
        "clean_text": "You can put on it any model you want.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "You can take one of the largest open source models out there, fine-tune it, do whatever you want, and just give us an image.",
        "clean_text": "You can take one of the largest open source models out there, fine-tune it, do whatever you want, and just give us an image.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Then we run it on the H100 for 24 hours or something.",
        "clean_text": "Then we run it on the H100 for 24 hours or something.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You see what you get.",
        "clean_text": "You see what you get.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 136,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:19:03",
    "content": "It's worth pointing out that there's two different test sets. There is a public test set that's in the public GitHub repository that anyone can use to train. You can put in an open API call, whatever you'd like to do. Then there's the private test set, which is the hundred that is actually measuring the state of the art. It is pretty open-ended and interesting to have folks at least attempt to use the public test set and go try it. Now there is an asterisk on any score that's reported on against the public test set because it is public. It could have leaked into the training data somewhere.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's worth pointing out that there's two different test sets.",
        "clean_text": "It's worth pointing out that there's two different test sets.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There is a public test set that's in the public GitHub repository that anyone can use to train.",
        "clean_text": "There is a public test set that's in the public GitHub repository that anyone can use to train.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You can put in an open API call, whatever you'd like to do.",
        "clean_text": "You can put in an open API call, whatever you'd like to do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Then there's the private test set, which is the hundred that is actually measuring the state of the art.",
        "clean_text": "Then there's the private test set, which is the hundred that is actually measuring the state of the art.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It is pretty open-ended and interesting to have folks at least attempt to use the public test set and go try it.",
        "clean_text": "It is pretty open-ended and interesting to have folks at least attempt to use the public test set and go try it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Now there is an asterisk on any score that's reported on against the public test set because it is public.",
        "clean_text": "Now there is an asterisk on any score that's reported on against the public test set because it is public.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "It could have leaked into the training data somewhere.",
        "clean_text": "It could have leaked into the training data somewhere.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 137,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:19:32",
    "content": "This is actually what people are already doing. You can already try to prompt one of the best models, like the latest Gemini or the latest GPT-4, with tasks from the public evaluation set. Again, the problem is that these tasks are available as JSON files on GitHub. These models are also trained on GitHub. So they're actually trained on these tasks. That kind of creates uncertainty. If they can actually solve some of the tasks, is that because they memorized the answer or not? Maybe you would be better off trying to create your own private, ARC-like very novel test set. Don't make the tasks difficult. Don't make them complex. Make them very obvious for humans, but make sure to make them original as much as possible. Make them unique, different, and see how well your GPT-4 or GPT-5 does on them.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThis is actually what people are already doing.",
        "clean_text": "This is actually what people are already doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You can already try to prompt one of the best models, like the latest Gemini or the latest GPT-4, with tasks from the public evaluation set.",
        "clean_text": "You can already try to prompt one of the best models, like the latest Gemini or the latest GPT-4, with tasks from the public evaluation set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Again, the problem is that these tasks are available as JSON files on GitHub.",
        "clean_text": "Again, the problem is that these tasks are available as JSON files on GitHub.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "These models are also trained on GitHub.",
        "clean_text": "These models are also trained on GitHub.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "So they're actually trained on these tasks.",
        "clean_text": "So they're actually trained on these tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "That kind of creates uncertainty.",
        "clean_text": "That kind of creates uncertainty.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "If they can actually solve some of the tasks, is that because they memorized the answer or not?",
        "clean_text": "If they can actually solve some of the tasks, is that because they memorized the answer or not?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Maybe you would be better off trying to create your own private, ARC-like very novel test set.",
        "clean_text": "Maybe you would be better off trying to create your own private, ARC-like very novel test set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Don't make the tasks difficult.",
        "clean_text": "Don't make the tasks difficult.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Don't make them complex.",
        "clean_text": "Don't make them complex.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Make them very obvious for humans, but make sure to make them original as much as possible.",
        "clean_text": "Make them very obvious for humans, but make sure to make them original as much as possible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "Make them unique, different, and see how well your GPT-4 or GPT-5 does on them.",
        "clean_text": "Make them unique, different, and see how well your GPT-4 or GPT-5 does on them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 138,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:20:25",
    "content": "There have been tests on whether these models are being overtrained on these benchmarks. Scale recently did this with GSM8K. They basically replicated the benchmark, but with different questions. Some of the models actually were extremely overfit on the benchmark, like Mistral and so forth. Frontier models like Claude and GPT actually did as well on their novel benchmark as they did on the specific questions that were in the existing public benchmark. I would be relatively optimistic about them just training on the JSON. I was joking with Mike that you should allow API access but keep an even more private validation set of these ARC questions. So you allow API access and people can play with GPT-4 scaffolding to enter into this contest. Maybe later on you run the validation set on the API. If it performs worse than the test set that you originally allowed the API to access, that means that OpenAI is training on your API calls. You go public with this and show them like, \"oh my god, they've leaked your data.\"",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere have been tests on whether these models are being overtrained on these benchmarks.",
        "clean_text": "There have been tests on whether these models are being overtrained on these benchmarks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "[Scale recently did this with GSM8K](https://arxiv.org/html/2405.00332v1).",
        "clean_text": "Scale recently did this with GSM8K.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They basically replicated the benchmark, but with different questions.",
        "clean_text": "They basically replicated the benchmark, but with different questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Some of the models actually were extremely overfit on the benchmark, like [Mistral](https://en.wikipedia.org/wiki/Mistral_AI) and so forth.",
        "clean_text": "Some of the models actually were extremely overfit on the benchmark, like Mistral and so forth.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Frontier models like Claude and GPT actually did as well on their novel benchmark as they did on the specific questions that were in the existing public benchmark.",
        "clean_text": "Frontier models like Claude and GPT actually did as well on their novel benchmark as they did on the specific questions that were in the existing public benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I would be relatively optimistic about them just training on the JSON.",
        "clean_text": "I would be relatively optimistic about them just training on the JSON.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I was joking with Mike that you should allow API access but keep an even more private validation set of these ARC questions.",
        "clean_text": "I was joking with Mike that you should allow API access but keep an even more private validation set of these ARC questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "So you allow API access and people can play with GPT-4 scaffolding to enter into this contest.",
        "clean_text": "So you allow API access and people can play with GPT-4 scaffolding to enter into this contest.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Maybe later on you run the validation set on the API.",
        "clean_text": "Maybe later on you run the validation set on the API.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "If it performs worse than the test set that you originally allowed the API to access, that means that OpenAI is training on your API calls.",
        "clean_text": "If it performs worse than the test set that you originally allowed the API to access, that means that OpenAI is training on your API calls.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You go public with this and show them like, \"oh my god, they've leaked your data.\"",
        "clean_text": "You go public with this and show them like, \"oh my god, they've leaked your data.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 139,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:21:31",
    "content": "We do want to evolve the ARC dataset. That is a goal that we want to do. François mentioned that it's not perfect.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe do want to evolve the ARC dataset.",
        "clean_text": "We do want to evolve the ARC dataset.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "That is a goal that we want to do.",
        "clean_text": "That is a goal that we want to do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "François mentioned that it's not perfect.",
        "clean_text": "François mentioned that it's not perfect.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 140,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:21:38",
    "content": "Yeah, ARC is not a perfect benchmark. I made it over four years ago, almost five now. This was in a time before LLMs. We’ve actually learned a lot since about what potential flaws there might be. There is some redundancy in the set of tasks, which is of course against the goals of the benchmark. Every task is supposed to be unique in practice. That's not quite true. Every task is also supposed to be very novel, but in practice, they might not be. They might be structurally similar to something that you might find online somewhere. So we want to keep iterating and release an ARC 2.0 version later this year. When we do that, we're going to want to make the old private test set available. Maybe we won't be releasing it publicly, but what we could do is just create a test server where you can query, get a task, and submit a solution. Of course you can use whatever frontier model you want there. Because you actually have to query this API, you're making sure that no one is going to accidentally train on this data. It's unlike the current public ARC data, which is literally on GitHub. There's actually no question about whether the models are trained on it. They are because they train on GitHub. By gating access to requiring this API, we would avoid this issue. For people who want to try whatever technique they have in mind, using whatever resources they want, that would be a way for them to get an answer.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYeah, ARC is not a perfect benchmark.",
        "clean_text": "Yeah, ARC is not a perfect benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I made it over four years ago, almost five now.",
        "clean_text": "I made it over four years ago, almost five now.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This was in a time before LLMs.",
        "clean_text": "This was in a time before LLMs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We’ve actually learned a lot since about what potential flaws there might be.",
        "clean_text": "We’ve actually learned a lot since about what potential flaws there might be.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "There is some redundancy in the set of tasks, which is of course against the goals of the benchmark.",
        "clean_text": "There is some redundancy in the set of tasks, which is of course against the goals of the benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Every task is supposed to be unique in practice.",
        "clean_text": "Every task is supposed to be unique in practice.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "That's not quite true.",
        "clean_text": "That's not quite true.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Every task is also supposed to be very novel, but in practice, they might not be.",
        "clean_text": "Every task is also supposed to be very novel, but in practice, they might not be.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "They might be structurally similar to something that you might find online somewhere.",
        "clean_text": "They might be structurally similar to something that you might find online somewhere.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "So we want to keep iterating and release an ARC 2.0 version later this year.",
        "clean_text": "So we want to keep iterating and release an ARC 2.0 version later this year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "When we do that, we're going to want to make the old private test set available.",
        "clean_text": "When we do that, we're going to want to make the old private test set available.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "Maybe we won't be releasing it publicly, but what we could do is just create a test server where you can query, get a task, and submit a solution.",
        "clean_text": "Maybe we won't be releasing it publicly, but what we could do is just create a test server where you can query, get a task, and submit a solution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Of course you can use whatever frontier model you want there.",
        "clean_text": "Of course you can use whatever frontier model you want there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Because you actually have to query this API, you're making sure that no one is going to accidentally train on this data.",
        "clean_text": "Because you actually have to query this API, you're making sure that no one is going to accidentally train on this data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "It's unlike the current public ARC data, which is literally on GitHub.",
        "clean_text": "It's unlike the current public ARC data, which is literally on GitHub.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "There's actually no question about whether the models are trained on it.",
        "clean_text": "There's actually no question about whether the models are trained on it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "They are because they train on GitHub.",
        "clean_text": "They are because they train on GitHub.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "By gating access to requiring this API, we would avoid this issue.",
        "clean_text": "By gating access to requiring this API, we would avoid this issue.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "For people who want to try whatever technique they have in mind, using whatever resources they want, that would be a way for them to get an answer.",
        "clean_text": "For people who want to try whatever technique they have in mind, using whatever resources they want, that would be a way for them to get an answer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 141,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:23:11",
    "content": "I wonder what might happen. I'm not sure. One answer is that they come up with a whole new algorithm for AI with some explicit program synthesis. Now we're on a new track. Another is that they did something hacky with the existing models in a way that actually is valid, which reveals that maybe intelligence is more of getting things to the right part of the distribution. Then it can reason. In that world, that will be interesting. Maybe that'll indicate that you had to do something hacky with current models. As they get better you won't have to do something hacky. I'm also going to be very curious to see if these multimodal models will natively perform much better at ARC-like tests.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI wonder what might happen.",
        "clean_text": "I wonder what might happen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm not sure.",
        "clean_text": "I'm not sure.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One answer is that they come up with a whole new algorithm for AI with some explicit program synthesis.",
        "clean_text": "One answer is that they come up with a whole new algorithm for AI with some explicit program synthesis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Now we're on a new track.",
        "clean_text": "Now we're on a new track.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Another is that they did something hacky with the existing models in a way that actually is valid, which reveals that maybe intelligence is more of getting things to the right part of the distribution.",
        "clean_text": "Another is that they did something hacky with the existing models in a way that actually is valid, which reveals that maybe intelligence is more of getting things to the right part of the distribution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Then it can reason.",
        "clean_text": "Then it can reason.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "In that world, that will be interesting.",
        "clean_text": "In that world, that will be interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Maybe that'll indicate that you had to do something hacky with current models.",
        "clean_text": "Maybe that'll indicate that you had to do something hacky with current models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "As they get better you won't have to do something hacky.",
        "clean_text": "As they get better you won't have to do something hacky.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I'm also going to be very curious to see if these multimodal models will natively perform much better at ARC-like tests.",
        "clean_text": "I'm also going to be very curious to see if these multimodal models will natively perform much better at ARC-like tests.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 142,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:23:51",
    "content": "If ARC survives three months from here, we'll up the prize. We're about to make a really important moment of contact with reality by blowing up the prize, putting a much bigger prize pool against it. We're going to learn really quickly if there's a lot of low-hanging fruit ideas. Again, I think new ideas are needed. Anyone listening might have the idea in their head. I'd encourage everyone to give it a try. As time goes on, that adds strength to the argument that we've stalled out in progress and that new ideas are necessary to beat ARC.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf ARC survives three months from here, we'll up the prize.",
        "clean_text": "If ARC survives three months from here, we'll up the prize.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We're about to make a really important moment of contact with reality by blowing up the prize, putting a much bigger prize pool against it.",
        "clean_text": "We're about to make a really important moment of contact with reality by blowing up the prize, putting a much bigger prize pool against it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We're going to learn really quickly if there's a lot of low-hanging fruit ideas.",
        "clean_text": "We're going to learn really quickly if there's a lot of low-hanging fruit ideas.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Again, I think new ideas are needed.",
        "clean_text": "Again, I think new ideas are needed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Anyone listening might have the idea in their head.",
        "clean_text": "Anyone listening might have the idea in their head.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I'd encourage everyone to give it a try.",
        "clean_text": "I'd encourage everyone to give it a try.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "As time goes on, that adds strength to the argument that we've stalled out in progress and that new ideas are necessary to beat ARC.",
        "clean_text": "As time goes on, that adds strength to the argument that we've stalled out in progress and that new ideas are necessary to beat ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 143,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:24:19",
    "content": "Yeah, that's the point of having a money prize. You attract more people and you get them to try to solve it. If there's an easy way to hack the benchmark, that reveals that the benchmark is flawed. You’re going to know about it. In fact, that was the point of the original Kaggle competition for ARC back in 2020. I was running this competition because I had released this dataset and I wanted to know if it was hackable, if you could cheat. There was a small money prize at the time. It was like $20K. This was right around the same time as GPT-3 was released. People of course tried GPT-3 on the public data. It scored zero. What the first contest taught us is that there is no obvious shortcut. Now there's more money. There's going to be more people looking into it. We're going to find out. We're going to see if the benchmark is going to survive. Let’s say we end up with a solution that is not like trying to brute force the space of possible ARC tasks. It’s just trained on core knowledge. I don't think it's necessarily going to be in and of itself AGI, but it's probably going to be a huge milestone on the way to AGI. What it represents is the ability to synthesize a problem-solving program from just two or three examples. That alone is a new way to program. It's an entirely new paradigm for software development. You can start programming potentially quite complex programs that will generalize very well. Instead of programming them by coming up with the shape of the program in your mind and then typing it up, you're actually just showing the computer what output you want. You let the computer figure it out. That's what is extremely powerful.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYeah, that's the point of having a money prize.",
        "clean_text": "Yeah, that's the point of having a money prize.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You attract more people and you get them to try to solve it.",
        "clean_text": "You attract more people and you get them to try to solve it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If there's an easy way to hack the benchmark, that reveals that the benchmark is flawed.",
        "clean_text": "If there's an easy way to hack the benchmark, that reveals that the benchmark is flawed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You’re going to know about it.",
        "clean_text": "You’re going to know about it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "In fact, that was the point of the [original Kaggle competition](https://www.kaggle.com/c/abstraction-and-reasoning-challenge) for ARC back in 2020.",
        "clean_text": "In fact, that was the point of the original Kaggle competition for ARC back in 2020.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I was running this competition because I had released this dataset and I wanted to know if it was hackable, if you could cheat.",
        "clean_text": "I was running this competition because I had released this dataset and I wanted to know if it was hackable, if you could cheat.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There was a small money prize at the time.",
        "clean_text": "There was a small money prize at the time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It was like $20K.",
        "clean_text": "It was like $20K.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "This was right around the same time as GPT-3 was released.",
        "clean_text": "This was right around the same time as GPT-3 was released.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "People of course tried GPT-3 on the public data.",
        "clean_text": "People of course tried GPT-3 on the public data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "It scored zero.",
        "clean_text": "It scored zero.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "What the first contest taught us is that there is no obvious shortcut.",
        "clean_text": "What the first contest taught us is that there is no obvious shortcut.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Now there's more money.",
        "clean_text": "Now there's more money.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "There's going to be more people looking into it.",
        "clean_text": "There's going to be more people looking into it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "We're going to find out.",
        "clean_text": "We're going to find out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "We're going to see if the benchmark is going to survive.",
        "clean_text": "We're going to see if the benchmark is going to survive.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "Let’s say we end up with a solution that is not like trying to brute force the space of possible ARC tasks.",
        "clean_text": "Let’s say we end up with a solution that is not like trying to brute force the space of possible ARC tasks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "It’s just trained on core knowledge.",
        "clean_text": "It’s just trained on core knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "I don't think it's necessarily going to be in and of itself AGI, but it's probably going to be a huge milestone on the way to AGI.",
        "clean_text": "I don't think it's necessarily going to be in and of itself AGI, but it's probably going to be a huge milestone on the way to AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "What it represents is the ability to synthesize a problem-solving program from just two or three examples.",
        "clean_text": "What it represents is the ability to synthesize a problem-solving program from just two or three examples.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "That alone is a new way to program.",
        "clean_text": "That alone is a new way to program.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "It's an entirely new paradigm for software development.",
        "clean_text": "It's an entirely new paradigm for software development.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "You can start programming potentially quite complex programs that will generalize very well.",
        "clean_text": "You can start programming potentially quite complex programs that will generalize very well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "Instead of programming them by coming up with the shape of the program in your mind and then typing it up, you're actually just showing the computer what output you want.",
        "clean_text": "Instead of programming them by coming up with the shape of the program in your mind and then typing it up, you're actually just showing the computer what output you want.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "You let the computer figure it out.",
        "clean_text": "You let the computer figure it out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "That's what is extremely powerful.",
        "clean_text": "That's what is extremely powerful.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 144,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:26:19",
    "content": "I want to riff a little bit on what kinds of solutions might be possible here, and which you would consider defeating the purpose of ARC vs. which are valid. Here's one I'll mention. My friends Ryan and Buck stayed up last night because I told them about this. They were like, \"oh, of course LLMs can solve this.\"",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI want to riff a little bit on what kinds of solutions might be possible here, and which you would consider defeating the purpose of ARC vs.",
        "clean_text": "I want to riff a little bit on what kinds of solutions might be possible here, and which you would consider defeating the purpose of ARC vs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "which are valid.",
        "clean_text": "which are valid.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Here's one I'll mention.",
        "clean_text": "Here's one I'll mention.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "My friends Ryan and Buck stayed up last night because I told them about this.",
        "clean_text": "My friends Ryan and Buck stayed up last night because I told them about this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "They were like, \"oh, of course LLMs can solve this.\"",
        "clean_text": "They were like, \"oh, of course LLMs can solve this.\"",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 145,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:26:37",
    "content": "Good. Thank you for spreading the word.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nGood.",
        "clean_text": "Good.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Thank you for spreading the word.",
        "clean_text": "Thank you for spreading the word.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 146,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:26:39",
    "content": "They were trying to prompt Claude Opus on this and they say they got 25% on the public ARC test. What they did was have other examples of some of the ARC tests and in context explain the reasoning of why you went from one output to another output and now you have the current problem. I think there was also expressing the JSON in a way that is more amenable to the tokenizer. Another thing was using the code interpreter. Do you think the code interpreter, which keeps getting better as these models get smarter, is just the program synthesis right there? What they were able to do was get the actual output of the cells, that JSON output, through the code interpreter, like “write the Python program that gets the right output here.” Do you think that the program synthesis kind of research you're talking about will just look like using the code interpreter in large language models?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThey were trying to prompt Claude Opus on this and they say they got 25% on the public ARC test.",
        "clean_text": "They were trying to prompt Claude Opus on this and they say they got 25% on the public ARC test.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What they did was have other examples of some of the ARC tests and in context explain the reasoning of why you went from one output to another output and now you have the current problem.",
        "clean_text": "What they did was have other examples of some of the ARC tests and in context explain the reasoning of why you went from one output to another output and now you have the current problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I think there was also expressing the JSON in a way that is more amenable to the tokenizer.",
        "clean_text": "I think there was also expressing the JSON in a way that is more amenable to the tokenizer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Another thing was using the code interpreter.",
        "clean_text": "Another thing was using the code interpreter.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Do you think the code interpreter, which keeps getting better as these models get smarter, is just the program synthesis right there?",
        "clean_text": "Do you think the code interpreter, which keeps getting better as these models get smarter, is just the program synthesis right there?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "What they were able to do was get the actual output of the cells, that JSON output, through the code interpreter, like “write the Python program that gets the right output here.”\n\nDo you think that the program synthesis kind of research you're talking about will just look like using the code interpreter in large language models?",
        "clean_text": "What they were able to do was get the actual output of the cells, that JSON output, through the code interpreter, like “write the Python program that gets the right output here.” Do you think that the program synthesis kind of research you're talking about will just look like using the code interpreter in large language models?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 147,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:27:36",
    "content": "I think whatever solution we see that will score well is probably going to need to leverage some aspects from deep learning models and LLMs in particular. We've shown already that LLMs can do quite well. That's basically the Jack Cole approach. We've also shown that pure discrete program search from a small DSL does very well. Before Jack Cole, this was the state of the art. In fact, it's still extremely close to the state of the art and there's no deep learning involved at all in these models. We have two approaches that have basically no overlap, that are doing quite well. They're very much at two opposite ends of one spectrum. On one end, you have these extremely large banks of millions of vector programs, but very shallow recombination, simplistic recombination. On the other end, you have very simplistic DSLs, 100-200 primitives, but very deep, very sophisticated program search. The solution is going to be somewhere in between. The people who are going to be winning the ARC competition and making the most progress towards near-term AGI are going to be those that manage to merge the deep learning paradigm and the discrete program search paradigm into one elegant way. You asked what would be legitimate and what would be cheating. If you want to add a code interpreter to the system, I think that's great. That's legitimate. The part that would be cheating is trying to anticipate what might be in the test, like brute force the space of possible tasks and train a memorization system on that. You rely on the fact that you're generating so many tasks, millions and millions. Inevitably there's going to be some overlap between what you're generating and what's in the test set. That's defeating the purpose of the benchmark because then you can just solve it with that and you need to adapt just by fetching a memorized solution. Hopefully ARC will resist that, but no benchmark is perfect. Maybe there's a way to hack it. We're going to get an answer very soon.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think whatever solution we see that will score well is probably going to need to leverage some aspects from deep learning models and LLMs in particular.",
        "clean_text": "I think whatever solution we see that will score well is probably going to need to leverage some aspects from deep learning models and LLMs in particular.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We've shown already that LLMs can do quite well.",
        "clean_text": "We've shown already that LLMs can do quite well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "That's basically the Jack Cole approach.",
        "clean_text": "That's basically the Jack Cole approach.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We've also shown that pure discrete program search from a small DSL does very well.",
        "clean_text": "We've also shown that pure discrete program search from a small DSL does very well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Before Jack Cole, this was the state of the art.",
        "clean_text": "Before Jack Cole, this was the state of the art.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "In fact, it's still extremely close to the state of the art and there's no deep learning involved at all in these models.",
        "clean_text": "In fact, it's still extremely close to the state of the art and there's no deep learning involved at all in these models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "We have two approaches that have basically no overlap, that are doing quite well.",
        "clean_text": "We have two approaches that have basically no overlap, that are doing quite well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "They're very much at two opposite ends of one spectrum.",
        "clean_text": "They're very much at two opposite ends of one spectrum.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "On one end, you have these extremely large banks of millions of vector programs, but very shallow recombination, simplistic recombination.",
        "clean_text": "On one end, you have these extremely large banks of millions of vector programs, but very shallow recombination, simplistic recombination.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "On the other end, you have very simplistic DSLs, 100-200 primitives, but very deep, very sophisticated program search.",
        "clean_text": "On the other end, you have very simplistic DSLs, 100-200 primitives, but very deep, very sophisticated program search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "The solution is going to be somewhere in between.",
        "clean_text": "The solution is going to be somewhere in between.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "The people who are going to be winning the ARC competition and making the most progress towards near-term AGI are going to be those that manage to merge the deep learning paradigm and the discrete program search paradigm into one elegant way.",
        "clean_text": "The people who are going to be winning the ARC competition and making the most progress towards near-term AGI are going to be those that manage to merge the deep learning paradigm and the discrete program search paradigm into one elegant way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "You asked what would be legitimate and what would be cheating.",
        "clean_text": "You asked what would be legitimate and what would be cheating.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "If you want to add a code interpreter to the system, I think that's great.",
        "clean_text": "If you want to add a code interpreter to the system, I think that's great.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "That's legitimate.",
        "clean_text": "That's legitimate.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "The part that would be cheating is trying to anticipate what might be in the test, like brute force the space of possible tasks and train a memorization system on that.",
        "clean_text": "The part that would be cheating is trying to anticipate what might be in the test, like brute force the space of possible tasks and train a memorization system on that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "You rely on the fact that you're generating so many tasks, millions and millions.",
        "clean_text": "You rely on the fact that you're generating so many tasks, millions and millions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "Inevitably there's going to be some overlap between what you're generating and what's in the test set.",
        "clean_text": "Inevitably there's going to be some overlap between what you're generating and what's in the test set.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "That's defeating the purpose of the benchmark because then you can just solve it with that and you need to adapt just by fetching a memorized solution.",
        "clean_text": "That's defeating the purpose of the benchmark because then you can just solve it with that and you need to adapt just by fetching a memorized solution.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "Hopefully ARC will resist that, but no benchmark is perfect.",
        "clean_text": "Hopefully ARC will resist that, but no benchmark is perfect.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "Maybe there's a way to hack it.",
        "clean_text": "Maybe there's a way to hack it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "We're going to get an answer very soon.",
        "clean_text": "We're going to get an answer very soon.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 148,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:29:41",
    "content": "Although some amount of fine tuning is valid because they have to use open source language models to compete here and they’re natively language. They’d need to be able to think in the ARC-type way.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAlthough some amount of fine tuning is valid because they have to use open source language models to compete here and they’re natively language.",
        "clean_text": "Although some amount of fine tuning is valid because they have to use open source language models to compete here and they’re natively language.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They’d need to be able to think in the ARC-type way.",
        "clean_text": "They’d need to be able to think in the ARC-type way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 149,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:29:58",
    "content": "Yes. You want to input core knowledge, ARC-like core knowledge, into the model but surely you don't need tens of millions of tasks to do this. Core knowledge is extremely basic.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYes.",
        "clean_text": "Yes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You want to input core knowledge, ARC-like core knowledge, into the model but surely you don't need tens of millions of tasks to do this.",
        "clean_text": "You want to input core knowledge, ARC-like core knowledge, into the model but surely you don't need tens of millions of tasks to do this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Core knowledge is extremely basic.",
        "clean_text": "Core knowledge is extremely basic.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 150,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:30:08",
    "content": "If you look at some of these ARC-type questions, I actually do think they rely a little bit on things I have seen throughout my life. For example, something bounces off a wall and comes back and you see that pattern. I've played arcade games and I've seen Pong or something. For example, you see the Flynn effect and people's intelligence, as measured on Raven's progressive matrices, increasing on these kinds of questions. It's probably a similar story where since childhood now, we actually see these sorts of patterns in TV and whatever, these spatial patterns. So I don't think this is core knowledge. This is actually also part of the “fine-tuning” that humans have as they grow up, seeing different kinds of spatial patterns and trying to pattern match to them.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf you look at some of these ARC-type questions, I actually do think they rely a little bit on things I have seen throughout my life.",
        "clean_text": "If you look at some of these ARC-type questions, I actually do think they rely a little bit on things I have seen throughout my life.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "For example, something bounces off a wall and comes back and you see that pattern.",
        "clean_text": "For example, something bounces off a wall and comes back and you see that pattern.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I've played arcade games and I've seen [Pong](https://en.wikipedia.org/wiki/Pong) or something.",
        "clean_text": "I've played arcade games and I've seen Pong or something.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "For example, you see the [Flynn effect](https://en.wikipedia.org/wiki/Flynn_effect) and people's intelligence, as measured on Raven's progressive matrices, increasing on these kinds of questions.",
        "clean_text": "For example, you see the Flynn effect and people's intelligence, as measured on Raven's progressive matrices, increasing on these kinds of questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It's probably a similar story where since childhood now, we actually see these sorts of patterns in TV and whatever, these spatial patterns.",
        "clean_text": "It's probably a similar story where since childhood now, we actually see these sorts of patterns in TV and whatever, these spatial patterns.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "So I don't think this is core knowledge.",
        "clean_text": "So I don't think this is core knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "This is actually also part of the “fine-tuning” that humans have as they grow up, seeing different kinds of spatial patterns and trying to pattern match to them.",
        "clean_text": "This is actually also part of the “fine-tuning” that humans have as they grow up, seeing different kinds of spatial patterns and trying to pattern match to them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 151,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:30:54",
    "content": "I would definitely file that under core knowledge. Core knowledge includes basic physics, for instance bouncing or trajectories. That would be included. But yeah, you're entirely right. The reason why, as a human, you're able to quickly figure out the solution is because you have this set of building blocks, this set of patterns, in your mind that you can recombine.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI would definitely file that under core knowledge.",
        "clean_text": "I would definitely file that under core knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Core knowledge includes basic physics, for instance bouncing or trajectories.",
        "clean_text": "Core knowledge includes basic physics, for instance bouncing or trajectories.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "That would be included.",
        "clean_text": "That would be included.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "But yeah, you're entirely right.",
        "clean_text": "But yeah, you're entirely right.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "The reason why, as a human, you're able to quickly figure out the solution is because you have this set of building blocks, this set of patterns, in your mind that you can recombine.",
        "clean_text": "The reason why, as a human, you're able to quickly figure out the solution is because you have this set of building blocks, this set of patterns, in your mind that you can recombine.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 152,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:31:12",
    "content": "Is core knowledge required to attain intelligence? For any algorithm you have, does the core knowledge have to be, in some sense, hardcoded? Or can even the core knowledge be learned through intelligence?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIs core knowledge required to attain intelligence?",
        "clean_text": "Is core knowledge required to attain intelligence?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "For any algorithm you have, does the core knowledge have to be, in some sense, hardcoded?",
        "clean_text": "For any algorithm you have, does the core knowledge have to be, in some sense, hardcoded?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Or can even the core knowledge be learned through intelligence?",
        "clean_text": "Or can even the core knowledge be learned through intelligence?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 153,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:31:22",
    "content": "Core knowledge can be learned. In the case of humans, some amount of core knowledge is something that you're born with. We're actually born with a small amount of knowledge about the world we're going to live in. We're not blank slates. But most core knowledge is acquired through experience. The thing with core knowledge is that it's not going to be acquired in school for instance. It's actually acquired very early in the first 3-4 years of your life. By age four, you have all the core knowledge you're going to need as an adult.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nCore knowledge can be learned.",
        "clean_text": "Core knowledge can be learned.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "In the case of humans, some amount of core knowledge is something that you're born with.",
        "clean_text": "In the case of humans, some amount of core knowledge is something that you're born with.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We're actually born with a small amount of knowledge about the world we're going to live in.",
        "clean_text": "We're actually born with a small amount of knowledge about the world we're going to live in.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We're not blank slates.",
        "clean_text": "We're not blank slates.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "But most core knowledge is acquired through experience.",
        "clean_text": "But most core knowledge is acquired through experience.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "The thing with core knowledge is that it's not going to be acquired in school for instance.",
        "clean_text": "The thing with core knowledge is that it's not going to be acquired in school for instance.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "It's actually acquired very early in the first 3-4 years of your life.",
        "clean_text": "It's actually acquired very early in the first 3-4 years of your life.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "By age four, you have all the core knowledge you're going to need as an adult.",
        "clean_text": "By age four, you have all the core knowledge you're going to need as an adult.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 154,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:31:52",
    "content": "Interesting. On the prize itself, I'm super excited to see the open source versions, maybe with a Llama (70B) or something, and what people can score in the competition itself. I’m also excited to test specifically the scaling hypothesis and I'm very curious if you can prompt on the public version of ARC. You won't be able to submit that to this competition itself but I'd be very curious to see if people can crack that and get ARC working there. Would that update your views on AGI?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nInteresting.",
        "clean_text": "Interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "On the prize itself, I'm super excited to see the open source versions, maybe with a [Llama (70B)](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-code-llama-70b/) or something, and what people can score in the competition itself.",
        "clean_text": "On the prize itself, I'm super excited to see the open source versions, maybe with a Llama (70B) or something, and what people can score in the competition itself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I’m also excited to test specifically the scaling hypothesis and I'm very curious if you can prompt on the public version of ARC.",
        "clean_text": "I’m also excited to test specifically the scaling hypothesis and I'm very curious if you can prompt on the public version of ARC.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You won't be able to submit that to this competition itself but I'd be very curious to see if people can crack that and get ARC working there.",
        "clean_text": "You won't be able to submit that to this competition itself but I'd be very curious to see if people can crack that and get ARC working there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Would that update your views on AGI?",
        "clean_text": "Would that update your views on AGI?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 155,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:32:23",
    "content": "It's really going to be motivating. We're going to keep running the contest until somebody puts a reproducible open source version in the public domain. Even if somebody privately beats the ARC eval, we're going to still keep the prize money until someone can reproduce it and put the public reproducible version out there.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's really going to be motivating.",
        "clean_text": "It's really going to be motivating.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We're going to keep running the contest until somebody puts a reproducible open source version in the public domain.",
        "clean_text": "We're going to keep running the contest until somebody puts a reproducible open source version in the public domain.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Even if somebody privately beats the ARC eval, we're going to still keep the prize money until someone can reproduce it and put the public reproducible version out there.",
        "clean_text": "Even if somebody privately beats the ARC eval, we're going to still keep the prize money until someone can reproduce it and put the public reproducible version out there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 156,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:32:37",
    "content": "Exactly. The goal is to accelerate progress towards AGI. A key part of that is that any meaningful bits of progress need to be shared, need to be public, so everyone can know about it and try to iterate on it. If there's no sharing, there's no progress.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nExactly.",
        "clean_text": "Exactly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The goal is to accelerate progress towards AGI.",
        "clean_text": "The goal is to accelerate progress towards AGI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "A key part of that is that any meaningful bits of progress need to be shared, need to be public, so everyone can know about it and try to iterate on it.",
        "clean_text": "A key part of that is that any meaningful bits of progress need to be shared, need to be public, so everyone can know about it and try to iterate on it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If there's no sharing, there's no progress.",
        "clean_text": "If there's no sharing, there's no progress.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 157,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:32:51",
    "content": "What I'm especially curious about is disaggregating the bets. Can we make an open version of this or is this just possible with scaling? We can test both of them based on the public and the private version.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat I'm especially curious about is disaggregating the bets.",
        "clean_text": "What I'm especially curious about is disaggregating the bets.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Can we make an open version of this or is this just possible with scaling?",
        "clean_text": "Can we make an open version of this or is this just possible with scaling?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We can test both of them based on the public and the private version.",
        "clean_text": "We can test both of them based on the public and the private version.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 158,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:33:06",
    "content": "We're making contact with reality as well with this. We're gonna learn a lot about what the actual limits of the compute are. If someone showed up and said, “hey, here's a closed source model and I'm getting +50% with it,” that would probably update us. We’d think, “okay, perhaps we should increase the amount of compute that we give on the private test set in order to balance.” Some of the decisions initially are somewhat arbitrary in order to learn about what people want. What does progress look like? Both of us are committed to evolving it over time in order to be the best or the closest to perfect as we can get it",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe're making contact with reality as well with this.",
        "clean_text": "We're making contact with reality as well with this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We're gonna learn a lot about what the actual limits of the compute are.",
        "clean_text": "We're gonna learn a lot about what the actual limits of the compute are.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If someone showed up and said, “hey, here's a closed source model and I'm getting +50% with it,” that would probably update us.",
        "clean_text": "If someone showed up and said, “hey, here's a closed source model and I'm getting +50% with it,” that would probably update us.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We’d think, “okay, perhaps we should increase the amount of compute that we give on the private test set in order to balance.”\n\nSome of the decisions initially are somewhat arbitrary in order to learn about what people want.",
        "clean_text": "We’d think, “okay, perhaps we should increase the amount of compute that we give on the private test set in order to balance.” Some of the decisions initially are somewhat arbitrary in order to learn about what people want.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "What does progress look like?",
        "clean_text": "What does progress look like?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Both of us are committed to evolving it over time in order to be the best or the closest to perfect as we can get it",
        "clean_text": "Both of us are committed to evolving it over time in order to be the best or the closest to perfect as we can get it",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 159,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:33:32",
    "content": "Awesome. Where can people go to learn more about the prize and maybe try their hand at it?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAwesome.",
        "clean_text": "Awesome.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Where can people go to learn more about the prize and maybe try their hand at it?",
        "clean_text": "Where can people go to learn more about the prize and maybe try their hand at it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 160,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:33:36",
    "content": "Arcprize.org. It’s live now.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\n[Arcprize.org](https://arcprize.org/).",
        "clean_text": "Arcprize.org.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It’s live now.",
        "clean_text": "It’s live now.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 161,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:33:37",
    "content": "It goes live today. One million dollars is on the line, people. Thank you guys for coming on the podcast. It's super fun to go through all the cruxes on intelligence and get a different perspective and also to announce a prize here. This is awesome.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt goes live today.",
        "clean_text": "It goes live today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "One million dollars is on the line, people.",
        "clean_text": "One million dollars is on the line, people.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Thank you guys for coming on the podcast.",
        "clean_text": "Thank you guys for coming on the podcast.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's super fun to go through all the cruxes on intelligence and get a different perspective and also to announce a prize here.",
        "clean_text": "It's super fun to go through all the cruxes on intelligence and get a different perspective and also to announce a prize here.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "This is awesome.",
        "clean_text": "This is awesome.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 162,
    "role": "Guest",
    "speaker": "Mike Knoop",
    "start_time": "01:33:50",
    "content": "Thank you for helping break the news.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThank you for helping break the news.",
        "clean_text": "Thank you for helping break the news.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 163,
    "role": "Guest",
    "speaker": "François Chollet",
    "start_time": "01:33:51",
    "content": "Thank you for having us.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThank you for having us.",
        "clean_text": "Thank you for having us.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  }
]