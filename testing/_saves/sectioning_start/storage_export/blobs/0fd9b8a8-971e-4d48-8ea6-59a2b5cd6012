[
  {
    "index": 0,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:00:00",
    "content": "Mark, welcome to the podcast.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nMark, welcome to the podcast.",
        "clean_text": "Mark, welcome to the podcast.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 1,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "0:00:01",
    "content": "Thanks for having me. Big fan of your podcast.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThanks for having me.",
        "clean_text": "Thanks for having me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Big fan of your podcast.",
        "clean_text": "Big fan of your podcast.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 2,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:00:03",
    "content": "Thank you, that's very nice of you to say. Let's start by talking about the releases that will go out when this interview goes out. Tell me about the models and [Meta AI](https://ai.meta.com/). What’s new and exciting about them?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThank you, that's very nice of you to say.",
        "clean_text": "Thank you, that's very nice of you to say.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Let's start by talking about the releases that will go out when this interview goes out.",
        "clean_text": "Let's start by talking about the releases that will go out when this interview goes out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Tell me about the models and [Meta AI](https://ai.meta.com/).",
        "clean_text": "Tell me about the models and Meta AI.",
        "extracted_information": {
          "links": {
            "Meta AI": "https://ai.meta.com/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "What’s new and exciting about them?",
        "clean_text": "What’s new and exciting about them?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 3,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:00:15",
    "content": "I think the main thing that most people in the world are going to see is the new version of Meta AI. The most important thing that we're doing is the upgrade to the model. We're rolling out [Llama-3](https://llama.meta.com/). We're doing it both as open source for the dev community and it is now going to be powering Meta AI. There's a lot that I'm sure we'll get into around Llama-3, but I think the bottom line on this is that we think now that Meta AI is the most intelligent, freely-available AI assistant that people can use. We're also integrating Google and Bing for real-time knowledge.\n\nWe're going to make it a lot more prominent across our apps. At the top of Facebook and Messenger, you'll be able to just use the search box right there to ask any question. There's a bunch of new creation features that we added that I think are pretty cool and that I think people will enjoy. I think animations is a good one. You can basically take any image and just animate it.\n\nOne that people are going to find pretty wild is that it now generates high quality images so quickly that it actually generates it as you're typing and updates it in real time. So you're typing your query and it's honing in. It’s like “show me a picture of a cow in a field with mountains in the background, eating macadamia nuts, drinking beer” and it's updating the image in real time. It's pretty wild. I think people are going to enjoy that. So I think that's what most people are going to see in the world. We're rolling that out, not everywhere, but we're starting in a handful of countries and we'll do more over the coming weeks and months. I think that’s going to be a pretty big deal and I'm really excited to get that in people's hands. It's a big step forward for Meta AI.\n\nBut I think if you want to get under the hood a bit, the Llama-3 stuff is obviously the most technically interesting. We're training [three versions](https://www.theverge.com/2024/4/9/24125217/meta-llama-smaller-lightweight-model-ai): an 8 billion parameter model and a 70 billion, which we're releasing today, and a 405 billion [dense model](https://www.perplexity.ai/search/what-does-a-R2bzVN2UTJOLH1BUHsWiKA#0), which is still training. So we're not releasing that today, but I'm pretty excited about how the 8B and the 70B turned out. They're leading for their scale. We'll release a blog post with all the benchmarks so people can check it out themselves. Obviously it's open source so people get a chance to play with it.\n\nWe have a roadmap of new releases coming that are going to bring [multimodality](https://ai.meta.com/tools/system-cards/multimodal-generative-ai-systems/), more [multi-linguality](https://ai.meta.com/blog/multilingual-model-speech-recognition/), and [bigger context windows](https://ai.meta.com/research/publications/effective-long-context-scaling-of-foundation-models/) as well. Hopefully, sometime later in the year we'll get to roll out the 405B. For where it is right now in training, it is already at around 85 [MMLU](https://arxiv.org/abs/2009.03300) and we expect that it's going to have leading benchmarks on a bunch of the benchmarks. I'm pretty excited about all of that. The 70 billion is great too. We're releasing that today. It's around 82 MMLU and has leading scores on math and reasoning. I think just getting this in people's hands is going to be pretty wild.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think the main thing that most people in the world are going to see is the new version of Meta AI.",
        "clean_text": "I think the main thing that most people in the world are going to see is the new version of Meta AI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The most important thing that we're doing is the upgrade to the model.",
        "clean_text": "The most important thing that we're doing is the upgrade to the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We're rolling out [Llama-3](https://llama.meta.com/).",
        "clean_text": "We're rolling out Llama-3.",
        "extracted_information": {
          "links": {
            "Llama-3": "https://llama.meta.com/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We're doing it both as open source for the dev community and it is now going to be powering Meta AI.",
        "clean_text": "We're doing it both as open source for the dev community and it is now going to be powering Meta AI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "There's a lot that I'm sure we'll get into around Llama-3, but I think the bottom line on this is that we think now that Meta AI is the most intelligent, freely-available AI assistant that people can use.",
        "clean_text": "There's a lot that I'm sure we'll get into around Llama-3, but I think the bottom line on this is that we think now that Meta AI is the most intelligent, freely-available AI assistant that people can use.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "We're also integrating Google and Bing for real-time knowledge.",
        "clean_text": "We're also integrating Google and Bing for real-time knowledge.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "We're going to make it a lot more prominent across our apps.",
        "clean_text": "We're going to make it a lot more prominent across our apps.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "At the top of Facebook and Messenger, you'll be able to just use the search box right there to ask any question.",
        "clean_text": "At the top of Facebook and Messenger, you'll be able to just use the search box right there to ask any question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "There's a bunch of new creation features that we added that I think are pretty cool and that I think people will enjoy.",
        "clean_text": "There's a bunch of new creation features that we added that I think are pretty cool and that I think people will enjoy.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I think animations is a good one.",
        "clean_text": "I think animations is a good one.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You can basically take any image and just animate it.",
        "clean_text": "You can basically take any image and just animate it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "One that people are going to find pretty wild is that it now generates high quality images so quickly that it actually generates it as you're typing and updates it in real time.",
        "clean_text": "One that people are going to find pretty wild is that it now generates high quality images so quickly that it actually generates it as you're typing and updates it in real time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "So you're typing your query and it's honing in.",
        "clean_text": "So you're typing your query and it's honing in.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "It’s like “show me a picture of a cow in a field with mountains in the background, eating macadamia nuts, drinking beer” and it's updating the image in real time.",
        "clean_text": "It’s like “show me a picture of a cow in a field with mountains in the background, eating macadamia nuts, drinking beer” and it's updating the image in real time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "It's pretty wild.",
        "clean_text": "It's pretty wild.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "I think people are going to enjoy that.",
        "clean_text": "I think people are going to enjoy that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "So I think that's what most people are going to see in the world.",
        "clean_text": "So I think that's what most people are going to see in the world.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "We're rolling that out, not everywhere, but we're starting in a handful of countries and we'll do more over the coming weeks and months.",
        "clean_text": "We're rolling that out, not everywhere, but we're starting in a handful of countries and we'll do more over the coming weeks and months.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "I think that’s going to be a pretty big deal and I'm really excited to get that in people's hands.",
        "clean_text": "I think that’s going to be a pretty big deal and I'm really excited to get that in people's hands.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "It's a big step forward for Meta AI.",
        "clean_text": "It's a big step forward for Meta AI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "But I think if you want to get under the hood a bit, the Llama-3 stuff is obviously the most technically interesting.",
        "clean_text": "But I think if you want to get under the hood a bit, the Llama-3 stuff is obviously the most technically interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "We're training [three versions](https://www.theverge.com/2024/4/9/24125217/meta-llama-smaller-lightweight-model-ai): an 8 billion parameter model and a 70 billion, which we're releasing today, and a 405 billion [dense model](https://www.perplexity.ai/search/what-does-a-R2bzVN2UTJOLH1BUHsWiKA#0), which is still training.",
        "clean_text": "We're training three versions: an 8 billion parameter model and a 70 billion, which we're releasing today, and a 405 billion dense model, which is still training.",
        "extracted_information": {
          "links": {
            "three versions": "https://www.theverge.com/2024/4/9/24125217/meta-llama-smaller-lightweight-model-ai",
            "dense model": "https://www.perplexity.ai/search/what-does-a-R2bzVN2UTJOLH1BUHsWiKA#0"
          },
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "So we're not releasing that today, but I'm pretty excited about how the 8B and the 70B turned out.",
        "clean_text": "So we're not releasing that today, but I'm pretty excited about how the 8B and the 70B turned out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "They're leading for their scale.",
        "clean_text": "They're leading for their scale.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "We'll release a blog post with all the benchmarks so people can check it out themselves.",
        "clean_text": "We'll release a blog post with all the benchmarks so people can check it out themselves.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "Obviously it's open source so people get a chance to play with it.",
        "clean_text": "Obviously it's open source so people get a chance to play with it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "We have a roadmap of new releases coming that are going to bring [multimodality](https://ai.meta.com/tools/system-cards/multimodal-generative-ai-systems/), more [multi-linguality](https://ai.meta.com/blog/multilingual-model-speech-recognition/), and [bigger context windows](https://ai.meta.com/research/publications/effective-long-context-scaling-of-foundation-models/) as well.",
        "clean_text": "We have a roadmap of new releases coming that are going to bring multimodality, more multi-linguality, and bigger context windows as well.",
        "extracted_information": {
          "links": {
            "multimodality": "https://ai.meta.com/tools/system-cards/multimodal-generative-ai-systems/",
            "multi-linguality": "https://ai.meta.com/blog/multilingual-model-speech-recognition/",
            "bigger context windows": "https://ai.meta.com/research/publications/effective-long-context-scaling-of-foundation-models/"
          },
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "Hopefully, sometime later in the year we'll get to roll out the 405B.",
        "clean_text": "Hopefully, sometime later in the year we'll get to roll out the 405B.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "For where it is right now in training, it is already at around 85 [MMLU](https://arxiv.org/abs/2009.03300) and we expect that it's going to have leading benchmarks on a bunch of the benchmarks.",
        "clean_text": "For where it is right now in training, it is already at around 85 MMLU and we expect that it's going to have leading benchmarks on a bunch of the benchmarks.",
        "extracted_information": {
          "links": {
            "MMLU": "https://arxiv.org/abs/2009.03300"
          },
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "I'm pretty excited about all of that.",
        "clean_text": "I'm pretty excited about all of that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 30,
        "original_text": "The 70 billion is great too.",
        "clean_text": "The 70 billion is great too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 31,
        "original_text": "We're releasing that today.",
        "clean_text": "We're releasing that today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 32,
        "original_text": "It's around 82 MMLU and has leading scores on math and reasoning.",
        "clean_text": "It's around 82 MMLU and has leading scores on math and reasoning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 33,
        "original_text": "I think just getting this in people's hands is going to be pretty wild.",
        "clean_text": "I think just getting this in people's hands is going to be pretty wild.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 4,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:03:42",
    "content": "Oh, interesting. That's the first I’m hearing of it as a benchmark. That's super impressive.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOh, interesting.",
        "clean_text": "Oh, interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "That's the first I’m hearing of it as a benchmark.",
        "clean_text": "That's the first I’m hearing of it as a benchmark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "That's super impressive.",
        "clean_text": "That's super impressive.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 5,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:03:45",
    "content": "The 8 billion is nearly as powerful as the biggest version of [Llama-2](https://llama.meta.com/llama2/) that we released. So the smallest Llama-3 is basically as powerful as the biggest Llama-2.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThe 8 billion is nearly as powerful as the biggest version of [Llama-2](https://llama.meta.com/llama2/) that we released.",
        "clean_text": "The 8 billion is nearly as powerful as the biggest version of Llama-2 that we released.",
        "extracted_information": {
          "links": {
            "Llama-2": "https://llama.meta.com/llama2/"
          },
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "So the smallest Llama-3 is basically as powerful as the biggest Llama-2.",
        "clean_text": "So the smallest Llama-3 is basically as powerful as the biggest Llama-2.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 6,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:03:59",
    "content": "Before we dig into these models, I want to go back in time. I'm assuming 2022 is when you started acquiring these [H100s](https://www.nvidia.com/en-us/data-center/h100/), or you can tell me when. The stock price is getting hammered. [People are asking what's happening with all this capex.](https://www.reuters.com/breakingviews/metas-spending-splurge-starts-look-troubling-2022-10-26/) [People aren't buying](https://www.nytimes.com/2022/02/02/technology/meta-facebook-earnings-metaverse.html) the [metaverse](https://about.meta.com/what-is-the-metaverse/). Presumably you're spending that [capex](https://www.investopedia.com/terms/c/capitalexpenditure.asp) to get these H100s. How did you know back then to get the H100s? How did you know that you’d need the [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit)?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBefore we dig into these models, I want to go back in time.",
        "clean_text": "Before we dig into these models, I want to go back in time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm assuming 2022 is when you started acquiring these [H100s](https://www.nvidia.com/en-us/data-center/h100/), or you can tell me when.",
        "clean_text": "I'm assuming 2022 is when you started acquiring these H100s, or you can tell me when.",
        "extracted_information": {
          "links": {
            "H100s": "https://www.nvidia.com/en-us/data-center/h100/"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The stock price is getting hammered.",
        "clean_text": "The stock price is getting hammered.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "[People are asking what's happening with all this capex.",
        "clean_text": "[People are asking what's happening with all this capex.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "](https://www.reuters.com/breakingviews/metas-spending-splurge-starts-look-troubling-2022-10-26/) [People aren't buying](https://www.nytimes.com/2022/02/02/technology/meta-facebook-earnings-metaverse.html) the [metaverse](https://about.meta.com/what-is-the-metaverse/).",
        "clean_text": "](https://www.reuters.com/breakingviews/metas-spending-splurge-starts-look-troubling-2022-10-26/) People aren't buying the metaverse.",
        "extracted_information": {
          "links": {
            "People aren't buying": "https://www.nytimes.com/2022/02/02/technology/meta-facebook-earnings-metaverse.html",
            "metaverse": "https://about.meta.com/what-is-the-metaverse/"
          },
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Presumably you're spending that [capex](https://www.investopedia.com/terms/c/capitalexpenditure.asp) to get these H100s.",
        "clean_text": "Presumably you're spending that capex to get these H100s.",
        "extracted_information": {
          "links": {
            "capex": "https://www.investopedia.com/terms/c/capitalexpenditure.asp"
          },
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "How did you know back then to get the H100s?",
        "clean_text": "How did you know back then to get the H100s?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "How did you know that you’d need the [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit)?",
        "clean_text": "How did you know that you’d need the GPUs?",
        "extracted_information": {
          "links": {
            "GPUs": "https://en.wikipedia.org/wiki/Graphics_processing_unit"
          },
          "titles": [
            "processing"
          ]
        }
      }
    ]
  },
  {
    "index": 7,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:04:22",
    "content": "I think it was because we were working on [Reels](https://creators.facebook.com/tools/reels/?locale=en_US). We always want to have enough capacity to build something that we can't quite see on the horizon yet. We got into this position with Reels where we needed more GPUs to train the models. It was this big evolution for our services. Instead of just ranking content from people or pages you follow, we made this big push to start recommending what we call [unconnected content](https://ai.meta.com/blog/ai-unconnected-content-recommendations-facebook-instagram/), content from people or pages that you're not following.\n\nThe corpus of content candidates that we could potentially show you expanded from on the order of thousands to on the order of hundreds of millions. It needed a completely different infrastructure. We started working on doing that and we were [constrained on the infrastructure in catching up to what TikTok was doing](https://www.theregister.com/2022/06/30/meta_we_need_5x_more/) as quickly as we wanted to. I basically looked at that and I was like “hey, we have to make sure that we're never in this situation again. So let's order enough GPUs to do what we need to do on Reels and ranking content and feed. But let's also double that.” Again, our normal principle is that there's going to be something on the horizon that we can't see yet.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think it was because we were working on [Reels](https://creators.facebook.com/tools/reels/?locale=en_US).",
        "clean_text": "I think it was because we were working on Reels.",
        "extracted_information": {
          "links": {
            "Reels": "https://creators.facebook.com/tools/reels/?locale=en_US"
          },
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We always want to have enough capacity to build something that we can't quite see on the horizon yet.",
        "clean_text": "We always want to have enough capacity to build something that we can't quite see on the horizon yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We got into this position with Reels where we needed more GPUs to train the models.",
        "clean_text": "We got into this position with Reels where we needed more GPUs to train the models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It was this big evolution for our services.",
        "clean_text": "It was this big evolution for our services.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Instead of just ranking content from people or pages you follow, we made this big push to start recommending what we call [unconnected content](https://ai.meta.com/blog/ai-unconnected-content-recommendations-facebook-instagram/), content from people or pages that you're not following.",
        "clean_text": "Instead of just ranking content from people or pages you follow, we made this big push to start recommending what we call unconnected content, content from people or pages that you're not following.",
        "extracted_information": {
          "links": {
            "unconnected content": "https://ai.meta.com/blog/ai-unconnected-content-recommendations-facebook-instagram/"
          },
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "The corpus of content candidates that we could potentially show you expanded from on the order of thousands to on the order of hundreds of millions.",
        "clean_text": "The corpus of content candidates that we could potentially show you expanded from on the order of thousands to on the order of hundreds of millions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "It needed a completely different infrastructure.",
        "clean_text": "It needed a completely different infrastructure.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "We started working on doing that and we were [constrained on the infrastructure in catching up to what TikTok was doing](https://www.theregister.com/2022/06/30/meta_we_need_5x_more/) as quickly as we wanted to.",
        "clean_text": "We started working on doing that and we were constrained on the infrastructure in catching up to what TikTok was doing as quickly as we wanted to.",
        "extracted_information": {
          "links": {
            "constrained on the infrastructure in catching up to what TikTok was doing": "https://www.theregister.com/2022/06/30/meta_we_need_5x_more/"
          },
          "titles": [
            "we",
            "5x"
          ]
        }
      },
      {
        "index": 8,
        "original_text": "I basically looked at that and I was like “hey, we have to make sure that we're never in this situation again.",
        "clean_text": "I basically looked at that and I was like “hey, we have to make sure that we're never in this situation again.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "So let's order enough GPUs to do what we need to do on Reels and ranking content and feed.",
        "clean_text": "So let's order enough GPUs to do what we need to do on Reels and ranking content and feed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "But let's also double that.” Again, our normal principle is that there's going to be something on the horizon that we can't see yet.",
        "clean_text": "But let's also double that.” Again, our normal principle is that there's going to be something on the horizon that we can't see yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 8,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:05:51",
    "content": "Did you know it would be AI?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nDid you know it would be AI?",
        "clean_text": "Did you know it would be AI?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 9,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:05:52",
    "content": "We thought it was going to be something that had to do with training large models. At the time I thought it was probably going to be something that had to do with content. It’s just the pattern matching of running the company, there's always another thing. At that time I was so deep into trying to get the recommendations working for Reels and other content. That’s just such a big unlock for Instagram and Facebook now, being able to show people content that's interesting to them from people that they're not even following.\n\nBut that ended up being a very good decision in retrospect. And it came from being behind. It wasn't like “oh, I was so far ahead.” Actually, most of the times where we make some decision that ends up seeming good is because we messed something up before and just didn't want to repeat the mistake.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe thought it was going to be something that had to do with training large models.",
        "clean_text": "We thought it was going to be something that had to do with training large models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "At the time I thought it was probably going to be something that had to do with content.",
        "clean_text": "At the time I thought it was probably going to be something that had to do with content.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It’s just the pattern matching of running the company, there's always another thing.",
        "clean_text": "It’s just the pattern matching of running the company, there's always another thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "At that time I was so deep into trying to get the recommendations working for Reels and other content.",
        "clean_text": "At that time I was so deep into trying to get the recommendations working for Reels and other content.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "That’s just such a big unlock for Instagram and Facebook now, being able to show people content that's interesting to them from people that they're not even following.",
        "clean_text": "That’s just such a big unlock for Instagram and Facebook now, being able to show people content that's interesting to them from people that they're not even following.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "But that ended up being a very good decision in retrospect.",
        "clean_text": "But that ended up being a very good decision in retrospect.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "And it came from being behind.",
        "clean_text": "And it came from being behind.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It wasn't like “oh, I was so far ahead.” Actually, most of the times where we make some decision that ends up seeming good is because we messed something up before and just didn't want to repeat the mistake.",
        "clean_text": "It wasn't like “oh, I was so far ahead.” Actually, most of the times where we make some decision that ends up seeming good is because we messed something up before and just didn't want to repeat the mistake.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 10,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:06:47",
    "content": "This is a total detour, but I want to ask about this while we're on this. We'll get back to AI in a second. In 2006 you [didn't sell for $1 billion](https://techcrunch.com/2013/03/13/would-facebook-have-sold-to-yahoo-for-1-6-billion-well-never-know/) but presumably there's some amount you would have sold for, right? Did you write down in your head like “I think the actual valuation of Facebook at the time is this and they're not actually getting the valuation right”? If they’d offered you $5 trillion, of course you would have sold. So how did you think about that choice?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThis is a total detour, but I want to ask about this while we're on this.",
        "clean_text": "This is a total detour, but I want to ask about this while we're on this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We'll get back to AI in a second.",
        "clean_text": "We'll get back to AI in a second.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "In 2006 you [didn't sell for $1 billion](https://techcrunch.com/2013/03/13/would-facebook-have-sold-to-yahoo-for-1-6-billion-well-never-know/) but presumably there's some amount you would have sold for, right?",
        "clean_text": "In 2006 you didn't sell for $1 billion but presumably there's some amount you would have sold for, right?",
        "extracted_information": {
          "links": {
            "didn't sell for $1 billion": "https://techcrunch.com/2013/03/13/would-facebook-have-sold-to-yahoo-for-1-6-billion-well-never-know/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Did you write down in your head like “I think the actual valuation of Facebook at the time is this and they're not actually getting the valuation right”?",
        "clean_text": "Did you write down in your head like “I think the actual valuation of Facebook at the time is this and they're not actually getting the valuation right”?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "If they’d offered you $5 trillion, of course you would have sold.",
        "clean_text": "If they’d offered you $5 trillion, of course you would have sold.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "So how did you think about that choice?",
        "clean_text": "So how did you think about that choice?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 11,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:07:08",
    "content": "I think some of these things are just personal. I don't know that at the time I was sophisticated enough to do that analysis. I had all these people around me who were making all these arguments for a billion dollars like “here's the revenue that we need to make and here's how big we need to be. It's clearly so many years in the future.” It was very far ahead of where we were at the time. I didn't really have the financial sophistication to really engage with that kind of debate.\n\nDeep down I believed in what we were doing. I did some analysis like “what would I do if I weren’t doing this? Well, I really like building things and I like helping people communicate. I like understanding what's going on with people and the dynamics between people. So I think if I sold this company, I'd just go build another company like this and I kind of like the one I have. So why?” I think a lot of the biggest bets that people make are often just based on conviction and values. It's actually usually very hard to do the analyses trying to connect the dots forward.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think some of these things are just personal.",
        "clean_text": "I think some of these things are just personal.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I don't know that at the time I was sophisticated enough to do that analysis.",
        "clean_text": "I don't know that at the time I was sophisticated enough to do that analysis.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I had all these people around me who were making all these arguments for a billion dollars like “here's the revenue that we need to make and here's how big we need to be.",
        "clean_text": "I had all these people around me who were making all these arguments for a billion dollars like “here's the revenue that we need to make and here's how big we need to be.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's clearly so many years in the future.” It was very far ahead of where we were at the time.",
        "clean_text": "It's clearly so many years in the future.” It was very far ahead of where we were at the time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I didn't really have the financial sophistication to really engage with that kind of debate.",
        "clean_text": "I didn't really have the financial sophistication to really engage with that kind of debate.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Deep down I believed in what we were doing.",
        "clean_text": "Deep down I believed in what we were doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I did some analysis like “what would I do if I weren’t doing this?",
        "clean_text": "I did some analysis like “what would I do if I weren’t doing this?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Well, I really like building things and I like helping people communicate.",
        "clean_text": "Well, I really like building things and I like helping people communicate.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "I like understanding what's going on with people and the dynamics between people.",
        "clean_text": "I like understanding what's going on with people and the dynamics between people.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "So I think if I sold this company, I'd just go build another company like this and I kind of like the one I have.",
        "clean_text": "So I think if I sold this company, I'd just go build another company like this and I kind of like the one I have.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "So why?” I think a lot of the biggest bets that people make are often just based on conviction and values.",
        "clean_text": "So why?” I think a lot of the biggest bets that people make are often just based on conviction and values.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "It's actually usually very hard to do the analyses trying to connect the dots forward.",
        "clean_text": "It's actually usually very hard to do the analyses trying to connect the dots forward.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 12,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:08:32",
    "content": "You've had [Facebook AI Research](https://techcrunch.com/2013/12/09/facebook-artificial-intelligence-lab-lecun/) for a long time. Now it's become seemingly central to your company. At what point did making [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence), or however you consider that mission, become a key priority of what Meta is doing?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYou've had [Facebook AI Research](https://techcrunch.com/2013/12/09/facebook-artificial-intelligence-lab-lecun/) for a long time.",
        "clean_text": "You've had Facebook AI Research for a long time.",
        "extracted_information": {
          "links": {
            "Facebook AI Research": "https://techcrunch.com/2013/12/09/facebook-artificial-intelligence-lab-lecun/"
          },
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Now it's become seemingly central to your company.",
        "clean_text": "Now it's become seemingly central to your company.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "At what point did making [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence), or however you consider that mission, become a key priority of what Meta is doing?",
        "clean_text": "At what point did making AGI, or however you consider that mission, become a key priority of what Meta is doing?",
        "extracted_information": {
          "links": {
            "AGI": "https://en.wikipedia.org/wiki/Artificial_general_intelligence"
          },
          "titles": [
            "general"
          ]
        }
      }
    ]
  },
  {
    "index": 13,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:08:49",
    "content": "It's been a big deal for a while. We started FAIR about 10 years ago. The idea was that, along the way to general intelligence or whatever you wanna call it, there are going to be all these different innovations and that's going to just improve everything that we do. So we didn't conceive of it as a product. It was more of a research group. Over the last 10 years it has created a lot of different things that have improved all of our products. It’s advanced the field and allowed other people in the field to create things that have improved our products too. I think that that's been great.\n\nThere's obviously a big change in the last few years with [ChatGPT](https://openai.com/blog/chatgpt) and the [diffusion models around image creation](https://openai.com/research/dall-e) coming out. This is some pretty wild stuff that is pretty clearly going to affect how people interact with every app that's out there. At that point we started a second group, [the gen AI group](https://ai.meta.com/genai/), with the goal of bringing that stuff into our products and building leading [foundation models](https://en.wikipedia.org/wiki/Foundation_model) that would power all these different products.\n\nWhen we started doing that the theory initially was that a lot of the stuff we're doing is pretty social. It's helping people interact with creators, helping people interact with businesses, helping businesses sell things or do customer support. There’s also basic assistant functionality, whether it's for our apps or the [smart glasses](https://about.fb.com/news/2023/09/new-ray-ban-meta-smart-glasses/) or [VR](https://www.meta.com/quest/). So it wasn't completely clear at first that you were going to need full AGI to be able to support those use cases. But in all these subtle ways, through working on them, I think it's actually become clear that you do. For example, when we were working on Llama-2, we didn't prioritize coding because people aren't going to ask Meta AI a lot of coding questions in WhatsApp.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's been a big deal for a while.",
        "clean_text": "It's been a big deal for a while.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We started FAIR about 10 years ago.",
        "clean_text": "We started FAIR about 10 years ago.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The idea was that, along the way to general intelligence or whatever you wanna call it, there are going to be all these different innovations and that's going to just improve everything that we do.",
        "clean_text": "The idea was that, along the way to general intelligence or whatever you wanna call it, there are going to be all these different innovations and that's going to just improve everything that we do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "So we didn't conceive of it as a product.",
        "clean_text": "So we didn't conceive of it as a product.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It was more of a research group.",
        "clean_text": "It was more of a research group.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Over the last 10 years it has created a lot of different things that have improved all of our products.",
        "clean_text": "Over the last 10 years it has created a lot of different things that have improved all of our products.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "It’s advanced the field and allowed other people in the field to create things that have improved our products too.",
        "clean_text": "It’s advanced the field and allowed other people in the field to create things that have improved our products too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "I think that that's been great.",
        "clean_text": "I think that that's been great.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "There's obviously a big change in the last few years with [ChatGPT](https://openai.com/blog/chatgpt) and the [diffusion models around image creation](https://openai.com/research/dall-e) coming out.",
        "clean_text": "There's obviously a big change in the last few years with ChatGPT and the diffusion models around image creation coming out.",
        "extracted_information": {
          "links": {
            "ChatGPT": "https://openai.com/blog/chatgpt",
            "diffusion models around image creation": "https://openai.com/research/dall-e"
          },
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "This is some pretty wild stuff that is pretty clearly going to affect how people interact with every app that's out there.",
        "clean_text": "This is some pretty wild stuff that is pretty clearly going to affect how people interact with every app that's out there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "At that point we started a second group, [the gen AI group](https://ai.meta.com/genai/), with the goal of bringing that stuff into our products and building leading [foundation models](https://en.wikipedia.org/wiki/Foundation_model) that would power all these different products.",
        "clean_text": "At that point we started a second group, the gen AI group, with the goal of bringing that stuff into our products and building leading foundation models that would power all these different products.",
        "extracted_information": {
          "links": {
            "the gen AI group": "https://ai.meta.com/genai/",
            "foundation models": "https://en.wikipedia.org/wiki/Foundation_model"
          },
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "When we started doing that the theory initially was that a lot of the stuff we're doing is pretty social.",
        "clean_text": "When we started doing that the theory initially was that a lot of the stuff we're doing is pretty social.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "It's helping people interact with creators, helping people interact with businesses, helping businesses sell things or do customer support.",
        "clean_text": "It's helping people interact with creators, helping people interact with businesses, helping businesses sell things or do customer support.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "There’s also basic assistant functionality, whether it's for our apps or the [smart glasses](https://about.fb.com/news/2023/09/new-ray-ban-meta-smart-glasses/) or [VR](https://www.meta.com/quest/).",
        "clean_text": "There’s also basic assistant functionality, whether it's for our apps or the smart glasses or VR.",
        "extracted_information": {
          "links": {
            "smart glasses": "https://about.fb.com/news/2023/09/new-ray-ban-meta-smart-glasses/",
            "VR": "https://www.meta.com/quest/"
          },
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "So it wasn't completely clear at first that you were going to need full AGI to be able to support those use cases.",
        "clean_text": "So it wasn't completely clear at first that you were going to need full AGI to be able to support those use cases.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "But in all these subtle ways, through working on them, I think it's actually become clear that you do.",
        "clean_text": "But in all these subtle ways, through working on them, I think it's actually become clear that you do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "For example, when we were working on Llama-2, we didn't prioritize coding because people aren't going to ask Meta AI a lot of coding questions in WhatsApp.",
        "clean_text": "For example, when we were working on Llama-2, we didn't prioritize coding because people aren't going to ask Meta AI a lot of coding questions in WhatsApp.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 14,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:10:59",
    "content": "Now they will, right?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNow they will, right?",
        "clean_text": "Now they will, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 15,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:11:00",
    "content": "I don't know. I'm not sure that WhatsApp, or Facebook or Instagram, is the UI where people are going to be doing a lot of coding questions. Maybe the website, [meta.ai](http://meta.ai/), that we’re launching. But the thing that has been a somewhat surprising result over the last 18 months is that it turns out that [coding is important for a lot of domains, not just coding](https://arxiv.org/abs/2210.07128). Even if people aren't asking coding questions, training the models on coding helps them become more rigorous in answering the question and helps them reason across a lot of different types of domains. That's one example where for Llama-3, we really focused on training it with a lot of coding because that's going to make it better on all these things even if people aren't asking primarily coding questions.\n\n[Reasoning](https://en.wikipedia.org/wiki/Automated_reasoning) is another example. Maybe you want to chat with a creator or you're a business and you're trying to interact with a customer. That interaction is not just like “okay, the person sends you a message and you just reply.” It's a multi-step interaction where you're trying to think through “how do I accomplish the person's goals?” A lot of times when a customer comes, they don't necessarily know exactly what they're looking for or how to ask their questions. So it's not really the job of the AI to just respond to the question.\n\nYou need to kind of think about it more holistically. It really becomes a reasoning problem. So if someone else solves reasoning, or makes good advances on reasoning, and we're sitting here with a basic chat bot, then our product is lame compared to what other people are building. At the end of the day, we basically realized we've got to solve general intelligence and we just upped the ante and the investment to make sure that we could do that.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI don't know.",
        "clean_text": "I don't know.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm not sure that WhatsApp, or Facebook or Instagram, is the UI where people are going to be doing a lot of coding questions.",
        "clean_text": "I'm not sure that WhatsApp, or Facebook or Instagram, is the UI where people are going to be doing a lot of coding questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Maybe the website, [meta.ai](http://meta.ai/), that we’re launching.",
        "clean_text": "Maybe the website, meta.ai, that we’re launching.",
        "extracted_information": {
          "links": {
            "meta.ai": "http://meta.ai/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "But the thing that has been a somewhat surprising result over the last 18 months is that it turns out that [coding is important for a lot of domains, not just coding](https://arxiv.org/abs/2210.07128).",
        "clean_text": "But the thing that has been a somewhat surprising result over the last 18 months is that it turns out that coding is important for a lot of domains, not just coding.",
        "extracted_information": {
          "links": {
            "coding is important for a lot of domains, not just coding": "https://arxiv.org/abs/2210.07128"
          },
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Even if people aren't asking coding questions, training the models on coding helps them become more rigorous in answering the question and helps them reason across a lot of different types of domains.",
        "clean_text": "Even if people aren't asking coding questions, training the models on coding helps them become more rigorous in answering the question and helps them reason across a lot of different types of domains.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "That's one example where for Llama-3, we really focused on training it with a lot of coding because that's going to make it better on all these things even if people aren't asking primarily coding questions.",
        "clean_text": "That's one example where for Llama-3, we really focused on training it with a lot of coding because that's going to make it better on all these things even if people aren't asking primarily coding questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "[Reasoning](https://en.wikipedia.org/wiki/Automated_reasoning) is another example.",
        "clean_text": "Reasoning is another example.",
        "extracted_information": {
          "links": {
            "Reasoning": "https://en.wikipedia.org/wiki/Automated_reasoning"
          },
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Maybe you want to chat with a creator or you're a business and you're trying to interact with a customer.",
        "clean_text": "Maybe you want to chat with a creator or you're a business and you're trying to interact with a customer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "That interaction is not just like “okay, the person sends you a message and you just reply.” It's a multi-step interaction where you're trying to think through “how do I accomplish the person's goals?” A lot of times when a customer comes, they don't necessarily know exactly what they're looking for or how to ask their questions.",
        "clean_text": "That interaction is not just like “okay, the person sends you a message and you just reply.” It's a multi-step interaction where you're trying to think through “how do I accomplish the person's goals?” A lot of times when a customer comes, they don't necessarily know exactly what they're looking for or how to ask their questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "So it's not really the job of the AI to just respond to the question.",
        "clean_text": "So it's not really the job of the AI to just respond to the question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You need to kind of think about it more holistically.",
        "clean_text": "You need to kind of think about it more holistically.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "It really becomes a reasoning problem.",
        "clean_text": "It really becomes a reasoning problem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "So if someone else solves reasoning, or makes good advances on reasoning, and we're sitting here with a basic chat bot, then our product is lame compared to what other people are building.",
        "clean_text": "So if someone else solves reasoning, or makes good advances on reasoning, and we're sitting here with a basic chat bot, then our product is lame compared to what other people are building.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "At the end of the day, we basically realized we've got to solve general intelligence and we just upped the ante and the investment to make sure that we could do that.",
        "clean_text": "At the end of the day, we basically realized we've got to solve general intelligence and we just upped the ante and the investment to make sure that we could do that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 16,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:12:48",
    "content": "So the version of Llama that's going to solve all these use cases for users, is that the version that will be powerful enough to replace a programmer you might have in this building?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSo the version of Llama that's going to solve all these use cases for users, is that the version that will be powerful enough to replace a programmer you might have in this building?",
        "clean_text": "So the version of Llama that's going to solve all these use cases for users, is that the version that will be powerful enough to replace a programmer you might have in this building?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 17,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:13:03",
    "content": "I just think that all this stuff is going to be progressive over time.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI just think that all this stuff is going to be progressive over time.",
        "clean_text": "I just think that all this stuff is going to be progressive over time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 18,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:13:05",
    "content": "But in the end case: Llama-10.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut in the end case: Llama-10.",
        "clean_text": "But in the end case: Llama-10.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 19,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:13:10",
    "content": "I think that there's a lot baked into that question. I'm not sure that we're replacing people as much as we’re giving people tools to do more stuff.\n\n**Dwarkesh Patel** 00:13:18\n\nIs the programmer in this building 10x more productive after Llama-10?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think that there's a lot baked into that question.",
        "clean_text": "I think that there's a lot baked into that question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm not sure that we're replacing people as much as we’re giving people tools to do more stuff.",
        "clean_text": "I'm not sure that we're replacing people as much as we’re giving people tools to do more stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "**Dwarkesh Patel** 00:13:18\n\nIs the programmer in this building 10x more productive after Llama-10?",
        "clean_text": "**Dwarkesh Patel** 00:13:18 Is the programmer in this building 10x more productive after Llama-10?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 20,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:13:20",
    "content": "I would hope more. I don't believe that there's a single threshold of intelligence for humanity because people have different skills. I think that at some point AI is probably going to surpass people at most of those things, depending on how powerful the models are. But I think it's progressive and I don't think AGI is one thing. You're basically adding different capabilities. Multimodality is a key one that we're focused on now, initially with photos and images and text but eventually with videos. Because we're so focused on the metaverse, 3D type stuff is important too. One modality that I'm pretty focused on, that I haven't seen as many other people in the industry focus on, is [emotional understanding](https://arxiv.org/abs/2108.10152). So much of the [human brain is just dedicated to understanding people](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5732077/) and understanding expressions and emotions. I think that's its own whole modality, right? You could say that maybe it's just video or image, but it's clearly a very specialized version of those two.\n\nSo there are all these different capabilities that you want to train the models to focus on, in addition to getting a lot better at reasoning and memory, which is its own whole thing. I don't think in the future we're going to be primarily shoving things into a query context window to ask more complicated questions. There will be different stores of memory or different custom models that are more personalized to people. These are all just different capabilities. Obviously then there’s making them big and small. We care about both. If you're running something like Meta AI, that's pretty server-based. We also want it running on smart glasses and there's not a lot of space in smart glasses. So you want to have something that's very efficient for that.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI would hope more.",
        "clean_text": "I would hope more.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I don't believe that there's a single threshold of intelligence for humanity because people have different skills.",
        "clean_text": "I don't believe that there's a single threshold of intelligence for humanity because people have different skills.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I think that at some point AI is probably going to surpass people at most of those things, depending on how powerful the models are.",
        "clean_text": "I think that at some point AI is probably going to surpass people at most of those things, depending on how powerful the models are.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "But I think it's progressive and I don't think AGI is one thing.",
        "clean_text": "But I think it's progressive and I don't think AGI is one thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You're basically adding different capabilities.",
        "clean_text": "You're basically adding different capabilities.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Multimodality is a key one that we're focused on now, initially with photos and images and text but eventually with videos.",
        "clean_text": "Multimodality is a key one that we're focused on now, initially with photos and images and text but eventually with videos.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Because we're so focused on the metaverse, 3D type stuff is important too.",
        "clean_text": "Because we're so focused on the metaverse, 3D type stuff is important too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "One modality that I'm pretty focused on, that I haven't seen as many other people in the industry focus on, is [emotional understanding](https://arxiv.org/abs/2108.10152).",
        "clean_text": "One modality that I'm pretty focused on, that I haven't seen as many other people in the industry focus on, is emotional understanding.",
        "extracted_information": {
          "links": {
            "emotional understanding": "https://arxiv.org/abs/2108.10152"
          },
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "So much of the [human brain is just dedicated to understanding people](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5732077/) and understanding expressions and emotions.",
        "clean_text": "So much of the human brain is just dedicated to understanding people and understanding expressions and emotions.",
        "extracted_information": {
          "links": {
            "human brain is just dedicated to understanding people": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5732077/"
          },
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I think that's its own whole modality, right?",
        "clean_text": "I think that's its own whole modality, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You could say that maybe it's just video or image, but it's clearly a very specialized version of those two.",
        "clean_text": "You could say that maybe it's just video or image, but it's clearly a very specialized version of those two.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "So there are all these different capabilities that you want to train the models to focus on, in addition to getting a lot better at reasoning and memory, which is its own whole thing.",
        "clean_text": "So there are all these different capabilities that you want to train the models to focus on, in addition to getting a lot better at reasoning and memory, which is its own whole thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "I don't think in the future we're going to be primarily shoving things into a query context window to ask more complicated questions.",
        "clean_text": "I don't think in the future we're going to be primarily shoving things into a query context window to ask more complicated questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "There will be different stores of memory or different custom models that are more personalized to people.",
        "clean_text": "There will be different stores of memory or different custom models that are more personalized to people.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "These are all just different capabilities.",
        "clean_text": "These are all just different capabilities.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "Obviously then there’s making them big and small.",
        "clean_text": "Obviously then there’s making them big and small.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "We care about both.",
        "clean_text": "We care about both.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "If you're running something like Meta AI, that's pretty server-based.",
        "clean_text": "If you're running something like Meta AI, that's pretty server-based.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "We also want it running on smart glasses and there's not a lot of space in smart glasses.",
        "clean_text": "We also want it running on smart glasses and there's not a lot of space in smart glasses.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "So you want to have something that's very efficient for that.",
        "clean_text": "So you want to have something that's very efficient for that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 21,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:15:16",
    "content": "If you're doing $10Bs worth of [inference](https://hazelcast.com/glossary/machine-learning-inference/) or even eventually $100Bs, if you're using intelligence in an industrial scale what is the use case? Is it simulations? Is it the AIs that will be in the metaverse? What will we be using the data centers for?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf you're doing $10Bs worth of [inference](https://hazelcast.com/glossary/machine-learning-inference/) or even eventually $100Bs, if you're using intelligence in an industrial scale what is the use case?",
        "clean_text": "If you're doing $10Bs worth of inference or even eventually $100Bs, if you're using intelligence in an industrial scale what is the use case?",
        "extracted_information": {
          "links": {
            "inference": "https://hazelcast.com/glossary/machine-learning-inference/"
          },
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Is it simulations?",
        "clean_text": "Is it simulations?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Is it the AIs that will be in the metaverse?",
        "clean_text": "Is it the AIs that will be in the metaverse?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "What will we be using the data centers for?",
        "clean_text": "What will we be using the data centers for?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 22,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:15:32",
    "content": "Our bet is that it's going to basically change all of the products. I think that there's going to be a kind of Meta AI general assistant product. I think that that will shift from something that feels more like a chatbot, where you ask a question and it formulates an answer, to things where you're giving it more complicated tasks and then it goes away and does them. That's going to take a lot of inference and it's going to take a lot of compute in other ways too.\n\nThen I think interacting with other agents for other people is going to be a big part of what we do, whether it's for businesses or creators. A big part of my theory on this is that there's not going to be just one singular AI that you interact with. Every business is going to want an AI that represents their interests. They're not going to want to primarily interact with you through an AI that is going to sell their competitors’ products.\n\nI think creators is going to be a big one. There are about 200 million creators on our platforms. They basically all have the pattern where they want to engage their community but they're limited by the hours in the day. Their community generally wants to engage them, but they don't know that they're limited by the hours in the day. If you could create something where that creator can basically own the AI, train it in the way they want, and engage their community, I think that's going to be super powerful. There's going to be a ton of engagement across all these things.\n\nThese are just the consumer use cases. My wife and I run our foundation, [Chan Zuckerberg Initiative](https://chanzuckerberg.com/). We're doing a bunch of stuff on science and there's obviously a lot of AI work that is going to advance science and healthcare and all these things. So it will end up affecting basically every area of the products and the economy.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOur bet is that it's going to basically change all of the products.",
        "clean_text": "Our bet is that it's going to basically change all of the products.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think that there's going to be a kind of Meta AI general assistant product.",
        "clean_text": "I think that there's going to be a kind of Meta AI general assistant product.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I think that that will shift from something that feels more like a chatbot, where you ask a question and it formulates an answer, to things where you're giving it more complicated tasks and then it goes away and does them.",
        "clean_text": "I think that that will shift from something that feels more like a chatbot, where you ask a question and it formulates an answer, to things where you're giving it more complicated tasks and then it goes away and does them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "That's going to take a lot of inference and it's going to take a lot of compute in other ways too.",
        "clean_text": "That's going to take a lot of inference and it's going to take a lot of compute in other ways too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Then I think interacting with other agents for other people is going to be a big part of what we do, whether it's for businesses or creators.",
        "clean_text": "Then I think interacting with other agents for other people is going to be a big part of what we do, whether it's for businesses or creators.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "A big part of my theory on this is that there's not going to be just one singular AI that you interact with.",
        "clean_text": "A big part of my theory on this is that there's not going to be just one singular AI that you interact with.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Every business is going to want an AI that represents their interests.",
        "clean_text": "Every business is going to want an AI that represents their interests.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "They're not going to want to primarily interact with you through an AI that is going to sell their competitors’ products.",
        "clean_text": "They're not going to want to primarily interact with you through an AI that is going to sell their competitors’ products.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "I think creators is going to be a big one.",
        "clean_text": "I think creators is going to be a big one.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "There are about 200 million creators on our platforms.",
        "clean_text": "There are about 200 million creators on our platforms.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "They basically all have the pattern where they want to engage their community but they're limited by the hours in the day.",
        "clean_text": "They basically all have the pattern where they want to engage their community but they're limited by the hours in the day.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "Their community generally wants to engage them, but they don't know that they're limited by the hours in the day.",
        "clean_text": "Their community generally wants to engage them, but they don't know that they're limited by the hours in the day.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "If you could create something where that creator can basically own the AI, train it in the way they want, and engage their community, I think that's going to be super powerful.",
        "clean_text": "If you could create something where that creator can basically own the AI, train it in the way they want, and engage their community, I think that's going to be super powerful.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "There's going to be a ton of engagement across all these things.",
        "clean_text": "There's going to be a ton of engagement across all these things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "These are just the consumer use cases.",
        "clean_text": "These are just the consumer use cases.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "My wife and I run our foundation, [Chan Zuckerberg Initiative](https://chanzuckerberg.com/).",
        "clean_text": "My wife and I run our foundation, Chan Zuckerberg Initiative.",
        "extracted_information": {
          "links": {
            "Chan Zuckerberg Initiative": "https://chanzuckerberg.com/"
          },
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "We're doing a bunch of stuff on science and there's obviously a lot of AI work that is going to advance science and healthcare and all these things.",
        "clean_text": "We're doing a bunch of stuff on science and there's obviously a lot of AI work that is going to advance science and healthcare and all these things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "So it will end up affecting basically every area of the products and the economy.",
        "clean_text": "So it will end up affecting basically every area of the products and the economy.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 23,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:17:41",
    "content": "You mentioned AI that can just go out and do something for you that's multi-step. Is that a bigger model? With Llama-4 for example, will there still be a version that's 70B but you'll just train it on the right data and that will be super powerful? What does the progression look like? Is it [scaling](https://www.dwarkeshpatel.com/p/will-scaling-work)? Is it just the same size but different banks like you were talking about?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYou mentioned AI that can just go out and do something for you that's multi-step.",
        "clean_text": "You mentioned AI that can just go out and do something for you that's multi-step.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Is that a bigger model?",
        "clean_text": "Is that a bigger model?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "With Llama-4 for example, will there still be a version that's 70B but you'll just train it on the right data and that will be super powerful?",
        "clean_text": "With Llama-4 for example, will there still be a version that's 70B but you'll just train it on the right data and that will be super powerful?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "What does the progression look like?",
        "clean_text": "What does the progression look like?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Is it [scaling](https://www.dwarkeshpatel.com/p/will-scaling-work)?",
        "clean_text": "Is it scaling?",
        "extracted_information": {
          "links": {
            "scaling": "https://www.dwarkeshpatel.com/p/will-scaling-work"
          },
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Is it just the same size but different banks like you were talking about?",
        "clean_text": "Is it just the same size but different banks like you were talking about?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 24,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:18:02",
    "content": "I don't know that we know the answer to that. I think one thing that seems to be a pattern is that you have the Llama model and then you build some kind of other application specific code around it. Some of it is the [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_/(deep_learning/)) for the use case, but some of it is, for example, logic for how Meta AI should work with tools like Google or Bing to bring in real-time knowledge. That's not part of the base Llama model. For Llama-2, we had some of that and it was a little more hand-engineered. Part of our goal for Llama-3 was to bring more of that into the model itself. For Llama-3, as we start getting into more of these agent-like behaviors, I think some of that is going to be more hand-engineered. Our goal for Llama-4 will be to bring more of that into the model.\n\nAt each step along the way you have a sense of what's going to be possible on the horizon. You start messing with it and hacking around it. I think that helps you then hone your intuition for what you want to try to train into the next version of the model itself. That makes it more general because obviously for anything that you're hand-coding you can unlock some use cases, but it's just inherently brittle and non-general.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI don't know that we know the answer to that.",
        "clean_text": "I don't know that we know the answer to that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think one thing that seems to be a pattern is that you have the Llama model and then you build some kind of other application specific code around it.",
        "clean_text": "I think one thing that seems to be a pattern is that you have the Llama model and then you build some kind of other application specific code around it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Some of it is the [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_/(deep_learning/)) for the use case, but some of it is, for example, logic for how Meta AI should work with tools like Google or Bing to bring in real-time knowledge.",
        "clean_text": "Some of it is the fine-tuning) for the use case, but some of it is, for example, logic for how Meta AI should work with tools like Google or Bing to bring in real-time knowledge.",
        "extracted_information": {
          "links": {
            "fine-tuning": "https://en.wikipedia.org/wiki/Fine-tuning_/(deep_learning/"
          },
          "titles": [
            "/(deep"
          ]
        }
      },
      {
        "index": 3,
        "original_text": "That's not part of the base Llama model.",
        "clean_text": "That's not part of the base Llama model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "For Llama-2, we had some of that and it was a little more hand-engineered.",
        "clean_text": "For Llama-2, we had some of that and it was a little more hand-engineered.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Part of our goal for Llama-3 was to bring more of that into the model itself.",
        "clean_text": "Part of our goal for Llama-3 was to bring more of that into the model itself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "For Llama-3, as we start getting into more of these agent-like behaviors, I think some of that is going to be more hand-engineered.",
        "clean_text": "For Llama-3, as we start getting into more of these agent-like behaviors, I think some of that is going to be more hand-engineered.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Our goal for Llama-4 will be to bring more of that into the model.",
        "clean_text": "Our goal for Llama-4 will be to bring more of that into the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "At each step along the way you have a sense of what's going to be possible on the horizon.",
        "clean_text": "At each step along the way you have a sense of what's going to be possible on the horizon.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You start messing with it and hacking around it.",
        "clean_text": "You start messing with it and hacking around it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "I think that helps you then hone your intuition for what you want to try to train into the next version of the model itself.",
        "clean_text": "I think that helps you then hone your intuition for what you want to try to train into the next version of the model itself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "That makes it more general because obviously for anything that you're hand-coding you can unlock some use cases, but it's just inherently brittle and non-general.",
        "clean_text": "That makes it more general because obviously for anything that you're hand-coding you can unlock some use cases, but it's just inherently brittle and non-general.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 25,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:20:35",
    "content": "When you say “into the model itself,” you train it on the thing that you want in the model itself? What do you mean by “into the model itself”?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhen you say “into the model itself,” you train it on the thing that you want in the model itself?",
        "clean_text": "When you say “into the model itself,” you train it on the thing that you want in the model itself?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What do you mean by “into the model itself”?",
        "clean_text": "What do you mean by “into the model itself”?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 26,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:20:42",
    "content": "For Llama- 2, the tool use was very specific, whereas Llama-3 has much better tool use. We don't have to [hand code](https://en.wikipedia.org/wiki/Hand_coding) all the stuff to have it use Google and go do a search. It can just do that. Similarly for coding and running code and a bunch of stuff like that. Once you kind of get that capability, then you get a peek at what we can start doing next. We don't necessarily want to wait until Llama-4 is around to start building those capabilities, so we can start hacking around it. You do a bunch of hand coding and that makes the products better, if only for the interim. That helps show the way then of what we want to build into the next version of the model.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nFor Llama- 2, the tool use was very specific, whereas Llama-3 has much better tool use.",
        "clean_text": "For Llama- 2, the tool use was very specific, whereas Llama-3 has much better tool use.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We don't have to [hand code](https://en.wikipedia.org/wiki/Hand_coding) all the stuff to have it use Google and go do a search.",
        "clean_text": "We don't have to hand code all the stuff to have it use Google and go do a search.",
        "extracted_information": {
          "links": {
            "hand code": "https://en.wikipedia.org/wiki/Hand_coding"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It can just do that.",
        "clean_text": "It can just do that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Similarly for coding and running code and a bunch of stuff like that.",
        "clean_text": "Similarly for coding and running code and a bunch of stuff like that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Once you kind of get that capability, then you get a peek at what we can start doing next.",
        "clean_text": "Once you kind of get that capability, then you get a peek at what we can start doing next.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "We don't necessarily want to wait until Llama-4 is around to start building those capabilities, so we can start hacking around it.",
        "clean_text": "We don't necessarily want to wait until Llama-4 is around to start building those capabilities, so we can start hacking around it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "You do a bunch of hand coding and that makes the products better, if only for the interim.",
        "clean_text": "You do a bunch of hand coding and that makes the products better, if only for the interim.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "That helps show the way then of what we want to build into the next version of the model.",
        "clean_text": "That helps show the way then of what we want to build into the next version of the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 27,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:21:37",
    "content": "What is the community fine tune of Llama-3 that you're most excited for? Maybe not the one that will be most useful to you, but the one you'll just enjoy playing with the most. They fine-tune it on antiquity and you'll just be talking to Virgil or something. What are you excited about?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat is the community fine tune of Llama-3 that you're most excited for?",
        "clean_text": "What is the community fine tune of Llama-3 that you're most excited for?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Maybe not the one that will be most useful to you, but the one you'll just enjoy playing with the most.",
        "clean_text": "Maybe not the one that will be most useful to you, but the one you'll just enjoy playing with the most.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "They fine-tune it on antiquity and you'll just be talking to Virgil or something.",
        "clean_text": "They fine-tune it on antiquity and you'll just be talking to Virgil or something.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "What are you excited about?",
        "clean_text": "What are you excited about?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 28,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:21:50",
    "content": "I think the nature of the stuff is that you get surprised. Any specific thing that I thought would be valuable, we'd probably be building. I think you'll get [distilled versions](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.). I think you'll get smaller versions. One thing is that I think 8B isn’t quite small enough for a bunch of use cases. Over time I'd love to get a 1-2B parameter model, or even a 500M parameter model and see what you can do with that.\n\nIf with 8B parameters we’re nearly as powerful as the largest Llama-2 model, then with a billion parameters you should be able to do something that's interesting, and faster. It’d be good for classification, or a lot of basic things that people do before understanding the intent of a user query and feeding it to the most powerful model to hone in on what the prompt should be. I think that's one thing that maybe the community can help fill in. We're also thinking about getting around to distilling some of these ourselves but right now the GPUs are pegged training the 405B.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think the nature of the stuff is that you get surprised.",
        "clean_text": "I think the nature of the stuff is that you get surprised.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Any specific thing that I thought would be valuable, we'd probably be building.",
        "clean_text": "Any specific thing that I thought would be valuable, we'd probably be building.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I think you'll get [distilled versions](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.).",
        "clean_text": "I think you'll get distilled versions.",
        "extracted_information": {
          "links": {
            "distilled versions": "https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized."
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I think you'll get smaller versions.",
        "clean_text": "I think you'll get smaller versions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "One thing is that I think 8B isn’t quite small enough for a bunch of use cases.",
        "clean_text": "One thing is that I think 8B isn’t quite small enough for a bunch of use cases.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Over time I'd love to get a 1-2B parameter model, or even a 500M parameter model and see what you can do with that.",
        "clean_text": "Over time I'd love to get a 1-2B parameter model, or even a 500M parameter model and see what you can do with that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "If with 8B parameters we’re nearly as powerful as the largest Llama-2 model, then with a billion parameters you should be able to do something that's interesting, and faster.",
        "clean_text": "If with 8B parameters we’re nearly as powerful as the largest Llama-2 model, then with a billion parameters you should be able to do something that's interesting, and faster.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It’d be good for classification, or a lot of basic things that people do before understanding the intent of a user query and feeding it to the most powerful model to hone in on what the prompt should be.",
        "clean_text": "It’d be good for classification, or a lot of basic things that people do before understanding the intent of a user query and feeding it to the most powerful model to hone in on what the prompt should be.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "I think that's one thing that maybe the community can help fill in.",
        "clean_text": "I think that's one thing that maybe the community can help fill in.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "We're also thinking about getting around to distilling some of these ourselves but right now the GPUs are pegged training the 405B.",
        "clean_text": "We're also thinking about getting around to distilling some of these ourselves but right now the GPUs are pegged training the 405B.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 29,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:23:12",
    "content": "So you have all these GPUs. I think you said 350,000 by the end of the year.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSo you have all these GPUs.",
        "clean_text": "So you have all these GPUs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think you said 350,000 by the end of the year.",
        "clean_text": "I think you said 350,000 by the end of the year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 30,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:23:18",
    "content": "That's the whole fleet. We built two, I think 22,000 or 24,000 clusters that are the single clusters that we have for training the big models, obviously across a lot of the stuff that we do. A lot of our stuff goes towards training Reels models and [Facebook News Feed](https://transparency.meta.com/features/explaining-ranking/fb-feed) and [Instagram Feed](https://transparency.meta.com/features/explaining-ranking/ig-feed/). Inference is a huge thing for us because we serve a ton of people. Our ratio of inference compute required to training is probably much higher than most other companies that are doing this stuff just because of the sheer volume of the community that we're serving.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's the whole fleet.",
        "clean_text": "That's the whole fleet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We built two, I think 22,000 or 24,000 clusters that are the single clusters that we have for training the big models, obviously across a lot of the stuff that we do.",
        "clean_text": "We built two, I think 22,000 or 24,000 clusters that are the single clusters that we have for training the big models, obviously across a lot of the stuff that we do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "A lot of our stuff goes towards training Reels models and [Facebook News Feed](https://transparency.meta.com/features/explaining-ranking/fb-feed) and [Instagram Feed](https://transparency.meta.com/features/explaining-ranking/ig-feed/).",
        "clean_text": "A lot of our stuff goes towards training Reels models and Facebook News Feed and Instagram Feed.",
        "extracted_information": {
          "links": {
            "Facebook News Feed": "https://transparency.meta.com/features/explaining-ranking/fb-feed",
            "Instagram Feed": "https://transparency.meta.com/features/explaining-ranking/ig-feed/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Inference is a huge thing for us because we serve a ton of people.",
        "clean_text": "Inference is a huge thing for us because we serve a ton of people.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Our ratio of inference compute required to training is probably much higher than most other companies that are doing this stuff just because of the sheer volume of the community that we're serving.",
        "clean_text": "Our ratio of inference compute required to training is probably much higher than most other companies that are doing this stuff just because of the sheer volume of the community that we're serving.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 31,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:23:56",
    "content": "In the material they shared with me before, it was really interesting that you trained it on more data than is [compute optimal](https://arxiv.org/abs/2203.15556) just for training. The inference is such a big deal for you guys, and also for the community, that it makes sense to just have this thing and have trillions of tokens in there.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIn the material they shared with me before, it was really interesting that you trained it on more data than is [compute optimal](https://arxiv.org/abs/2203.15556) just for training.",
        "clean_text": "In the material they shared with me before, it was really interesting that you trained it on more data than is compute optimal just for training.",
        "extracted_information": {
          "links": {
            "compute optimal": "https://arxiv.org/abs/2203.15556"
          },
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The inference is such a big deal for you guys, and also for the community, that it makes sense to just have this thing and have trillions of tokens in there.",
        "clean_text": "The inference is such a big deal for you guys, and also for the community, that it makes sense to just have this thing and have trillions of tokens in there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 32,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:24:08",
    "content": "Although one of the interesting things about it, even with the 70B, is that we thought it would get more [saturated](http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_SSCI_2015/data/7560b423.pdf). We trained it on around 15 trillion tokens. I guess our prediction going in was that it was going to asymptote more, but even by the end it was still learning. We probably could have fed it more tokens and it would have gotten somewhat better.\n\nAt some point you're running a company and you need to do these meta reasoning questions. Do I want to spend our GPUs on training the 70B model further? Do we want to get on with it so we can start testing hypotheses for Llama-4? We needed to make that call and I think we got a reasonable balance for this version of the 70B. There'll be others in the future, the 70B multimodal one, that'll come over the next period. But that was fascinating that the architectures at this point can just take so much data.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAlthough one of the interesting things about it, even with the 70B, is that we thought it would get more [saturated](http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_SSCI_2015/data/7560b423.pdf).",
        "clean_text": "Although one of the interesting things about it, even with the 70B, is that we thought it would get more saturated.",
        "extracted_information": {
          "links": {
            "saturated": "http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_SSCI_2015/data/7560b423.pdf"
          },
          "titles": [
            "CDs/IEEE"
          ]
        }
      },
      {
        "index": 1,
        "original_text": "We trained it on around 15 trillion tokens.",
        "clean_text": "We trained it on around 15 trillion tokens.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I guess our prediction going in was that it was going to asymptote more, but even by the end it was still learning.",
        "clean_text": "I guess our prediction going in was that it was going to asymptote more, but even by the end it was still learning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We probably could have fed it more tokens and it would have gotten somewhat better.",
        "clean_text": "We probably could have fed it more tokens and it would have gotten somewhat better.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "At some point you're running a company and you need to do these meta reasoning questions.",
        "clean_text": "At some point you're running a company and you need to do these meta reasoning questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Do I want to spend our GPUs on training the 70B model further?",
        "clean_text": "Do I want to spend our GPUs on training the 70B model further?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Do we want to get on with it so we can start testing hypotheses for Llama-4?",
        "clean_text": "Do we want to get on with it so we can start testing hypotheses for Llama-4?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "We needed to make that call and I think we got a reasonable balance for this version of the 70B.",
        "clean_text": "We needed to make that call and I think we got a reasonable balance for this version of the 70B.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "There'll be others in the future, the 70B multimodal one, that'll come over the next period.",
        "clean_text": "There'll be others in the future, the 70B multimodal one, that'll come over the next period.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "But that was fascinating that the architectures at this point can just take so much data.",
        "clean_text": "But that was fascinating that the architectures at this point can just take so much data.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 33,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:25:11",
    "content": "That's really interesting. What does this imply about future models? You mentioned that the Llama-3 8B is better than the Llama-2 70B.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's really interesting.",
        "clean_text": "That's really interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What does this imply about future models?",
        "clean_text": "What does this imply about future models?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You mentioned that the Llama-3 8B is better than the Llama-2 70B.",
        "clean_text": "You mentioned that the Llama-3 8B is better than the Llama-2 70B.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 34,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:25:19",
    "content": "No, no, it's nearly as good. I don’t want to overstate it. It’s in a similar order of magnitude.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNo, no, it's nearly as good.",
        "clean_text": "No, no, it's nearly as good.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I don’t want to overstate it.",
        "clean_text": "I don’t want to overstate it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "It’s in a similar order of magnitude.",
        "clean_text": "It’s in a similar order of magnitude.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 35,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:25:24",
    "content": "Does that mean the Llama-4 70B will be as good as the Llama-3 405B? What does the future of this look like?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nDoes that mean the Llama-4 70B will be as good as the Llama-3 405B?",
        "clean_text": "Does that mean the Llama-4 70B will be as good as the Llama-3 405B?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What does the future of this look like?",
        "clean_text": "What does the future of this look like?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 36,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:25:30",
    "content": "This is one of the great questions, right? I think no one knows. One of the trickiest things in the world to plan around is an exponential curve. How long does it keep going for? I think it's likely enough that we'll keep going. I think it’s worth investing the $10Bs or $100B+ in building the infrastructure and assuming that if it keeps going you're going to get some really amazing things that are going to make amazing products. I don't think anyone in the industry can really tell you that it will continue scaling at that rate for sure. In general in history, you hit bottlenecks at certain points. Now there's so much energy on this that maybe those bottlenecks get knocked over pretty quickly. I think that’s an interesting question.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThis is one of the great questions, right?",
        "clean_text": "This is one of the great questions, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think no one knows.",
        "clean_text": "I think no one knows.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "One of the trickiest things in the world to plan around is an exponential curve.",
        "clean_text": "One of the trickiest things in the world to plan around is an exponential curve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "How long does it keep going for?",
        "clean_text": "How long does it keep going for?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I think it's likely enough that we'll keep going.",
        "clean_text": "I think it's likely enough that we'll keep going.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I think it’s worth investing the $10Bs or $100B+ in building the infrastructure and assuming that if it keeps going you're going to get some really amazing things that are going to make amazing products.",
        "clean_text": "I think it’s worth investing the $10Bs or $100B+ in building the infrastructure and assuming that if it keeps going you're going to get some really amazing things that are going to make amazing products.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I don't think anyone in the industry can really tell you that it will continue scaling at that rate for sure.",
        "clean_text": "I don't think anyone in the industry can really tell you that it will continue scaling at that rate for sure.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "In general in history, you hit bottlenecks at certain points.",
        "clean_text": "In general in history, you hit bottlenecks at certain points.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Now there's so much energy on this that maybe those bottlenecks get knocked over pretty quickly.",
        "clean_text": "Now there's so much energy on this that maybe those bottlenecks get knocked over pretty quickly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I think that’s an interesting question.",
        "clean_text": "I think that’s an interesting question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 37,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:26:24",
    "content": "What does the world look like where there aren't these bottlenecks? Suppose progress just continues at this pace, which seems plausible. Zooming out and forgetting about Llamas…",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat does the world look like where there aren't these bottlenecks?",
        "clean_text": "What does the world look like where there aren't these bottlenecks?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Suppose progress just continues at this pace, which seems plausible.",
        "clean_text": "Suppose progress just continues at this pace, which seems plausible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Zooming out and forgetting about Llamas…",
        "clean_text": "Zooming out and forgetting about Llamas…",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 38,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:26:33",
    "content": "Well, there are going to be different bottlenecks. Over the last few years, I think there was this [issue of GPU production](https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html). Even companies that had the money to pay for the GPUs couldn't necessarily get as many as they wanted because there were all these supply constraints. Now I think that's sort of getting less. So you're seeing a bunch of companies thinking now about investing a lot of money in building out these things. I think that that will go on for some period of time. There is a capital question. At what point does it stop being worth it to put the capital in?\n\nI actually think before we hit that, you're going to run into [energy constraints](https://nationalinterest.org/blog/techland/promise-and-peril-ai-power-grid-208858). I don't think anyone's built a gigawatt single training cluster yet. You run into these things that just end up being slower in the world. Getting energy permitted is a very heavily regulated government function. You're going from software, which is somewhat regulated and I'd argue it’s more regulated than a lot of people in the tech community feel. Obviously it’s different if you're starting a small company, maybe you feel that less. We interact with different governments and regulators and we have lots of rules that we need to follow and make sure we do a good job with around the world. But I think that there's no doubt about energy.\n\nIf you're talking about building large new power plants or large build-outs and then building transmission lines that cross other private or public land, that’s just a heavily regulated thing. You're talking about many years of lead time. If we wanted to stand up some massive facility, powering that is a very long-term project. I think people do it but I don't think this is something that can be quite as magical as just getting to a level of AI, getting a bunch of capital and putting it in, and then all of a sudden the models are just going to… You do hit different bottlenecks along the way.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWell, there are going to be different bottlenecks.",
        "clean_text": "Well, there are going to be different bottlenecks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Over the last few years, I think there was this [issue of GPU production](https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html).",
        "clean_text": "Over the last few years, I think there was this issue of GPU production.",
        "extracted_information": {
          "links": {
            "issue of GPU production": "https://www.nytimes.com/2023/08/16/technology/ai-gpu-chips-shortage.html"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Even companies that had the money to pay for the GPUs couldn't necessarily get as many as they wanted because there were all these supply constraints.",
        "clean_text": "Even companies that had the money to pay for the GPUs couldn't necessarily get as many as they wanted because there were all these supply constraints.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Now I think that's sort of getting less.",
        "clean_text": "Now I think that's sort of getting less.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "So you're seeing a bunch of companies thinking now about investing a lot of money in building out these things.",
        "clean_text": "So you're seeing a bunch of companies thinking now about investing a lot of money in building out these things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I think that that will go on for some period of time.",
        "clean_text": "I think that that will go on for some period of time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There is a capital question.",
        "clean_text": "There is a capital question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "At what point does it stop being worth it to put the capital in?",
        "clean_text": "At what point does it stop being worth it to put the capital in?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "I actually think before we hit that, you're going to run into [energy constraints](https://nationalinterest.org/blog/techland/promise-and-peril-ai-power-grid-208858).",
        "clean_text": "I actually think before we hit that, you're going to run into energy constraints.",
        "extracted_information": {
          "links": {
            "energy constraints": "https://nationalinterest.org/blog/techland/promise-and-peril-ai-power-grid-208858"
          },
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I don't think anyone's built a gigawatt single training cluster yet.",
        "clean_text": "I don't think anyone's built a gigawatt single training cluster yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You run into these things that just end up being slower in the world.",
        "clean_text": "You run into these things that just end up being slower in the world.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "Getting energy permitted is a very heavily regulated government function.",
        "clean_text": "Getting energy permitted is a very heavily regulated government function.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "You're going from software, which is somewhat regulated and I'd argue it’s more regulated than a lot of people in the tech community feel.",
        "clean_text": "You're going from software, which is somewhat regulated and I'd argue it’s more regulated than a lot of people in the tech community feel.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Obviously it’s different if you're starting a small company, maybe you feel that less.",
        "clean_text": "Obviously it’s different if you're starting a small company, maybe you feel that less.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "We interact with different governments and regulators and we have lots of rules that we need to follow and make sure we do a good job with around the world.",
        "clean_text": "We interact with different governments and regulators and we have lots of rules that we need to follow and make sure we do a good job with around the world.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "But I think that there's no doubt about energy.",
        "clean_text": "But I think that there's no doubt about energy.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "If you're talking about building large new power plants or large build-outs and then building transmission lines that cross other private or public land, that’s just a heavily regulated thing.",
        "clean_text": "If you're talking about building large new power plants or large build-outs and then building transmission lines that cross other private or public land, that’s just a heavily regulated thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "You're talking about many years of lead time.",
        "clean_text": "You're talking about many years of lead time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "If we wanted to stand up some massive facility, powering that is a very long-term project.",
        "clean_text": "If we wanted to stand up some massive facility, powering that is a very long-term project.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "I think people do it but I don't think this is something that can be quite as magical as just getting to a level of AI, getting a bunch of capital and putting it in, and then all of a sudden the models are just going to… You do hit different bottlenecks along the way.",
        "clean_text": "I think people do it but I don't think this is something that can be quite as magical as just getting to a level of AI, getting a bunch of capital and putting it in, and then all of a sudden the models are just going to… You do hit different bottlenecks along the way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 39,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:29:00",
    "content": "Is there something, maybe an AI-related project or maybe not, that even a company like Meta doesn't have the resources for? Something where if your [R&D](https://www.investopedia.com/terms/r/randd.asp) budget or capex budget were 10x what it is now, then you could pursue it? Something that’s in the back of your mind but with Meta today, you can't even issue stock or bonds for it? It's just like 10x bigger than your budget?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIs there something, maybe an AI-related project or maybe not, that even a company like Meta doesn't have the resources for?",
        "clean_text": "Is there something, maybe an AI-related project or maybe not, that even a company like Meta doesn't have the resources for?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Something where if your [R&D](https://www.investopedia.com/terms/r/randd.asp) budget or capex budget were 10x what it is now, then you could pursue it?",
        "clean_text": "Something where if your R&D budget or capex budget were 10x what it is now, then you could pursue it?",
        "extracted_information": {
          "links": {
            "R&D": "https://www.investopedia.com/terms/r/randd.asp"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Something that’s in the back of your mind but with Meta today, you can't even issue stock or bonds for it?",
        "clean_text": "Something that’s in the back of your mind but with Meta today, you can't even issue stock or bonds for it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It's just like 10x bigger than your budget?",
        "clean_text": "It's just like 10x bigger than your budget?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 40,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:29:19",
    "content": "I think energy is one piece. I think we would probably build out bigger clusters than we currently can if we could get the energy to do it.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think energy is one piece.",
        "clean_text": "I think energy is one piece.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think we would probably build out bigger clusters than we currently can if we could get the energy to do it.",
        "clean_text": "I think we would probably build out bigger clusters than we currently can if we could get the energy to do it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 41,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:29:34",
    "content": "That's fundamentally money-bottlenecked in the limit? If you had $1 trillion…",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's fundamentally money-bottlenecked in the limit?",
        "clean_text": "That's fundamentally money-bottlenecked in the limit?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If you had $1 trillion…",
        "clean_text": "If you had $1 trillion…",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 42,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:29:39",
    "content": "I think it’s time. It depends on how far the exponential curves go. Right now a lot of data centers are on the order of 50 megawatts or 100MW, or a big one might be 150MW. Take a whole data center and fill it up with all the stuff that you need to do for training and you build the biggest cluster you can. I think a bunch of companies are running at stuff like that.\n\nBut when you start getting into building a data center that's like 300MW or 500MW or 1 GW, no one has built a 1GW data center yet. I think it will happen. This is only a matter of time but it's not going to be next year. Some of these things will take some number of years to build out. Just to put this in perspective, I think a gigawatt would be [the size of a meaningful nuclear power plant](https://www.energy.gov/ne/articles/infographic-how-much-power-does-nuclear-reactor-produce) only going towards training a model.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think it’s time.",
        "clean_text": "I think it’s time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It depends on how far the exponential curves go.",
        "clean_text": "It depends on how far the exponential curves go.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Right now a lot of data centers are on the order of 50 megawatts or 100MW, or a big one might be 150MW.",
        "clean_text": "Right now a lot of data centers are on the order of 50 megawatts or 100MW, or a big one might be 150MW.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Take a whole data center and fill it up with all the stuff that you need to do for training and you build the biggest cluster you can.",
        "clean_text": "Take a whole data center and fill it up with all the stuff that you need to do for training and you build the biggest cluster you can.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I think a bunch of companies are running at stuff like that.",
        "clean_text": "I think a bunch of companies are running at stuff like that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "But when you start getting into building a data center that's like 300MW or 500MW or 1 GW, no one has built a 1GW data center yet.",
        "clean_text": "But when you start getting into building a data center that's like 300MW or 500MW or 1 GW, no one has built a 1GW data center yet.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I think it will happen.",
        "clean_text": "I think it will happen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "This is only a matter of time but it's not going to be next year.",
        "clean_text": "This is only a matter of time but it's not going to be next year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Some of these things will take some number of years to build out.",
        "clean_text": "Some of these things will take some number of years to build out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Just to put this in perspective, I think a gigawatt would be [the size of a meaningful nuclear power plant](https://www.energy.gov/ne/articles/infographic-how-much-power-does-nuclear-reactor-produce) only going towards training a model.",
        "clean_text": "Just to put this in perspective, I think a gigawatt would be the size of a meaningful nuclear power plant only going towards training a model.",
        "extracted_information": {
          "links": {
            "the size of a meaningful nuclear power plant": "https://www.energy.gov/ne/articles/infographic-how-much-power-does-nuclear-reactor-produce"
          },
          "titles": []
        }
      }
    ]
  },
  {
    "index": 43,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:30:51",
    "content": "Didn't [Amazon do this](https://www.costar.com/article/1471314418/amazon-pays-650-million-for-nuclear-powered-data-center-in-pennsylvania)? They have a 950MW–",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nDidn't [Amazon do this](https://www.costar.com/article/1471314418/amazon-pays-650-million-for-nuclear-powered-data-center-in-pennsylvania)?",
        "clean_text": "Didn't Amazon do this?",
        "extracted_information": {
          "links": {
            "Amazon do this": "https://www.costar.com/article/1471314418/amazon-pays-650-million-for-nuclear-powered-data-center-in-pennsylvania"
          },
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "They have a 950MW–",
        "clean_text": "They have a 950MW–",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 44,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:30:55",
    "content": "I'm not exactly sure what they did. You'd have to ask them.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'm not exactly sure what they did.",
        "clean_text": "I'm not exactly sure what they did.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You'd have to ask them.",
        "clean_text": "You'd have to ask them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 45,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:31:00",
    "content": "But it doesn’t have to be in the same place, right? If [distributed training](https://www.run.ai/guides/gpu-deep-learning/distributed-training#:~:text=As%20its%20name%20suggests%2C%20distributed,to%20accelerate%20the%20training%20process.) works, it can be distributed.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut it doesn’t have to be in the same place, right?",
        "clean_text": "But it doesn’t have to be in the same place, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If [distributed training](https://www.run.ai/guides/gpu-deep-learning/distributed-training#:~:text=As%20its%20name%20suggests%2C%20distributed,to%20accelerate%20the%20training%20process.)",
        "clean_text": "If distributed training",
        "extracted_information": {
          "links": {
            "distributed training": "https://www.run.ai/guides/gpu-deep-learning/distributed-training#:~:text=As%20its%20name%20suggests%2C%20distributed,to%20accelerate%20the%20training%20process."
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "works, it can be distributed.",
        "clean_text": "works, it can be distributed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 46,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:31:03",
    "content": "Well, I think that is a big question, how that's going to work. It seems quite possible that in the future, more of what we call training for these big models is actually more along the lines of inference generating [synthetic data](https://en.wikipedia.org/wiki/Synthetic_data#Machine_learning) to then go feed into the model. I don't know what that ratio is going to be but I consider the generation of synthetic data to be more inference than training today. Obviously if you're doing it in order to train a model, it's part of the broader training process. So that's an open question, the balance of that and how that plays out.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWell, I think that is a big question, how that's going to work.",
        "clean_text": "Well, I think that is a big question, how that's going to work.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It seems quite possible that in the future, more of what we call training for these big models is actually more along the lines of inference generating [synthetic data](https://en.wikipedia.org/wiki/Synthetic_data#Machine_learning) to then go feed into the model.",
        "clean_text": "It seems quite possible that in the future, more of what we call training for these big models is actually more along the lines of inference generating synthetic data to then go feed into the model.",
        "extracted_information": {
          "links": {
            "synthetic data": "https://en.wikipedia.org/wiki/Synthetic_data#Machine_learning"
          },
          "titles": [
            "data#Machine"
          ]
        }
      },
      {
        "index": 2,
        "original_text": "I don't know what that ratio is going to be but I consider the generation of synthetic data to be more inference than training today.",
        "clean_text": "I don't know what that ratio is going to be but I consider the generation of synthetic data to be more inference than training today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Obviously if you're doing it in order to train a model, it's part of the broader training process.",
        "clean_text": "Obviously if you're doing it in order to train a model, it's part of the broader training process.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "So that's an open question, the balance of that and how that plays out.",
        "clean_text": "So that's an open question, the balance of that and how that plays out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 47,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:31:44",
    "content": "Would that potentially also be the case with Llama-3, and maybe Llama-4 onwards? As in, you put this out and if somebody has a ton of compute, then they can just keep making these things arbitrarily smarter using the models that you've put out. Let’s say there’s some random country, like Kuwait or the UAE, that has a ton of compute and they can actually just use Llama-4 to make something much smarter.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWould that potentially also be the case with Llama-3, and maybe Llama-4 onwards?",
        "clean_text": "Would that potentially also be the case with Llama-3, and maybe Llama-4 onwards?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "As in, you put this out and if somebody has a ton of compute, then they can just keep making these things arbitrarily smarter using the models that you've put out.",
        "clean_text": "As in, you put this out and if somebody has a ton of compute, then they can just keep making these things arbitrarily smarter using the models that you've put out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Let’s say there’s some random country, like Kuwait or the UAE, that has a ton of compute and they can actually just use Llama-4 to make something much smarter.",
        "clean_text": "Let’s say there’s some random country, like Kuwait or the UAE, that has a ton of compute and they can actually just use Llama-4 to make something much smarter.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 48,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:32:08",
    "content": "I do think there are going to be dynamics like that, but I also think there is a fundamental limitation on the model architecture. I think like a 70B model that we trained with a Llama-3 architecture can get better, it can keep going. As I was saying, we felt that if we kept on feeding it more data or rotated the high value [tokens](https://techpolicyinstitute.org/publications/artificial-intelligence/from-tokens-to-context-windows-simplifying-ai-jargon/) through again, then it would continue getting better. We've seen a bunch of different companies around the world basically take the Llama-2 70B model architecture and then build a new model. But it's still the case that when you make a generational improvement to something like the Llama-3 70B or the Llama-3 405B, there isn’t anything like that open source today. I think that's a big step function. What people are going to be able to build on top of that I think can’t go infinitely from there. There can be some optimization in that until you get to the next step function.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI do think there are going to be dynamics like that, but I also think there is a fundamental limitation on the model architecture.",
        "clean_text": "I do think there are going to be dynamics like that, but I also think there is a fundamental limitation on the model architecture.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think like a 70B model that we trained with a Llama-3 architecture can get better, it can keep going.",
        "clean_text": "I think like a 70B model that we trained with a Llama-3 architecture can get better, it can keep going.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "As I was saying, we felt that if we kept on feeding it more data or rotated the high value [tokens](https://techpolicyinstitute.org/publications/artificial-intelligence/from-tokens-to-context-windows-simplifying-ai-jargon/) through again, then it would continue getting better.",
        "clean_text": "As I was saying, we felt that if we kept on feeding it more data or rotated the high value tokens through again, then it would continue getting better.",
        "extracted_information": {
          "links": {
            "tokens": "https://techpolicyinstitute.org/publications/artificial-intelligence/from-tokens-to-context-windows-simplifying-ai-jargon/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We've seen a bunch of different companies around the world basically take the Llama-2 70B model architecture and then build a new model.",
        "clean_text": "We've seen a bunch of different companies around the world basically take the Llama-2 70B model architecture and then build a new model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "But it's still the case that when you make a generational improvement to something like the Llama-3 70B or the Llama-3 405B, there isn’t anything like that open source today.",
        "clean_text": "But it's still the case that when you make a generational improvement to something like the Llama-3 70B or the Llama-3 405B, there isn’t anything like that open source today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I think that's a big step function.",
        "clean_text": "I think that's a big step function.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "What people are going to be able to build on top of that I think can’t go infinitely from there.",
        "clean_text": "What people are going to be able to build on top of that I think can’t go infinitely from there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "There can be some optimization in that until you get to the next step function.",
        "clean_text": "There can be some optimization in that until you get to the next step function.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 49,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:33:20",
    "content": "Let's zoom out a little bit from specific models and even the multi-year lead times you would need to get energy approvals and so on. Big picture, what's happening with AI these next couple of decades? Does it feel like another technology like the metaverse or social, or does it feel like a fundamentally different thing in the course of human history?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet's zoom out a little bit from specific models and even the multi-year lead times you would need to get energy approvals and so on.",
        "clean_text": "Let's zoom out a little bit from specific models and even the multi-year lead times you would need to get energy approvals and so on.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Big picture, what's happening with AI these next couple of decades?",
        "clean_text": "Big picture, what's happening with AI these next couple of decades?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Does it feel like another technology like the metaverse or social, or does it feel like a fundamentally different thing in the course of human history?",
        "clean_text": "Does it feel like another technology like the metaverse or social, or does it feel like a fundamentally different thing in the course of human history?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 50,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:33:43",
    "content": "I think it's going to be pretty fundamental. I think it's going to be more like the creation of computing in the first place. You'll get all these new apps in the same way as when you got the web or you got mobile phones. People basically rethought all these experiences as a lot of things that weren't possible before became possible. So I think that will happen, but I think it's a much [lower-level](https://en.wikipedia.org/wiki/High-_and_low-level#:~:text=In%20computer%20science%2C%20software%20is,hardware%20drivers%2C%20etc.\\).) innovation. My sense is that it's going to be more like people going from not having computers to having computers.\n\nIt’s very hard to reason about exactly how this goes. In the cosmic scale obviously it'll happen quickly, over a couple of decades or something. There is some set of people who are afraid of it really spinning out and going from being somewhat intelligent to extremely intelligent overnight. I just think that there's all these physical constraints that make that unlikely to happen. I just don't really see that playing out. I think we'll have time to acclimate a bit. But it will really change the way that we work and give people all these creative tools to do different things. I think it's going to really enable people to do the things that they want a lot more.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think it's going to be pretty fundamental.",
        "clean_text": "I think it's going to be pretty fundamental.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think it's going to be more like the creation of computing in the first place.",
        "clean_text": "I think it's going to be more like the creation of computing in the first place.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You'll get all these new apps in the same way as when you got the web or you got mobile phones.",
        "clean_text": "You'll get all these new apps in the same way as when you got the web or you got mobile phones.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "People basically rethought all these experiences as a lot of things that weren't possible before became possible.",
        "clean_text": "People basically rethought all these experiences as a lot of things that weren't possible before became possible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "So I think that will happen, but I think it's a much [lower-level](https://en.wikipedia.org/wiki/High-_and_low-level#:~:text=In%20computer%20science%2C%20software%20is,hardware%20drivers%2C%20etc.\\).)",
        "clean_text": "So I think that will happen, but I think it's a much lower-level.)",
        "extracted_information": {
          "links": {
            "lower-level": "https://en.wikipedia.org/wiki/High-_and_low-level#:~:text=In%20computer%20science%2C%20software%20is,hardware%20drivers%2C%20etc.\\"
          },
          "titles": [
            "and"
          ]
        }
      },
      {
        "index": 5,
        "original_text": "innovation.",
        "clean_text": "innovation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "My sense is that it's going to be more like people going from not having computers to having computers.",
        "clean_text": "My sense is that it's going to be more like people going from not having computers to having computers.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It’s very hard to reason about exactly how this goes.",
        "clean_text": "It’s very hard to reason about exactly how this goes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "In the cosmic scale obviously it'll happen quickly, over a couple of decades or something.",
        "clean_text": "In the cosmic scale obviously it'll happen quickly, over a couple of decades or something.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "There is some set of people who are afraid of it really spinning out and going from being somewhat intelligent to extremely intelligent overnight.",
        "clean_text": "There is some set of people who are afraid of it really spinning out and going from being somewhat intelligent to extremely intelligent overnight.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "I just think that there's all these physical constraints that make that unlikely to happen.",
        "clean_text": "I just think that there's all these physical constraints that make that unlikely to happen.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "I just don't really see that playing out.",
        "clean_text": "I just don't really see that playing out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "I think we'll have time to acclimate a bit.",
        "clean_text": "I think we'll have time to acclimate a bit.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "But it will really change the way that we work and give people all these creative tools to do different things.",
        "clean_text": "But it will really change the way that we work and give people all these creative tools to do different things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "I think it's going to really enable people to do the things that they want a lot more.",
        "clean_text": "I think it's going to really enable people to do the things that they want a lot more.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 51,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:35:18",
    "content": "So maybe not overnight, but is it your view that on a cosmic scale we can think of these milestones in this way? Humans evolved, and then AI happened, and then they went out into the galaxy. Maybe it takes many decades, maybe it takes a century, but is that the grand scheme of what's happening right now in history?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSo maybe not overnight, but is it your view that on a cosmic scale we can think of these milestones in this way?",
        "clean_text": "So maybe not overnight, but is it your view that on a cosmic scale we can think of these milestones in this way?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Humans evolved, and then AI happened, and then they went out into the galaxy.",
        "clean_text": "Humans evolved, and then AI happened, and then they went out into the galaxy.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "Maybe it takes many decades, maybe it takes a century, but is that the grand scheme of what's happening right now in history?",
        "clean_text": "Maybe it takes many decades, maybe it takes a century, but is that the grand scheme of what's happening right now in history?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 52,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:35:38",
    "content": "Sorry, in what sense?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSorry, in what sense?",
        "clean_text": "Sorry, in what sense?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 53,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:35:40",
    "content": "In the sense that there were other technologies, like computers and even fire, but the development of AI itself is as significant as humans evolving in the first place.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIn the sense that there were other technologies, like computers and even fire, but the development of AI itself is as significant as humans evolving in the first place.",
        "clean_text": "In the sense that there were other technologies, like computers and even fire, but the development of AI itself is as significant as humans evolving in the first place.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 54,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:35:48",
    "content": "I think that's tricky. The history of humanity has been people basically thinking that certain aspects of humanity are really unique in different ways and then coming to grips with the fact that that's not true, but that humanity is actually still super special. We thought that the earth was the center of the universe and it's not, but humans are still pretty awesome and pretty unique, right?\n\nI think another bias that people tend to have is thinking that [intelligence is somehow fundamentally connected to life](https://plato.stanford.edu/entries/artificial-intelligence/). It's not actually clear that it is. I don't know that we have a clear enough definition of [consciousness](https://plato.stanford.edu/entries/consciousness/) or [life](https://plato.stanford.edu/entries/life/) to fully interrogate this. There's all this science fiction about creating intelligence where it starts to take on all these human-like behaviors and things like that. The current incarnation of all this stuff feels like it's going in a direction where intelligence can be pretty separated from consciousness, [agency](https://plato.stanford.edu/entries/agency/), and things like that, which I think just makes it a super valuable tool.\n\nObviously it's very difficult to predict what direction this stuff goes in over time, which is why I don't think anyone should be dogmatic about how they plan to develop it or what they plan to do. You want to look at it with each release. We're obviously very pro [open source](https://en.wikipedia.org/wiki/Open-source_artificial_intelligence), but I haven't committed to releasing every single thing that we do. I’m basically very inclined to think that open sourcing is going to be good for the community and also good for us because we'll benefit from the innovations. If at some point however there's some qualitative change in what the thing is capable of, and we feel like it's not responsible to open source it, then we won't. It's all very difficult to predict.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think that's tricky.",
        "clean_text": "I think that's tricky.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The history of humanity has been people basically thinking that certain aspects of humanity are really unique in different ways and then coming to grips with the fact that that's not true, but that humanity is actually still super special.",
        "clean_text": "The history of humanity has been people basically thinking that certain aspects of humanity are really unique in different ways and then coming to grips with the fact that that's not true, but that humanity is actually still super special.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We thought that the earth was the center of the universe and it's not, but humans are still pretty awesome and pretty unique, right?",
        "clean_text": "We thought that the earth was the center of the universe and it's not, but humans are still pretty awesome and pretty unique, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I think another bias that people tend to have is thinking that [intelligence is somehow fundamentally connected to life](https://plato.stanford.edu/entries/artificial-intelligence/).",
        "clean_text": "I think another bias that people tend to have is thinking that intelligence is somehow fundamentally connected to life.",
        "extracted_information": {
          "links": {
            "intelligence is somehow fundamentally connected to life": "https://plato.stanford.edu/entries/artificial-intelligence/"
          },
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It's not actually clear that it is.",
        "clean_text": "It's not actually clear that it is.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I don't know that we have a clear enough definition of [consciousness](https://plato.stanford.edu/entries/consciousness/) or [life](https://plato.stanford.edu/entries/life/) to fully interrogate this.",
        "clean_text": "I don't know that we have a clear enough definition of consciousness or life to fully interrogate this.",
        "extracted_information": {
          "links": {
            "consciousness": "https://plato.stanford.edu/entries/consciousness/",
            "life": "https://plato.stanford.edu/entries/life/"
          },
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There's all this science fiction about creating intelligence where it starts to take on all these human-like behaviors and things like that.",
        "clean_text": "There's all this science fiction about creating intelligence where it starts to take on all these human-like behaviors and things like that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "The current incarnation of all this stuff feels like it's going in a direction where intelligence can be pretty separated from consciousness, [agency](https://plato.stanford.edu/entries/agency/), and things like that, which I think just makes it a super valuable tool.",
        "clean_text": "The current incarnation of all this stuff feels like it's going in a direction where intelligence can be pretty separated from consciousness, agency, and things like that, which I think just makes it a super valuable tool.",
        "extracted_information": {
          "links": {
            "agency": "https://plato.stanford.edu/entries/agency/"
          },
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Obviously it's very difficult to predict what direction this stuff goes in over time, which is why I don't think anyone should be dogmatic about how they plan to develop it or what they plan to do.",
        "clean_text": "Obviously it's very difficult to predict what direction this stuff goes in over time, which is why I don't think anyone should be dogmatic about how they plan to develop it or what they plan to do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You want to look at it with each release.",
        "clean_text": "You want to look at it with each release.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "We're obviously very pro [open source](https://en.wikipedia.org/wiki/Open-source_artificial_intelligence), but I haven't committed to releasing every single thing that we do.",
        "clean_text": "We're obviously very pro open source, but I haven't committed to releasing every single thing that we do.",
        "extracted_information": {
          "links": {
            "open source": "https://en.wikipedia.org/wiki/Open-source_artificial_intelligence"
          },
          "titles": [
            "artificial"
          ]
        }
      },
      {
        "index": 11,
        "original_text": "I’m basically very inclined to think that open sourcing is going to be good for the community and also good for us because we'll benefit from the innovations.",
        "clean_text": "I’m basically very inclined to think that open sourcing is going to be good for the community and also good for us because we'll benefit from the innovations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "If at some point however there's some qualitative change in what the thing is capable of, and we feel like it's not responsible to open source it, then we won't.",
        "clean_text": "If at some point however there's some qualitative change in what the thing is capable of, and we feel like it's not responsible to open source it, then we won't.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "It's all very difficult to predict.",
        "clean_text": "It's all very difficult to predict.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 55,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:38:07",
    "content": "What is a kind of specific qualitative change where you'd be training Llama-5 or Llama-4, and if you see it, it’d make you think “you know what, I'm not sure about open sourcing it”?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWhat is a kind of specific qualitative change where you'd be training Llama-5 or Llama-4, and if you see it, it’d make you think “you know what, I'm not sure about open sourcing it”?",
        "clean_text": "What is a kind of specific qualitative change where you'd be training Llama-5 or Llama-4, and if you see it, it’d make you think “you know what, I'm not sure about open sourcing it”?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 56,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:38:17",
    "content": "It's a little hard to answer that in the abstract because there are negative behaviors that any product can exhibit where as long as you can mitigate it, it's okay. There’s bad things about social media that we work to mitigate. There's bad things about Llama-2 where we spend a lot of time trying to make sure that it's not like helping people commit violent acts or things like that. That doesn't mean that it's a kind of autonomous or intelligent agent. It just means that it's learned a lot about the world and it can answer a set of questions that we think would be unhelpful for it to answer. I think the question isn't really what behaviors would it show, it's what things would we not be able to mitigate after it shows that.\n\nI think that there's so many ways in which something can be good or bad that it's hard to actually enumerate them all up front. Look at what we've had to deal with in social media and the different types of harms. We've basically gotten to like 18 or 19 categories of harmful things that people do and we've basically built AI systems to identify what those things are and to make sure that doesn't happen on our network as much as possible. Over time I think you'll be able to break this down into more of a taxonomy too. I think this is a thing that we spend time researching as well, because we want to make sure that we understand that.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's a little hard to answer that in the abstract because there are negative behaviors that any product can exhibit where as long as you can mitigate it, it's okay.",
        "clean_text": "It's a little hard to answer that in the abstract because there are negative behaviors that any product can exhibit where as long as you can mitigate it, it's okay.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There’s bad things about social media that we work to mitigate.",
        "clean_text": "There’s bad things about social media that we work to mitigate.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "There's bad things about Llama-2 where we spend a lot of time trying to make sure that it's not like helping people commit violent acts or things like that.",
        "clean_text": "There's bad things about Llama-2 where we spend a lot of time trying to make sure that it's not like helping people commit violent acts or things like that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "That doesn't mean that it's a kind of autonomous or intelligent agent.",
        "clean_text": "That doesn't mean that it's a kind of autonomous or intelligent agent.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It just means that it's learned a lot about the world and it can answer a set of questions that we think would be unhelpful for it to answer.",
        "clean_text": "It just means that it's learned a lot about the world and it can answer a set of questions that we think would be unhelpful for it to answer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I think the question isn't really what behaviors would it show, it's what things would we not be able to mitigate after it shows that.",
        "clean_text": "I think the question isn't really what behaviors would it show, it's what things would we not be able to mitigate after it shows that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I think that there's so many ways in which something can be good or bad that it's hard to actually enumerate them all up front.",
        "clean_text": "I think that there's so many ways in which something can be good or bad that it's hard to actually enumerate them all up front.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Look at what we've had to deal with in social media and the different types of harms.",
        "clean_text": "Look at what we've had to deal with in social media and the different types of harms.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "We've basically gotten to like 18 or 19 categories of harmful things that people do and we've basically built AI systems to identify what those things are and to make sure that doesn't happen on our network as much as possible.",
        "clean_text": "We've basically gotten to like 18 or 19 categories of harmful things that people do and we've basically built AI systems to identify what those things are and to make sure that doesn't happen on our network as much as possible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "Over time I think you'll be able to break this down into more of a taxonomy too.",
        "clean_text": "Over time I think you'll be able to break this down into more of a taxonomy too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "I think this is a thing that we spend time researching as well, because we want to make sure that we understand that.",
        "clean_text": "I think this is a thing that we spend time researching as well, because we want to make sure that we understand that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 57,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:41:04",
    "content": "It seems to me that it would be a good idea. I would be disappointed in a future where AI systems aren't broadly deployed and everybody doesn't have access to them. At the same time, I want to better understand the mitigations. If the mitigation is the fine-tuning, the whole thing about [open weights](https://opensource.org/blog/compelling-responses-to-ntias-ai-open-model-weights-rfc) is that you can then remove the fine-tuning, which is often superficial on top of these capabilities. If it's like talking on Slack with a biology researcher… I think models are very far from this. Right now, they’re like Google search. But if I can show them my Petri dish and they can explain why my smallpox sample didn’t grow and what to change, how do you mitigate that? Because somebody can just fine-tune that in there, right?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt seems to me that it would be a good idea.",
        "clean_text": "It seems to me that it would be a good idea.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I would be disappointed in a future where AI systems aren't broadly deployed and everybody doesn't have access to them.",
        "clean_text": "I would be disappointed in a future where AI systems aren't broadly deployed and everybody doesn't have access to them.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "At the same time, I want to better understand the mitigations.",
        "clean_text": "At the same time, I want to better understand the mitigations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "If the mitigation is the fine-tuning, the whole thing about [open weights](https://opensource.org/blog/compelling-responses-to-ntias-ai-open-model-weights-rfc) is that you can then remove the fine-tuning, which is often superficial on top of these capabilities.",
        "clean_text": "If the mitigation is the fine-tuning, the whole thing about open weights is that you can then remove the fine-tuning, which is often superficial on top of these capabilities.",
        "extracted_information": {
          "links": {
            "open weights": "https://opensource.org/blog/compelling-responses-to-ntias-ai-open-model-weights-rfc"
          },
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "If it's like talking on Slack with a biology researcher… I think models are very far from this.",
        "clean_text": "If it's like talking on Slack with a biology researcher… I think models are very far from this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Right now, they’re like Google search.",
        "clean_text": "Right now, they’re like Google search.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "But if I can show them my Petri dish and they can explain why my smallpox sample didn’t grow and what to change, how do you mitigate that?",
        "clean_text": "But if I can show them my Petri dish and they can explain why my smallpox sample didn’t grow and what to change, how do you mitigate that?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Because somebody can just fine-tune that in there, right?",
        "clean_text": "Because somebody can just fine-tune that in there, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 58,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:41:44",
    "content": "That's true. I think a lot of people will basically use the off-the-shelf model and some people who have basically bad faith are going to try to strip out all the bad stuff. So I do think that's an issue. On the flip side, one of the reasons why I'm philosophically so pro open source is that I do think that a concentration of AI in the future has the potential to be as dangerous as it being widespread. I think a lot of people think about the questions of “if we can do this stuff, is it bad for it to be out in the wild and just widely available?” I think another version of this is that it's probably also pretty bad for one institution to have an AI that is way more powerful than everyone else's AI.\n\nThere’s one security analogy that I think of. There are so many security holes in so many different things. If you could travel back in time a year or two years, let's say you just have one or two years more knowledge of the security holes. You can pretty much hack into any system. That’s not AI. So it's not that far-fetched to believe that a very intelligent AI probably would be able to identify some holes and basically be like a human who could go back in time a year or two and compromise all these systems.\n\nSo how have we dealt with that as a society? One big part is open source software that makes it so that when improvements are made to the software, it doesn't just get stuck in one company's products but can be broadly deployed to a lot of different systems, whether they’re banks or hospitals or government stuff. As the software gets hardened, which happens because more people can see it and more people can bang on it, there are standards on how this stuff works. The world can get upgraded together pretty quickly.\n\nI think that a world where AI is very widely deployed, in a way where it's gotten hardened progressively over time, is one where all the different systems will be in check in a way. That seems fundamentally more healthy to me than one where this is more concentrated. So there are risks on all sides, but I think that's a risk that I don't hear people talking about quite as much. There's the risk of the AI system doing something bad. But I stay up at night worrying more about an untrustworthy actor having the super strong AI, whether it's an adversarial government or an untrustworthy company or whatever. I think that that's potentially a much bigger risk.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's true.",
        "clean_text": "That's true.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think a lot of people will basically use the off-the-shelf model and some people who have basically bad faith are going to try to strip out all the bad stuff.",
        "clean_text": "I think a lot of people will basically use the off-the-shelf model and some people who have basically bad faith are going to try to strip out all the bad stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "So I do think that's an issue.",
        "clean_text": "So I do think that's an issue.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "On the flip side, one of the reasons why I'm philosophically so pro open source is that I do think that a concentration of AI in the future has the potential to be as dangerous as it being widespread.",
        "clean_text": "On the flip side, one of the reasons why I'm philosophically so pro open source is that I do think that a concentration of AI in the future has the potential to be as dangerous as it being widespread.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I think a lot of people think about the questions of “if we can do this stuff, is it bad for it to be out in the wild and just widely available?” I think another version of this is that it's probably also pretty bad for one institution to have an AI that is way more powerful than everyone else's AI.",
        "clean_text": "I think a lot of people think about the questions of “if we can do this stuff, is it bad for it to be out in the wild and just widely available?” I think another version of this is that it's probably also pretty bad for one institution to have an AI that is way more powerful than everyone else's AI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "There’s one security analogy that I think of.",
        "clean_text": "There’s one security analogy that I think of.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There are so many security holes in so many different things.",
        "clean_text": "There are so many security holes in so many different things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "If you could travel back in time a year or two years, let's say you just have one or two years more knowledge of the security holes.",
        "clean_text": "If you could travel back in time a year or two years, let's say you just have one or two years more knowledge of the security holes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You can pretty much hack into any system.",
        "clean_text": "You can pretty much hack into any system.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "That’s not AI.",
        "clean_text": "That’s not AI.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "So it's not that far-fetched to believe that a very intelligent AI probably would be able to identify some holes and basically be like a human who could go back in time a year or two and compromise all these systems.",
        "clean_text": "So it's not that far-fetched to believe that a very intelligent AI probably would be able to identify some holes and basically be like a human who could go back in time a year or two and compromise all these systems.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "So how have we dealt with that as a society?",
        "clean_text": "So how have we dealt with that as a society?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "One big part is open source software that makes it so that when improvements are made to the software, it doesn't just get stuck in one company's products but can be broadly deployed to a lot of different systems, whether they’re banks or hospitals or government stuff.",
        "clean_text": "One big part is open source software that makes it so that when improvements are made to the software, it doesn't just get stuck in one company's products but can be broadly deployed to a lot of different systems, whether they’re banks or hospitals or government stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "As the software gets hardened, which happens because more people can see it and more people can bang on it, there are standards on how this stuff works.",
        "clean_text": "As the software gets hardened, which happens because more people can see it and more people can bang on it, there are standards on how this stuff works.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "The world can get upgraded together pretty quickly.",
        "clean_text": "The world can get upgraded together pretty quickly.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "I think that a world where AI is very widely deployed, in a way where it's gotten hardened progressively over time, is one where all the different systems will be in check in a way.",
        "clean_text": "I think that a world where AI is very widely deployed, in a way where it's gotten hardened progressively over time, is one where all the different systems will be in check in a way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "That seems fundamentally more healthy to me than one where this is more concentrated.",
        "clean_text": "That seems fundamentally more healthy to me than one where this is more concentrated.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "So there are risks on all sides, but I think that's a risk that I don't hear people talking about quite as much.",
        "clean_text": "So there are risks on all sides, but I think that's a risk that I don't hear people talking about quite as much.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "There's the risk of the AI system doing something bad.",
        "clean_text": "There's the risk of the AI system doing something bad.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "But I stay up at night worrying more about an untrustworthy actor having the super strong AI, whether it's an adversarial government or an untrustworthy company or whatever.",
        "clean_text": "But I stay up at night worrying more about an untrustworthy actor having the super strong AI, whether it's an adversarial government or an untrustworthy company or whatever.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "I think that that's potentially a much bigger risk.",
        "clean_text": "I think that that's potentially a much bigger risk.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 59,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:44:59",
    "content": "As in, they could overthrow our government because they have a weapon that nobody else has?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAs in, they could overthrow our government because they have a weapon that nobody else has?",
        "clean_text": "As in, they could overthrow our government because they have a weapon that nobody else has?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 60,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:45:06",
    "content": "Or just cause a lot of mayhem. I think the intuition is that this stuff ends up being pretty important and valuable for both economic and security reasons and other things. If someone whom you don't trust or an adversary gets something more powerful, then I think that that could be an issue. Probably the best way to mitigate that is to have good open source AI that becomes the standard and in a lot of ways can become the leader. It just ensures that it's a much more even and balanced playing field.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOr just cause a lot of mayhem.",
        "clean_text": "Or just cause a lot of mayhem.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I think the intuition is that this stuff ends up being pretty important and valuable for both economic and security reasons and other things.",
        "clean_text": "I think the intuition is that this stuff ends up being pretty important and valuable for both economic and security reasons and other things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If someone whom you don't trust or an adversary gets something more powerful, then I think that that could be an issue.",
        "clean_text": "If someone whom you don't trust or an adversary gets something more powerful, then I think that that could be an issue.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Probably the best way to mitigate that is to have good open source AI that becomes the standard and in a lot of ways can become the leader.",
        "clean_text": "Probably the best way to mitigate that is to have good open source AI that becomes the standard and in a lot of ways can become the leader.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It just ensures that it's a much more even and balanced playing field.",
        "clean_text": "It just ensures that it's a much more even and balanced playing field.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 61,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:45:49",
    "content": "That seems plausible to me. If that works out, that would be the future I prefer. I want to understand mechanistically how the fact that there are open source AI systems in the world prevents somebody causing mayhem with their AI system? With the specific example of somebody coming with a bioweapon, is it just that we'll do a bunch of R&D in the rest of the world to figure out vaccines really fast? What's happening?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat seems plausible to me.",
        "clean_text": "That seems plausible to me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "If that works out, that would be the future I prefer.",
        "clean_text": "If that works out, that would be the future I prefer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I want to understand mechanistically how the fact that there are open source AI systems in the world prevents somebody causing mayhem with their AI system?",
        "clean_text": "I want to understand mechanistically how the fact that there are open source AI systems in the world prevents somebody causing mayhem with their AI system?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "With the specific example of somebody coming with a bioweapon, is it just that we'll do a bunch of R&D in the rest of the world to figure out vaccines really fast?",
        "clean_text": "With the specific example of somebody coming with a bioweapon, is it just that we'll do a bunch of R&D in the rest of the world to figure out vaccines really fast?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "What's happening?",
        "clean_text": "What's happening?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 62,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:46:13",
    "content": "If you take the security one that I was talking about, I think someone with a weaker AI trying to hack into a system that is protected by a stronger AI will succeed less. In terms of software security–",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIf you take the security one that I was talking about, I think someone with a weaker AI trying to hack into a system that is protected by a stronger AI will succeed less.",
        "clean_text": "If you take the security one that I was talking about, I think someone with a weaker AI trying to hack into a system that is protected by a stronger AI will succeed less.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "In terms of software security–",
        "clean_text": "In terms of software security–",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 63,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:46:28",
    "content": "How do we know everything in the world is like that? What if bioweapons aren't like that?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nHow do we know everything in the world is like that?",
        "clean_text": "How do we know everything in the world is like that?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What if bioweapons aren't like that?",
        "clean_text": "What if bioweapons aren't like that?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 64,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:46:32",
    "content": "I mean, I don't know that everything in the world is like that. [Bioweapons are one of the areas where the people who are most worried about this stuff are focused](https://www.rand.org/pubs/research_reports/RRA2977-2.html) and I think it makes a lot of sense. There are certain mitigations. You can try to not train certain knowledge into the model. There are different things but at some level if you get a sufficiently bad actor, and you don't have other AI that can balance them and understand what the threats are, then that could be a risk. That's one of the things that we need to watch out for.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI mean, I don't know that everything in the world is like that.",
        "clean_text": "I mean, I don't know that everything in the world is like that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "[Bioweapons are one of the areas where the people who are most worried about this stuff are focused](https://www.rand.org/pubs/research_reports/RRA2977-2.html) and I think it makes a lot of sense.",
        "clean_text": "Bioweapons are one of the areas where the people who are most worried about this stuff are focused and I think it makes a lot of sense.",
        "extracted_information": {
          "links": {
            "Bioweapons are one of the areas where the people who are most worried about this stuff are focused": "https://www.rand.org/pubs/research_reports/RRA2977-2.html"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "There are certain mitigations.",
        "clean_text": "There are certain mitigations.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You can try to not train certain knowledge into the model.",
        "clean_text": "You can try to not train certain knowledge into the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "There are different things but at some level if you get a sufficiently bad actor, and you don't have other AI that can balance them and understand what the threats are, then that could be a risk.",
        "clean_text": "There are different things but at some level if you get a sufficiently bad actor, and you don't have other AI that can balance them and understand what the threats are, then that could be a risk.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "That's one of the things that we need to watch out for.",
        "clean_text": "That's one of the things that we need to watch out for.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 65,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:47:19",
    "content": "Is there something you could see in the deployment of these systems where you're training Llama-4 and it lied to you because it thought you weren't noticing or something and you're like “whoa what's going on here?” This is probably not likely with a Llama-4 type system, but is there something you can imagine like that where you'd be really concerned about [deceptiveness](https://www.nature.com/articles/d41586-024-00189-3) and billions of copies of this being out in the wild?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIs there something you could see in the deployment of these systems where you're training Llama-4 and it lied to you because it thought you weren't noticing or something and you're like “whoa what's going on here?” This is probably not likely with a Llama-4 type system, but is there something you can imagine like that where you'd be really concerned about [deceptiveness](https://www.nature.com/articles/d41586-024-00189-3) and billions of copies of this being out in the wild?",
        "clean_text": "Is there something you could see in the deployment of these systems where you're training Llama-4 and it lied to you because it thought you weren't noticing or something and you're like “whoa what's going on here?” This is probably not likely with a Llama-4 type system, but is there something you can imagine like that where you'd be really concerned about deceptiveness and billions of copies of this being out in the wild?",
        "extracted_information": {
          "links": {
            "deceptiveness": "https://www.nature.com/articles/d41586-024-00189-3"
          },
          "titles": []
        }
      }
    ]
  },
  {
    "index": 66,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:47:46",
    "content": "I mean right now we see a lot of [hallucinations](https://en.wikipedia.org/wiki/Hallucination_/(artificial_intelligence/)). It's more so that. I think it's an interesting question, how you would tell the difference between hallucination and deception. There are a lot of risks and things to think about. I try, in running our company at least, to balance these longer-term theoretical risks with what I actually think are quite real risks that exist today. So when you talk about deception, the form of that that I worry about most is people [using this to generate misinformation](https://carnegieendowment.org/2024/01/31/looking-ahead-generative-ai-pub-91489) and then pump that through our networks or others. The way that we've combated this type of harmful content is by building AI systems that are smarter than the adversarial ones.\n\nThis informs part of my theory on this. If you look at the different types of harm that people do or try to do through social networks, there are ones that are not very adversarial. For example, hate speech is not super adversarial in the sense that people aren't getting better at being racist. That's one where I think the AIs are generally getting way more sophisticated faster than people are at those issues. And we have issues both ways. People do bad things, whether they're trying to incite violence or something, but we also have a lot of false positives where we basically censor stuff that we shouldn't. I think that understandably makes a lot of people annoyed. So I think having an AI that gets increasingly precise on that is going to be good over time.\n\nBut let me give you another example: [nation states trying to interfere in elections](https://apnews.com/article/artificial-intelligence-elections-disinformation-chatgpt-bc283e7426402f0b4baa7df280a4c3fd#:~:text=As%20the%20U.S.%20presidential%20race,to%20engage%20in%20malign%20influence.%E2%80%9D&text=With%20AI%20deepfakes%2C%20a%20candidate's,can%20be%20smeared%2C%20or%20softened.). That's an example where they absolutely have cutting edge technology and absolutely get better each year. So we block some technique, they learn what we did and come at us with a different technique. It's not like a person trying to say mean things, They have a goal. They're sophisticated. They have a lot of technology. In those cases, I still think about the ability to have our AI systems grow in sophistication at a faster rate than theirs do. It's an arms race but I think we're at least winning that arms race currently. This is a lot of the stuff that I spend time thinking about.\n\nYes, whether it's Llama-4 or Llama-6, we need to think about what behaviors we're observing and it's not just us. Part of the reason why you make this open source is that there are a lot of other people who study this too. So we want to see what other people are observing, what we’re observing, what we can mitigate, and then we'll make our assessment on whether we can make it open source. For the foreseeable future I'm optimistic we will be able to. In the near term, I don't want to take our eye off the ball in terms of what are actual bad things that people are trying to use the models for today. Even if they're not existential, there are pretty bad day-to-day harms that we're familiar with in running our services. That's actually a lot of what we have to spend our time on as well.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI mean right now we see a lot of [hallucinations](https://en.wikipedia.org/wiki/Hallucination_/(artificial_intelligence/)).",
        "clean_text": "I mean right now we see a lot of hallucinations).",
        "extracted_information": {
          "links": {
            "hallucinations": "https://en.wikipedia.org/wiki/Hallucination_/(artificial_intelligence/"
          },
          "titles": [
            "/(artificial"
          ]
        }
      },
      {
        "index": 1,
        "original_text": "It's more so that.",
        "clean_text": "It's more so that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I think it's an interesting question, how you would tell the difference between hallucination and deception.",
        "clean_text": "I think it's an interesting question, how you would tell the difference between hallucination and deception.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There are a lot of risks and things to think about.",
        "clean_text": "There are a lot of risks and things to think about.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I try, in running our company at least, to balance these longer-term theoretical risks with what I actually think are quite real risks that exist today.",
        "clean_text": "I try, in running our company at least, to balance these longer-term theoretical risks with what I actually think are quite real risks that exist today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "So when you talk about deception, the form of that that I worry about most is people [using this to generate misinformation](https://carnegieendowment.org/2024/01/31/looking-ahead-generative-ai-pub-91489) and then pump that through our networks or others.",
        "clean_text": "So when you talk about deception, the form of that that I worry about most is people using this to generate misinformation and then pump that through our networks or others.",
        "extracted_information": {
          "links": {
            "using this to generate misinformation": "https://carnegieendowment.org/2024/01/31/looking-ahead-generative-ai-pub-91489"
          },
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "The way that we've combated this type of harmful content is by building AI systems that are smarter than the adversarial ones.",
        "clean_text": "The way that we've combated this type of harmful content is by building AI systems that are smarter than the adversarial ones.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "This informs part of my theory on this.",
        "clean_text": "This informs part of my theory on this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "If you look at the different types of harm that people do or try to do through social networks, there are ones that are not very adversarial.",
        "clean_text": "If you look at the different types of harm that people do or try to do through social networks, there are ones that are not very adversarial.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "For example, hate speech is not super adversarial in the sense that people aren't getting better at being racist.",
        "clean_text": "For example, hate speech is not super adversarial in the sense that people aren't getting better at being racist.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "That's one where I think the AIs are generally getting way more sophisticated faster than people are at those issues.",
        "clean_text": "That's one where I think the AIs are generally getting way more sophisticated faster than people are at those issues.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "And we have issues both ways.",
        "clean_text": "And we have issues both ways.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "People do bad things, whether they're trying to incite violence or something, but we also have a lot of false positives where we basically censor stuff that we shouldn't.",
        "clean_text": "People do bad things, whether they're trying to incite violence or something, but we also have a lot of false positives where we basically censor stuff that we shouldn't.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "I think that understandably makes a lot of people annoyed.",
        "clean_text": "I think that understandably makes a lot of people annoyed.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "So I think having an AI that gets increasingly precise on that is going to be good over time.",
        "clean_text": "So I think having an AI that gets increasingly precise on that is going to be good over time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "But let me give you another example: [nation states trying to interfere in elections](https://apnews.com/article/artificial-intelligence-elections-disinformation-chatgpt-bc283e7426402f0b4baa7df280a4c3fd#:~:text=As%20the%20U.S.%20presidential%20race,to%20engage%20in%20malign%20influence.%E2%80%9D&text=With%20AI%20deepfakes%2C%20a%20candidate's,can%20be%20smeared%2C%20or%20softened.).",
        "clean_text": "But let me give you another example: nation states trying to interfere in elections.",
        "extracted_information": {
          "links": {
            "nation states trying to interfere in elections": "https://apnews.com/article/artificial-intelligence-elections-disinformation-chatgpt-bc283e7426402f0b4baa7df280a4c3fd#:~:text=As%20the%20U.S.%20presidential%20race,to%20engage%20in%20malign%20influence.%E2%80%9D&text=With%20AI%20deepfakes%2C%20a%20candidate's,can%20be%20smeared%2C%20or%20softened."
          },
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "That's an example where they absolutely have cutting edge technology and absolutely get better each year.",
        "clean_text": "That's an example where they absolutely have cutting edge technology and absolutely get better each year.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "So we block some technique, they learn what we did and come at us with a different technique.",
        "clean_text": "So we block some technique, they learn what we did and come at us with a different technique.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "It's not like a person trying to say mean things, They have a goal.",
        "clean_text": "It's not like a person trying to say mean things, They have a goal.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "They're sophisticated.",
        "clean_text": "They're sophisticated.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "They have a lot of technology.",
        "clean_text": "They have a lot of technology.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "In those cases, I still think about the ability to have our AI systems grow in sophistication at a faster rate than theirs do.",
        "clean_text": "In those cases, I still think about the ability to have our AI systems grow in sophistication at a faster rate than theirs do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "It's an arms race but I think we're at least winning that arms race currently.",
        "clean_text": "It's an arms race but I think we're at least winning that arms race currently.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "This is a lot of the stuff that I spend time thinking about.",
        "clean_text": "This is a lot of the stuff that I spend time thinking about.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "Yes, whether it's Llama-4 or Llama-6, we need to think about what behaviors we're observing and it's not just us.",
        "clean_text": "Yes, whether it's Llama-4 or Llama-6, we need to think about what behaviors we're observing and it's not just us.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "Part of the reason why you make this open source is that there are a lot of other people who study this too.",
        "clean_text": "Part of the reason why you make this open source is that there are a lot of other people who study this too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "So we want to see what other people are observing, what we’re observing, what we can mitigate, and then we'll make our assessment on whether we can make it open source.",
        "clean_text": "So we want to see what other people are observing, what we’re observing, what we can mitigate, and then we'll make our assessment on whether we can make it open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "For the foreseeable future I'm optimistic we will be able to.",
        "clean_text": "For the foreseeable future I'm optimistic we will be able to.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "In the near term, I don't want to take our eye off the ball in terms of what are actual bad things that people are trying to use the models for today.",
        "clean_text": "In the near term, I don't want to take our eye off the ball in terms of what are actual bad things that people are trying to use the models for today.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "Even if they're not existential, there are pretty bad day-to-day harms that we're familiar with in running our services.",
        "clean_text": "Even if they're not existential, there are pretty bad day-to-day harms that we're familiar with in running our services.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 30,
        "original_text": "That's actually a lot of what we have to spend our time on as well.",
        "clean_text": "That's actually a lot of what we have to spend our time on as well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 67,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:51:24",
    "content": "I found the synthetic data thing really curious. With current models it makes sense why there might be an asymptote with just doing the synthetic data again and again. But let’s say they get smarter and you use the kinds of techniques—you talk about in the paper or the blog posts that are coming out on the day this will be released—where it goes to the thought chain that is the most correct. Why do you think this wouldn't lead to a loop where it gets smarter, makes better output, gets smarter and so forth. Of course it wouldn't be overnight, but over many months or years of training potentially with a smarter model.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI found the synthetic data thing really curious.",
        "clean_text": "I found the synthetic data thing really curious.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "With current models it makes sense why there might be an asymptote with just doing the synthetic data again and again.",
        "clean_text": "With current models it makes sense why there might be an asymptote with just doing the synthetic data again and again.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "But let’s say they get smarter and you use the kinds of techniques—you talk about in the paper or the blog posts that are coming out on the day this will be released—where it goes to the thought chain that is the most correct.",
        "clean_text": "But let’s say they get smarter and you use the kinds of techniques—you talk about in the paper or the blog posts that are coming out on the day this will be released—where it goes to the thought chain that is the most correct.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Why do you think this wouldn't lead to a loop where it gets smarter, makes better output, gets smarter and so forth.",
        "clean_text": "Why do you think this wouldn't lead to a loop where it gets smarter, makes better output, gets smarter and so forth.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Of course it wouldn't be overnight, but over many months or years of training potentially with a smarter model.",
        "clean_text": "Of course it wouldn't be overnight, but over many months or years of training potentially with a smarter model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 68,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:52:00",
    "content": "I think it could, within the parameters of whatever the model architecture is. It's just that with today's 8B parameter models, I don't think you're going to get to be as good as the state-of-the-art multi-hundred billion parameter models that are incorporating new research into the architecture itself.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think it could, within the parameters of whatever the model architecture is.",
        "clean_text": "I think it could, within the parameters of whatever the model architecture is.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It's just that with today's 8B parameter models, I don't think you're going to get to be as good as the state-of-the-art multi-hundred billion parameter models that are incorporating new research into the architecture itself.",
        "clean_text": "It's just that with today's 8B parameter models, I don't think you're going to get to be as good as the state-of-the-art multi-hundred billion parameter models that are incorporating new research into the architecture itself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 69,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:52:28",
    "content": "But those will be open source as well, right?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut those will be open source as well, right?",
        "clean_text": "But those will be open source as well, right?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 70,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:52:31",
    "content": "Well yeah, subject to all the questions that we just talked about but yes. We would hope that that'll be the case. But I think that at each point, when you're building software there's a ton of stuff that you can do with software but then at some level you're constrained by the chips that it's running on. So there are always going to be different physical constraints. How big the models are is going to be constrained by how much energy you can get and use for inference. I'm simultaneously very optimistic that this stuff will continue to improve quickly and also a little more measured than I think some people are about it. I don’t think the runaway case is a particularly likely one.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWell yeah, subject to all the questions that we just talked about but yes.",
        "clean_text": "Well yeah, subject to all the questions that we just talked about but yes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We would hope that that'll be the case.",
        "clean_text": "We would hope that that'll be the case.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "But I think that at each point, when you're building software there's a ton of stuff that you can do with software but then at some level you're constrained by the chips that it's running on.",
        "clean_text": "But I think that at each point, when you're building software there's a ton of stuff that you can do with software but then at some level you're constrained by the chips that it's running on.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "So there are always going to be different physical constraints.",
        "clean_text": "So there are always going to be different physical constraints.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "How big the models are is going to be constrained by how much energy you can get and use for inference.",
        "clean_text": "How big the models are is going to be constrained by how much energy you can get and use for inference.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I'm simultaneously very optimistic that this stuff will continue to improve quickly and also a little more measured than I think some people are about it.",
        "clean_text": "I'm simultaneously very optimistic that this stuff will continue to improve quickly and also a little more measured than I think some people are about it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I don’t think the runaway case is a particularly likely one.",
        "clean_text": "I don’t think the runaway case is a particularly likely one.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 71,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:53:32",
    "content": "I think it makes sense to keep your options open. There's so much we don't know. There's a case in which it's really important to keep the balance of power so nobody becomes a totalitarian dictator. There's a case in which you don't want to open source the architecture because China can use it to catch up to America's AIs and there is an [intelligence explosion](https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion) and they win that. A lot of things seem possible. Keeping your options open considering all of them seems reasonable.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think it makes sense to keep your options open.",
        "clean_text": "I think it makes sense to keep your options open.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "There's so much we don't know.",
        "clean_text": "There's so much we don't know.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "There's a case in which it's really important to keep the balance of power so nobody becomes a totalitarian dictator.",
        "clean_text": "There's a case in which it's really important to keep the balance of power so nobody becomes a totalitarian dictator.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There's a case in which you don't want to open source the architecture because China can use it to catch up to America's AIs and there is an [intelligence explosion](https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion) and they win that.",
        "clean_text": "There's a case in which you don't want to open source the architecture because China can use it to catch up to America's AIs and there is an intelligence explosion and they win that.",
        "extracted_information": {
          "links": {
            "intelligence explosion": "https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion"
          },
          "titles": [
            "singularity#Intelligence"
          ]
        }
      },
      {
        "index": 4,
        "original_text": "A lot of things seem possible.",
        "clean_text": "A lot of things seem possible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Keeping your options open considering all of them seems reasonable.",
        "clean_text": "Keeping your options open considering all of them seems reasonable.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 72,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:53:57",
    "content": "Yeah.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYeah.",
        "clean_text": "Yeah.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 73,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:53:57",
    "content": "Let's talk about some other things. Metaverse. What time period in human history would you be most interested in going into? 100,000 BCE to now, you just want to see what it was like?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet's talk about some other things.",
        "clean_text": "Let's talk about some other things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Metaverse.",
        "clean_text": "Metaverse.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "What time period in human history would you be most interested in going into?",
        "clean_text": "What time period in human history would you be most interested in going into?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "100,000 BCE to now, you just want to see what it was like?",
        "clean_text": "100,000 BCE to now, you just want to see what it was like?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 74,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:54:09",
    "content": "It has to be the past?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt has to be the past?",
        "clean_text": "It has to be the past?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 75,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:54:12",
    "content": "Oh yeah, it has to be the past.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOh yeah, it has to be the past.",
        "clean_text": "Oh yeah, it has to be the past.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 76,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:54:13",
    "content": "I'm really interested in American history and classical history. I'm really interested in the history of science too. I actually think seeing and trying to understand more about how some of the big advances came about would be interesting. All we have are somewhat limited writings about some of that stuff. I'm not sure the metaverse is going to let you do that because it's going to be hard to go back in time for things that we don't have records of. I'm actually not sure that going back in time is going to be that important of a thing. I think it's going to be cool for like history classes and stuff, but that's probably not the use case that I'm most excited about for the metaverse overall.\n\nThe main thing is just the ability to feel present with people, no matter where you are. I think that's going to be killer. In the AI conversation that we were having, so much of it is about physical constraints that underlie all of this. I think one lesson of technology is that you want to move things from the physical constraint realm into software as much as possible because software is so much easier to build and evolve. You can democratize it more because not everyone is going to have a data center but a lot of people can write code and take open source code and modify it. Τhe metaverse version of this is enabling realistic digital presence. That’s going to be an absolutely huge difference so people don't feel like they have to be physically together for as many things. Now I think that there can be things that are better about being physically together. These things aren't binary. It's not going to be like “okay, now you don't need to do that anymore.” But overall, I think it's just going to be really powerful for socializing, for feeling connected with people, for working, for parts of industry, for medicine, for so many things.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'm really interested in American history and classical history.",
        "clean_text": "I'm really interested in American history and classical history.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I'm really interested in the history of science too.",
        "clean_text": "I'm really interested in the history of science too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I actually think seeing and trying to understand more about how some of the big advances came about would be interesting.",
        "clean_text": "I actually think seeing and trying to understand more about how some of the big advances came about would be interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "All we have are somewhat limited writings about some of that stuff.",
        "clean_text": "All we have are somewhat limited writings about some of that stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I'm not sure the metaverse is going to let you do that because it's going to be hard to go back in time for things that we don't have records of.",
        "clean_text": "I'm not sure the metaverse is going to let you do that because it's going to be hard to go back in time for things that we don't have records of.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I'm actually not sure that going back in time is going to be that important of a thing.",
        "clean_text": "I'm actually not sure that going back in time is going to be that important of a thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I think it's going to be cool for like history classes and stuff, but that's probably not the use case that I'm most excited about for the metaverse overall.",
        "clean_text": "I think it's going to be cool for like history classes and stuff, but that's probably not the use case that I'm most excited about for the metaverse overall.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "The main thing is just the ability to feel present with people, no matter where you are.",
        "clean_text": "The main thing is just the ability to feel present with people, no matter where you are.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "I think that's going to be killer.",
        "clean_text": "I think that's going to be killer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "In the AI conversation that we were having, so much of it is about physical constraints that underlie all of this.",
        "clean_text": "In the AI conversation that we were having, so much of it is about physical constraints that underlie all of this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "I think one lesson of technology is that you want to move things from the physical constraint realm into software as much as possible because software is so much easier to build and evolve.",
        "clean_text": "I think one lesson of technology is that you want to move things from the physical constraint realm into software as much as possible because software is so much easier to build and evolve.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "You can democratize it more because not everyone is going to have a data center but a lot of people can write code and take open source code and modify it.",
        "clean_text": "You can democratize it more because not everyone is going to have a data center but a lot of people can write code and take open source code and modify it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Τhe metaverse version of this is enabling realistic digital presence.",
        "clean_text": "Τhe metaverse version of this is enabling realistic digital presence.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "That’s going to be an absolutely huge difference so people don't feel like they have to be physically together for as many things.",
        "clean_text": "That’s going to be an absolutely huge difference so people don't feel like they have to be physically together for as many things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "Now I think that there can be things that are better about being physically together.",
        "clean_text": "Now I think that there can be things that are better about being physically together.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "These things aren't binary.",
        "clean_text": "These things aren't binary.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "It's not going to be like “okay, now you don't need to do that anymore.” But overall, I think it's just going to be really powerful for socializing, for feeling connected with people, for working, for parts of industry, for medicine, for so many things.",
        "clean_text": "It's not going to be like “okay, now you don't need to do that anymore.” But overall, I think it's just going to be really powerful for socializing, for feeling connected with people, for working, for parts of industry, for medicine, for so many things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 77,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "00:56:32",
    "content": "I want to go back to something you said at the beginning of the conversation. You didn't sell the company for a billion dollars. And with the metaverse, you knew you were going to do this even though the market was hammering you for it. I'm curious. What is the source of that edge? You said “oh, values, I have this intuition,” but everybody says that. If you had to say something that's specific to you, how would you express what that is? Why were you so convinced about the metaverse?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI want to go back to something you said at the beginning of the conversation.",
        "clean_text": "I want to go back to something you said at the beginning of the conversation.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You didn't sell the company for a billion dollars.",
        "clean_text": "You didn't sell the company for a billion dollars.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "And with the metaverse, you knew you were going to do this even though the market was hammering you for it.",
        "clean_text": "And with the metaverse, you knew you were going to do this even though the market was hammering you for it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I'm curious.",
        "clean_text": "I'm curious.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "What is the source of that edge?",
        "clean_text": "What is the source of that edge?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "You said “oh, values, I have this intuition,” but everybody says that.",
        "clean_text": "You said “oh, values, I have this intuition,” but everybody says that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "If you had to say something that's specific to you, how would you express what that is?",
        "clean_text": "If you had to say something that's specific to you, how would you express what that is?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "Why were you so convinced about the metaverse?",
        "clean_text": "Why were you so convinced about the metaverse?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 78,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "00:57:02",
    "content": "I think that those are different questions. What are the things that power me? We've talked about a bunch of the themes. I just really like building things. I specifically like building things around how people communicate and understanding how people express themselves and how people work. When I was in college I studied computer science and psychology. I think a lot of other people in the industry studied computer science. So, it's always been the intersection of those two things for me.\n\nIt’s also sort of this really deep drive. I don't know how to explain it but I just feel constitutionally that I'm doing something wrong if I'm not building something new. Even when we were putting together the business case for investing a $100 billion in AI or some huge amount in the metaverse, we have plans that I think made it pretty clear that if our stuff works, it'll be a good investment. But you can't know for certain from the outset. There are all these arguments that people have, with advisors or different folks. It's like, “how are you confident enough to do this?” Well the day I stop trying to build new things, I'm just done. I'm going to go build new things somewhere else. I'm fundamentally incapable of running something, or in my own life, and not trying to build new things that I think are interesting. That's not even a question for me, whether we're going to take a swing at building the next thing. I'm just incapable of not doing that. I don't know.\n\nI'm kind of like this in all the different aspects of my life. Our family built this [ranch in Kauai](https://www.wired.com/story/mark-zuckerberg-inside-hawaii-compound/) and I worked on designing all these buildings. [We started raising cattle](https://www.instagram.com/zuck/p/C15Lck4SfpS/?img_index=1) and I'm like “alright, I want to make the best cattle in the world so how do we architect this so that way we can figure this out and build all the stuff up that we need to try to do that.” I don't know, that's me. What was the other part of the question?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think that those are different questions.",
        "clean_text": "I think that those are different questions.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "What are the things that power me?",
        "clean_text": "What are the things that power me?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We've talked about a bunch of the themes.",
        "clean_text": "We've talked about a bunch of the themes.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I just really like building things.",
        "clean_text": "I just really like building things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "I specifically like building things around how people communicate and understanding how people express themselves and how people work.",
        "clean_text": "I specifically like building things around how people communicate and understanding how people express themselves and how people work.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "When I was in college I studied computer science and psychology.",
        "clean_text": "When I was in college I studied computer science and psychology.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I think a lot of other people in the industry studied computer science.",
        "clean_text": "I think a lot of other people in the industry studied computer science.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "So, it's always been the intersection of those two things for me.",
        "clean_text": "So, it's always been the intersection of those two things for me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "It’s also sort of this really deep drive.",
        "clean_text": "It’s also sort of this really deep drive.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "I don't know how to explain it but I just feel constitutionally that I'm doing something wrong if I'm not building something new.",
        "clean_text": "I don't know how to explain it but I just feel constitutionally that I'm doing something wrong if I'm not building something new.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "Even when we were putting together the business case for investing a $100 billion in AI or some huge amount in the metaverse, we have plans that I think made it pretty clear that if our stuff works, it'll be a good investment.",
        "clean_text": "Even when we were putting together the business case for investing a $100 billion in AI or some huge amount in the metaverse, we have plans that I think made it pretty clear that if our stuff works, it'll be a good investment.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "But you can't know for certain from the outset.",
        "clean_text": "But you can't know for certain from the outset.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "There are all these arguments that people have, with advisors or different folks.",
        "clean_text": "There are all these arguments that people have, with advisors or different folks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "It's like, “how are you confident enough to do this?” Well the day I stop trying to build new things, I'm just done.",
        "clean_text": "It's like, “how are you confident enough to do this?” Well the day I stop trying to build new things, I'm just done.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "I'm going to go build new things somewhere else.",
        "clean_text": "I'm going to go build new things somewhere else.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "I'm fundamentally incapable of running something, or in my own life, and not trying to build new things that I think are interesting.",
        "clean_text": "I'm fundamentally incapable of running something, or in my own life, and not trying to build new things that I think are interesting.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "That's not even a question for me, whether we're going to take a swing at building the next thing.",
        "clean_text": "That's not even a question for me, whether we're going to take a swing at building the next thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "I'm just incapable of not doing that.",
        "clean_text": "I'm just incapable of not doing that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "I don't know.",
        "clean_text": "I don't know.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "I'm kind of like this in all the different aspects of my life.",
        "clean_text": "I'm kind of like this in all the different aspects of my life.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "Our family built this [ranch in Kauai](https://www.wired.com/story/mark-zuckerberg-inside-hawaii-compound/) and I worked on designing all these buildings.",
        "clean_text": "Our family built this ranch in Kauai and I worked on designing all these buildings.",
        "extracted_information": {
          "links": {
            "ranch in Kauai": "https://www.wired.com/story/mark-zuckerberg-inside-hawaii-compound/"
          },
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "[We started raising cattle](https://www.instagram.com/zuck/p/C15Lck4SfpS/?img_index=1) and I'm like “alright, I want to make the best cattle in the world so how do we architect this so that way we can figure this out and build all the stuff up that we need to try to do that.” I don't know, that's me.",
        "clean_text": "We started raising cattle and I'm like “alright, I want to make the best cattle in the world so how do we architect this so that way we can figure this out and build all the stuff up that we need to try to do that.” I don't know, that's me.",
        "extracted_information": {
          "links": {
            "We started raising cattle": "https://www.instagram.com/zuck/p/C15Lck4SfpS/?img_index=1"
          },
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "What was the other part of the question?",
        "clean_text": "What was the other part of the question?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 79,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:00:54",
    "content": "I'm not sure but I'm actually curious about something else. So a 19-year-old Mark reads a bunch of antiquity and classics in high school and college. What important lesson did you learn from it? Not just interesting things you found, but there aren't that many tokens you consume by the time you're 19. A bunch of them were about the classics. Clearly that was important in some way.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI'm not sure but I'm actually curious about something else.",
        "clean_text": "I'm not sure but I'm actually curious about something else.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "So a 19-year-old Mark reads a bunch of antiquity and classics in high school and college.",
        "clean_text": "So a 19-year-old Mark reads a bunch of antiquity and classics in high school and college.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "What important lesson did you learn from it?",
        "clean_text": "What important lesson did you learn from it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Not just interesting things you found, but there aren't that many tokens you consume by the time you're 19.",
        "clean_text": "Not just interesting things you found, but there aren't that many tokens you consume by the time you're 19.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "A bunch of them were about the classics.",
        "clean_text": "A bunch of them were about the classics.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Clearly that was important in some way.",
        "clean_text": "Clearly that was important in some way.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 80,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:01:15",
    "content": "There aren't that many tokens you consume... That's a good question. Here’s one of the things I thought was really fascinating. [Augustus](https://en.wikipedia.org/wiki/Augustus) became emperor and he was trying to establish peace. There was no real [conception of peace](https://en.wikipedia.org/wiki/Pax_Romana) at the time. The people's understanding of peace was peace as the temporary time between when your enemies inevitably attack you. So you get a short rest. He had this view of changing the economy from being something mercenary and militaristic to this actually positive-sum thing. It was a very novel idea at the time.\n\nThat’s something that's really fundamental: the bounds on what people can conceive of at the time as rational ways to work. This applies to both the metaverse and the AI stuff. A lot of investors, and other people, can't wrap their head around why we would open source this. It’s like “I don't understand, it’s open source. That must just be the temporary time between which you're making things proprietary, right?” I think it's this very profound thing in tech that it actually creates a lot of winners.\n\nI don't want to strain the analogy too much but I do think that a lot of the time, there are models for building things that people often can't even wrap their head around. They can’t understand how that would be a valuable thing for people to do or how it would be a reasonable state of the world. I think there are more reasonable things than people think.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThere aren't that many tokens you consume... That's a good question.",
        "clean_text": "There aren't that many tokens you consume... That's a good question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Here’s one of the things I thought was really fascinating.",
        "clean_text": "Here’s one of the things I thought was really fascinating.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "[Augustus](https://en.wikipedia.org/wiki/Augustus) became emperor and he was trying to establish peace.",
        "clean_text": "Augustus became emperor and he was trying to establish peace.",
        "extracted_information": {
          "links": {
            "Augustus": "https://en.wikipedia.org/wiki/Augustus"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There was no real [conception of peace](https://en.wikipedia.org/wiki/Pax_Romana) at the time.",
        "clean_text": "There was no real conception of peace at the time.",
        "extracted_information": {
          "links": {
            "conception of peace": "https://en.wikipedia.org/wiki/Pax_Romana"
          },
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "The people's understanding of peace was peace as the temporary time between when your enemies inevitably attack you.",
        "clean_text": "The people's understanding of peace was peace as the temporary time between when your enemies inevitably attack you.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "So you get a short rest.",
        "clean_text": "So you get a short rest.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "He had this view of changing the economy from being something mercenary and militaristic to this actually positive-sum thing.",
        "clean_text": "He had this view of changing the economy from being something mercenary and militaristic to this actually positive-sum thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "It was a very novel idea at the time.",
        "clean_text": "It was a very novel idea at the time.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "That’s something that's really fundamental: the bounds on what people can conceive of at the time as rational ways to work.",
        "clean_text": "That’s something that's really fundamental: the bounds on what people can conceive of at the time as rational ways to work.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "This applies to both the metaverse and the AI stuff.",
        "clean_text": "This applies to both the metaverse and the AI stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "A lot of investors, and other people, can't wrap their head around why we would open source this.",
        "clean_text": "A lot of investors, and other people, can't wrap their head around why we would open source this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "It’s like “I don't understand, it’s open source.",
        "clean_text": "It’s like “I don't understand, it’s open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "That must just be the temporary time between which you're making things proprietary, right?” I think it's this very profound thing in tech that it actually creates a lot of winners.",
        "clean_text": "That must just be the temporary time between which you're making things proprietary, right?” I think it's this very profound thing in tech that it actually creates a lot of winners.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "I don't want to strain the analogy too much but I do think that a lot of the time, there are models for building things that people often can't even wrap their head around.",
        "clean_text": "I don't want to strain the analogy too much but I do think that a lot of the time, there are models for building things that people often can't even wrap their head around.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "They can’t understand how that would be a valuable thing for people to do or how it would be a reasonable state of the world.",
        "clean_text": "They can’t understand how that would be a valuable thing for people to do or how it would be a reasonable state of the world.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "I think there are more reasonable things than people think.",
        "clean_text": "I think there are more reasonable things than people think.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 81,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:03:36",
    "content": "That's super fascinating. Can I give you what I was thinking in terms of what you might have gotten from it? This is probably totally off, but I think it’s just how young some of these people are, who have very important roles in the empire. For example, Caesar Augustus, by the time he’s 19, is already one of the most important people in Roman politics. He's [leading battles](https://en.wikipedia.org/wiki/Battle_of_Mutina) and forming the [Second Triumvirate](https://en.wikipedia.org/wiki/Second_Triumvirate). I wonder if the 19-year-old you was thinking “I can do this because Caesar Augustus did this.”",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's super fascinating.",
        "clean_text": "That's super fascinating.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Can I give you what I was thinking in terms of what you might have gotten from it?",
        "clean_text": "Can I give you what I was thinking in terms of what you might have gotten from it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "This is probably totally off, but I think it’s just how young some of these people are, who have very important roles in the empire.",
        "clean_text": "This is probably totally off, but I think it’s just how young some of these people are, who have very important roles in the empire.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "For example, Caesar Augustus, by the time he’s 19, is already one of the most important people in Roman politics.",
        "clean_text": "For example, Caesar Augustus, by the time he’s 19, is already one of the most important people in Roman politics.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "He's [leading battles](https://en.wikipedia.org/wiki/Battle_of_Mutina) and forming the [Second Triumvirate](https://en.wikipedia.org/wiki/Second_Triumvirate).",
        "clean_text": "He's leading battles and forming the Second Triumvirate.",
        "extracted_information": {
          "links": {
            "leading battles": "https://en.wikipedia.org/wiki/Battle_of_Mutina",
            "Second Triumvirate": "https://en.wikipedia.org/wiki/Second_Triumvirate"
          },
          "titles": [
            "of"
          ]
        }
      },
      {
        "index": 5,
        "original_text": "I wonder if the 19-year-old you was thinking “I can do this because Caesar Augustus did this.”",
        "clean_text": "I wonder if the 19-year-old you was thinking “I can do this because Caesar Augustus did this.”",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 82,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:04:01",
    "content": "That's an interesting example, both from a lot of history and American history too. One of my favorite quotes is this [Picasso quote](https://stedelijkstudies.com/picasso-and-the-art-of-children/#:~:text=Several%20modern%20artists%20celebrated%20the,artist%20once%20we%20grow%20up.%E2%80%9D) that all children are artists and the challenge is to remain an artist as you grow up. When you’re younger, it’s just easier to have wild ideas. There are all these analogies to the [innovator’s dilemma](https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma) that exist in your life as well as for your company or whatever you’ve built. You’re earlier on in your trajectory so it's easier to pivot and take in new ideas without disrupting other commitments to different things. I think that's an interesting part of running a company. How do you stay dynamic?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's an interesting example, both from a lot of history and American history too.",
        "clean_text": "That's an interesting example, both from a lot of history and American history too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "One of my favorite quotes is this [Picasso quote](https://stedelijkstudies.com/picasso-and-the-art-of-children/#:~:text=Several%20modern%20artists%20celebrated%20the,artist%20once%20we%20grow%20up.%E2%80%9D) that all children are artists and the challenge is to remain an artist as you grow up.",
        "clean_text": "One of my favorite quotes is this Picasso quote that all children are artists and the challenge is to remain an artist as you grow up.",
        "extracted_information": {
          "links": {
            "Picasso quote": "https://stedelijkstudies.com/picasso-and-the-art-of-children/#:~:text=Several%20modern%20artists%20celebrated%20the,artist%20once%20we%20grow%20up.%E2%80%9D"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "When you’re younger, it’s just easier to have wild ideas.",
        "clean_text": "When you’re younger, it’s just easier to have wild ideas.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "There are all these analogies to the [innovator’s dilemma](https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma) that exist in your life as well as for your company or whatever you’ve built.",
        "clean_text": "There are all these analogies to the innovator’s dilemma that exist in your life as well as for your company or whatever you’ve built.",
        "extracted_information": {
          "links": {
            "innovator’s dilemma": "https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma"
          },
          "titles": [
            "Innovator%27s"
          ]
        }
      },
      {
        "index": 4,
        "original_text": "You’re earlier on in your trajectory so it's easier to pivot and take in new ideas without disrupting other commitments to different things.",
        "clean_text": "You’re earlier on in your trajectory so it's easier to pivot and take in new ideas without disrupting other commitments to different things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I think that's an interesting part of running a company.",
        "clean_text": "I think that's an interesting part of running a company.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "How do you stay dynamic?",
        "clean_text": "How do you stay dynamic?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 83,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:04:53",
    "content": "Let’s go back to the investors and open source. The $10B model, suppose it's totally safe. You've done these evaluations and unlike in this case the evaluators can also fine-tune the model, which hopefully will be the case in future models. Would you open source the $10 billion model?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nLet’s go back to the investors and open source.",
        "clean_text": "Let’s go back to the investors and open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The $10B model, suppose it's totally safe.",
        "clean_text": "The $10B model, suppose it's totally safe.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "You've done these evaluations and unlike in this case the evaluators can also fine-tune the model, which hopefully will be the case in future models.",
        "clean_text": "You've done these evaluations and unlike in this case the evaluators can also fine-tune the model, which hopefully will be the case in future models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "Would you open source the $10 billion model?",
        "clean_text": "Would you open source the $10 billion model?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 84,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:05:11",
    "content": "As long as it's helping us then yeah.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAs long as it's helping us then yeah.",
        "clean_text": "As long as it's helping us then yeah.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 85,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:05:13",
    "content": "But would it? $10 billion of R&D and now it's open source.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBut would it?",
        "clean_text": "But would it?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "$10 billion of R&D and now it's open source.",
        "clean_text": "$10 billion of R&D and now it's open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 86,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:05:17",
    "content": "That’s a question which we’ll have to evaluate as time goes on too. We have a long history of open sourcing software. We don’t tend to open source our product. We don't take the code for Instagram and make it open source. We take a lot of the low-level infrastructure and we make that open source. Probably the biggest one in our history was our [Open Compute Project](https://tech.facebook.com/engineering/2021/11/open-compute-project/) where we took the designs for all of our servers, network switches, and data centers, and made it open source and it ended up being super helpful. Although a lot of people can design servers the industry now standardized on our design, which meant that the supply chains basically all got built out around our design. So volumes went up, it got cheaper for everyone, and it saved us billions of dollars which was awesome.\n\nSo there's multiple ways where open source could be helpful for us. One is if people figure out how to run the models more cheaply. We're going to be spending tens, or a hundred billion dollars or more over time on all this stuff. So if we can do that 10% more efficiently, we're saving billions or tens of billions of dollars. That's probably worth a lot by itself. Especially if there are other competitive models out there, it's not like our thing is giving away some kind of crazy advantage.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat’s a question which we’ll have to evaluate as time goes on too.",
        "clean_text": "That’s a question which we’ll have to evaluate as time goes on too.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "We have a long history of open sourcing software.",
        "clean_text": "We have a long history of open sourcing software.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We don’t tend to open source our product.",
        "clean_text": "We don’t tend to open source our product.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "We don't take the code for Instagram and make it open source.",
        "clean_text": "We don't take the code for Instagram and make it open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "We take a lot of the low-level infrastructure and we make that open source.",
        "clean_text": "We take a lot of the low-level infrastructure and we make that open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "Probably the biggest one in our history was our [Open Compute Project](https://tech.facebook.com/engineering/2021/11/open-compute-project/) where we took the designs for all of our servers, network switches, and data centers, and made it open source and it ended up being super helpful.",
        "clean_text": "Probably the biggest one in our history was our Open Compute Project where we took the designs for all of our servers, network switches, and data centers, and made it open source and it ended up being super helpful.",
        "extracted_information": {
          "links": {
            "Open Compute Project": "https://tech.facebook.com/engineering/2021/11/open-compute-project/"
          },
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "Although a lot of people can design servers the industry now standardized on our design, which meant that the supply chains basically all got built out around our design.",
        "clean_text": "Although a lot of people can design servers the industry now standardized on our design, which meant that the supply chains basically all got built out around our design.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "So volumes went up, it got cheaper for everyone, and it saved us billions of dollars which was awesome.",
        "clean_text": "So volumes went up, it got cheaper for everyone, and it saved us billions of dollars which was awesome.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "So there's multiple ways where open source could be helpful for us.",
        "clean_text": "So there's multiple ways where open source could be helpful for us.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "One is if people figure out how to run the models more cheaply.",
        "clean_text": "One is if people figure out how to run the models more cheaply.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "We're going to be spending tens, or a hundred billion dollars or more over time on all this stuff.",
        "clean_text": "We're going to be spending tens, or a hundred billion dollars or more over time on all this stuff.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "So if we can do that 10% more efficiently, we're saving billions or tens of billions of dollars.",
        "clean_text": "So if we can do that 10% more efficiently, we're saving billions or tens of billions of dollars.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "That's probably worth a lot by itself.",
        "clean_text": "That's probably worth a lot by itself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "Especially if there are other competitive models out there, it's not like our thing is giving away some kind of crazy advantage.",
        "clean_text": "Especially if there are other competitive models out there, it's not like our thing is giving away some kind of crazy advantage.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 87,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:06:38",
    "content": "So is your view that the training will be commodified?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSo is your view that the training will be commodified?",
        "clean_text": "So is your view that the training will be commodified?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 88,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:06:44",
    "content": "I think there's a bunch of ways that this could play out and that's one. So “commodity” implies that it's going to get very cheap because there are lots of options. The other direction that this could go in is qualitative improvements. You mentioned fine-tuning. Right now it's pretty limited what you can do with fine-tuning major other models out there. There are some options but generally not for the biggest models. There’s being able to do that, different app specific things or use case specific things or building them into specific tool chains. I think that will not only enable more efficient development, but it could enable qualitatively different things.\n\nHere's one analogy on this. One thing that I think generally sucks about the mobile ecosystem is that you have these two gatekeeper companies, Apple and Google, that can tell you what you're allowed to build. There's the economic version of that which is like when we build something and they just take a bunch of your money. But then there's the qualitative version, which is actually what upsets me more. There's [a bunch of times](https://www.theverge.com/2019/1/30/18203551/apple-facebook-blocked-internal-ios-apps) when we've launched or wanted to launch features and Apple's just like “nope, you're not launching that.” That sucks, right? So the question is, are we set up for a world like that with AI? You're going to get a handful of companies that run these closed models that are going to be in control of the APIs and therefore able to tell you what you can build?\n\nFor us I can say it is worth it to go build a model ourselves to make sure that we're not in that position. I don't want any of those other companies telling us what we can build. From an open source perspective, I think a lot of developers don't want those companies telling them what they can build either. So the question is, what is the ecosystem that gets built out around that? What are interesting new things? How much does that improve our products? I think there are lots of cases where if this ends up being like our databases or caching systems or architecture, we'll get valuable contributions from the community that will make our stuff better. Our app specific work that we do will then still be so differentiated that it won't really matter. We'll be able to do what we do. We'll benefit and all the systems, ours and the communities’, will be better because it's open source.\n\nThere is one world where maybe that’s not the case. Maybe the model ends up being more of the product itself. I think it's a trickier economic calculation then, whether you open source that. You are commoditizing yourself then a lot. But from what I can see so far, it doesn't seem like we're in that zone.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nI think there's a bunch of ways that this could play out and that's one.",
        "clean_text": "I think there's a bunch of ways that this could play out and that's one.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "So “commodity” implies that it's going to get very cheap because there are lots of options.",
        "clean_text": "So “commodity” implies that it's going to get very cheap because there are lots of options.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The other direction that this could go in is qualitative improvements.",
        "clean_text": "The other direction that this could go in is qualitative improvements.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "You mentioned fine-tuning.",
        "clean_text": "You mentioned fine-tuning.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "Right now it's pretty limited what you can do with fine-tuning major other models out there.",
        "clean_text": "Right now it's pretty limited what you can do with fine-tuning major other models out there.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "There are some options but generally not for the biggest models.",
        "clean_text": "There are some options but generally not for the biggest models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "There’s being able to do that, different app specific things or use case specific things or building them into specific tool chains.",
        "clean_text": "There’s being able to do that, different app specific things or use case specific things or building them into specific tool chains.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "I think that will not only enable more efficient development, but it could enable qualitatively different things.",
        "clean_text": "I think that will not only enable more efficient development, but it could enable qualitatively different things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "Here's one analogy on this.",
        "clean_text": "Here's one analogy on this.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "One thing that I think generally sucks about the mobile ecosystem is that you have these two gatekeeper companies, Apple and Google, that can tell you what you're allowed to build.",
        "clean_text": "One thing that I think generally sucks about the mobile ecosystem is that you have these two gatekeeper companies, Apple and Google, that can tell you what you're allowed to build.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "There's the economic version of that which is like when we build something and they just take a bunch of your money.",
        "clean_text": "There's the economic version of that which is like when we build something and they just take a bunch of your money.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "But then there's the qualitative version, which is actually what upsets me more.",
        "clean_text": "But then there's the qualitative version, which is actually what upsets me more.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "There's [a bunch of times](https://www.theverge.com/2019/1/30/18203551/apple-facebook-blocked-internal-ios-apps) when we've launched or wanted to launch features and Apple's just like “nope, you're not launching that.” That sucks, right?",
        "clean_text": "There's a bunch of times when we've launched or wanted to launch features and Apple's just like “nope, you're not launching that.” That sucks, right?",
        "extracted_information": {
          "links": {
            "a bunch of times": "https://www.theverge.com/2019/1/30/18203551/apple-facebook-blocked-internal-ios-apps"
          },
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "So the question is, are we set up for a world like that with AI?",
        "clean_text": "So the question is, are we set up for a world like that with AI?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "You're going to get a handful of companies that run these closed models that are going to be in control of the APIs and therefore able to tell you what you can build?",
        "clean_text": "You're going to get a handful of companies that run these closed models that are going to be in control of the APIs and therefore able to tell you what you can build?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "For us I can say it is worth it to go build a model ourselves to make sure that we're not in that position.",
        "clean_text": "For us I can say it is worth it to go build a model ourselves to make sure that we're not in that position.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 16,
        "original_text": "I don't want any of those other companies telling us what we can build.",
        "clean_text": "I don't want any of those other companies telling us what we can build.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 17,
        "original_text": "From an open source perspective, I think a lot of developers don't want those companies telling them what they can build either.",
        "clean_text": "From an open source perspective, I think a lot of developers don't want those companies telling them what they can build either.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 18,
        "original_text": "So the question is, what is the ecosystem that gets built out around that?",
        "clean_text": "So the question is, what is the ecosystem that gets built out around that?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 19,
        "original_text": "What are interesting new things?",
        "clean_text": "What are interesting new things?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 20,
        "original_text": "How much does that improve our products?",
        "clean_text": "How much does that improve our products?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 21,
        "original_text": "I think there are lots of cases where if this ends up being like our databases or caching systems or architecture, we'll get valuable contributions from the community that will make our stuff better.",
        "clean_text": "I think there are lots of cases where if this ends up being like our databases or caching systems or architecture, we'll get valuable contributions from the community that will make our stuff better.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 22,
        "original_text": "Our app specific work that we do will then still be so differentiated that it won't really matter.",
        "clean_text": "Our app specific work that we do will then still be so differentiated that it won't really matter.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 23,
        "original_text": "We'll be able to do what we do.",
        "clean_text": "We'll be able to do what we do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 24,
        "original_text": "We'll benefit and all the systems, ours and the communities’, will be better because it's open source.",
        "clean_text": "We'll benefit and all the systems, ours and the communities’, will be better because it's open source.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 25,
        "original_text": "There is one world where maybe that’s not the case.",
        "clean_text": "There is one world where maybe that’s not the case.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 26,
        "original_text": "Maybe the model ends up being more of the product itself.",
        "clean_text": "Maybe the model ends up being more of the product itself.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 27,
        "original_text": "I think it's a trickier economic calculation then, whether you open source that.",
        "clean_text": "I think it's a trickier economic calculation then, whether you open source that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 28,
        "original_text": "You are commoditizing yourself then a lot.",
        "clean_text": "You are commoditizing yourself then a lot.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 29,
        "original_text": "But from what I can see so far, it doesn't seem like we're in that zone.",
        "clean_text": "But from what I can see so far, it doesn't seem like we're in that zone.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 89,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:09:42",
    "content": "Do you expect to earn significant revenue from licensing your model to the cloud providers? So they have to pay you a fee to actually serve the model.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nDo you expect to earn significant revenue from licensing your model to the cloud providers?",
        "clean_text": "Do you expect to earn significant revenue from licensing your model to the cloud providers?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "So they have to pay you a fee to actually serve the model.",
        "clean_text": "So they have to pay you a fee to actually serve the model.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 90,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:09:49",
    "content": "We want to have an arrangement like that but I don't know how significant it'll be. This is basically our license for Llama. In a lot of ways it's a very permissive open source license, except that we have a limit for the largest companies using it. This is why we put that limit in. We're not trying to prevent them from using it. We just want them to come talk to us if they're going to just basically take what we built and resell it and make money off of it. If you're like [Microsoft Azure](https://azure.microsoft.com/en-us) or [Amazon](https://aws.amazon.com/free/?trk=fce796e8-4ceb-48e0-9767-89f7873fac3d&sc_channel=ps&ef_id=Cj0KCQjwiYOxBhC5ARIsAIvdH52nDKliMjrj23E3ECqwNWLErxQrfpjdolOxCX1-rhhvyoab_OoQWIkaAqrVEALw_wcB:G:s&s_kwcid=AL!4422!3!432339156147!e!!g!!amazon%20web%20services!1644045032!68366401812), if you're going to be reselling the model then we should have some revenue share on that. So just come talk to us before you go do that. That's how that's played out.\n\nSo for Llama-2, we just have deals with basically all these major cloud companies and [Llama-2 is available as a hosted service](https://aws.amazon.com/bedrock/llama/) on all those clouds. I assume that as we release bigger and bigger models, that will become a bigger thing. It's not the main thing that we're doing, but I think if those companies are going to be selling our models it just makes sense that we should share the upside of that somehow.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nWe want to have an arrangement like that but I don't know how significant it'll be.",
        "clean_text": "We want to have an arrangement like that but I don't know how significant it'll be.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "This is basically our license for Llama.",
        "clean_text": "This is basically our license for Llama.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "In a lot of ways it's a very permissive open source license, except that we have a limit for the largest companies using it.",
        "clean_text": "In a lot of ways it's a very permissive open source license, except that we have a limit for the largest companies using it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "This is why we put that limit in.",
        "clean_text": "This is why we put that limit in.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "We're not trying to prevent them from using it.",
        "clean_text": "We're not trying to prevent them from using it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "We just want them to come talk to us if they're going to just basically take what we built and resell it and make money off of it.",
        "clean_text": "We just want them to come talk to us if they're going to just basically take what we built and resell it and make money off of it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "If you're like [Microsoft Azure](https://azure.microsoft.com/en-us) or [Amazon](https://aws.amazon.com/free/?trk=fce796e8-4ceb-48e0-9767-89f7873fac3d&sc_channel=ps&ef_id=Cj0KCQjwiYOxBhC5ARIsAIvdH52nDKliMjrj23E3ECqwNWLErxQrfpjdolOxCX1-rhhvyoab_OoQWIkaAqrVEALw_wcB:G:s&s_kwcid=AL!4422!3!432339156147!e!!g!",
        "clean_text": "If you're like Microsoft Azure or [Amazon](https://aws.amazon.com/free/?trk=fce796e8-4ceb-48e0-9767-89f7873fac3d&scchannel=ps&efid=Cj0KCQjwiYOxBhC5ARIsAIvdH52nDKliMjrj23E3ECqwNWLErxQrfpjdolOxCX1-rhhvyoabOoQWIkaAqrVEALwwcB:G:s&s_kwcid=AL!4422!3!432339156147!e!!g!",
        "extracted_information": {
          "links": {
            "Microsoft Azure": "https://azure.microsoft.com/en-us"
          },
          "titles": [
            "channel=ps&ef",
            "OoQWIkaAqrVEALw"
          ]
        }
      },
      {
        "index": 7,
        "original_text": "!amazon%20web%20services!1644045032!68366401812), if you're going to be reselling the model then we should have some revenue share on that.",
        "clean_text": "!amazon%20web%20services!1644045032!68366401812), if you're going to be reselling the model then we should have some revenue share on that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "So just come talk to us before you go do that.",
        "clean_text": "So just come talk to us before you go do that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "That's how that's played out.",
        "clean_text": "That's how that's played out.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "So for Llama-2, we just have deals with basically all these major cloud companies and [Llama-2 is available as a hosted service](https://aws.amazon.com/bedrock/llama/) on all those clouds.",
        "clean_text": "So for Llama-2, we just have deals with basically all these major cloud companies and Llama-2 is available as a hosted service on all those clouds.",
        "extracted_information": {
          "links": {
            "Llama-2 is available as a hosted service": "https://aws.amazon.com/bedrock/llama/"
          },
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "I assume that as we release bigger and bigger models, that will become a bigger thing.",
        "clean_text": "I assume that as we release bigger and bigger models, that will become a bigger thing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "It's not the main thing that we're doing, but I think if those companies are going to be selling our models it just makes sense that we should share the upside of that somehow.",
        "clean_text": "It's not the main thing that we're doing, but I think if those companies are going to be selling our models it just makes sense that we should share the upside of that somehow.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 91,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:10:55",
    "content": "Regarding other open source dangers, I think you have genuine legitimate points about the balance of power stuff and potentially the harms you can get rid of because we have better alignment techniques or something. I wish there were some sort of framework that Meta had. [Other labs have this](https://www.anthropic.com/news/anthropics-responsible-scaling-policy) where they say “if we see this concrete thing, then that's a no go on the open source or even potentially on deployment.” Just writing it down so the company is ready for it and people have expectations around it and so forth.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nRegarding other open source dangers, I think you have genuine legitimate points about the balance of power stuff and potentially the harms you can get rid of because we have better alignment techniques or something.",
        "clean_text": "Regarding other open source dangers, I think you have genuine legitimate points about the balance of power stuff and potentially the harms you can get rid of because we have better alignment techniques or something.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I wish there were some sort of framework that Meta had.",
        "clean_text": "I wish there were some sort of framework that Meta had.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "[Other labs have this](https://www.anthropic.com/news/anthropics-responsible-scaling-policy) where they say “if we see this concrete thing, then that's a no go on the open source or even potentially on deployment.” Just writing it down so the company is ready for it and people have expectations around it and so forth.",
        "clean_text": "Other labs have this where they say “if we see this concrete thing, then that's a no go on the open source or even potentially on deployment.” Just writing it down so the company is ready for it and people have expectations around it and so forth.",
        "extracted_information": {
          "links": {
            "Other labs have this": "https://www.anthropic.com/news/anthropics-responsible-scaling-policy"
          },
          "titles": []
        }
      }
    ]
  },
  {
    "index": 92,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:11:25",
    "content": "That's a fair point on the existential risk side. Right now we focus more on the types of risks that we see today, which are more of these content risks. We don't want the model to be doing things that are helping people commit violence or fraud or just harming people in different ways. While it is maybe more intellectually interesting to talk about the existential risks, I actually think the real harms that need more energy in being mitigated are things where someone takes a model and does something to hurt a person. In practice for the current models, and I would guess the next generation and maybe even the generation after that, those are the types of more mundane harms that we see today, people committing fraud against each other or things like that. I just don't want to shortchange that. I think we have a responsibility to make sure we do a good job on that.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nThat's a fair point on the existential risk side.",
        "clean_text": "That's a fair point on the existential risk side.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Right now we focus more on the types of risks that we see today, which are more of these content risks.",
        "clean_text": "Right now we focus more on the types of risks that we see today, which are more of these content risks.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "We don't want the model to be doing things that are helping people commit violence or fraud or just harming people in different ways.",
        "clean_text": "We don't want the model to be doing things that are helping people commit violence or fraud or just harming people in different ways.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "While it is maybe more intellectually interesting to talk about the existential risks, I actually think the real harms that need more energy in being mitigated are things where someone takes a model and does something to hurt a person.",
        "clean_text": "While it is maybe more intellectually interesting to talk about the existential risks, I actually think the real harms that need more energy in being mitigated are things where someone takes a model and does something to hurt a person.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "In practice for the current models, and I would guess the next generation and maybe even the generation after that, those are the types of more mundane harms that we see today, people committing fraud against each other or things like that.",
        "clean_text": "In practice for the current models, and I would guess the next generation and maybe even the generation after that, those are the types of more mundane harms that we see today, people committing fraud against each other or things like that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I just don't want to shortchange that.",
        "clean_text": "I just don't want to shortchange that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "I think we have a responsibility to make sure we do a good job on that.",
        "clean_text": "I think we have a responsibility to make sure we do a good job on that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 93,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:12:33",
    "content": "Meta's a big company. You can handle both.\n\nAs far as open source goes, I'm actually curious if you think the impact of open source, from [PyTorch](https://pytorch.org/), [React](https://react.dev/), [Open Compute](https://www.opencompute.org/) and other things, has been bigger for the world than even the social media aspects of Meta. I've talked to people who use these services and they think that it's plausible because a big part of the internet runs on these things.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nMeta's a big company.",
        "clean_text": "Meta's a big company.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "You can handle both.",
        "clean_text": "You can handle both.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "As far as open source goes, I'm actually curious if you think the impact of open source, from [PyTorch](https://pytorch.org/), [React](https://react.dev/), [Open Compute](https://www.opencompute.org/) and other things, has been bigger for the world than even the social media aspects of Meta.",
        "clean_text": "As far as open source goes, I'm actually curious if you think the impact of open source, from PyTorch, React, Open Compute and other things, has been bigger for the world than even the social media aspects of Meta.",
        "extracted_information": {
          "links": {
            "PyTorch": "https://pytorch.org/",
            "React": "https://react.dev/",
            "Open Compute": "https://www.opencompute.org/"
          },
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I've talked to people who use these services and they think that it's plausible because a big part of the internet runs on these things.",
        "clean_text": "I've talked to people who use these services and they think that it's plausible because a big part of the internet runs on these things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 94,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:12:55",
    "content": "It's an interesting question. I mean almost half the world uses our consumer products so it's hard to beat that. But I think open source is really powerful as a new way of building things. I mean, it's possible. It may be one of these things like [Bell Labs](https://en.wikipedia.org/wiki/Bell_Labs), where they were working on the [transistor](https://en.wikipedia.org/wiki/Transistor#Bipolar_transistors) because they wanted to enable long-distance calling. They did and it ended up being really profitable for them that they were able to enable long-distance calling. 5 to 10 years out from that, if you asked them what was the most useful thing that they invented it's like “okay, we enabled long distance calling and now all these people are long-distance calling.” But if you asked a hundred years later maybe it's a different answer.\n\nI think that's true of a lot of the things that we're building: [Reality Labs](https://about.meta.com/realitylabs/), some of the AI stuff, some of the open source stuff. The specific products evolve, and to some degree come and go, but the advances for humanity persist and that's a cool part of what we all get to do.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nIt's an interesting question.",
        "clean_text": "It's an interesting question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "I mean almost half the world uses our consumer products so it's hard to beat that.",
        "clean_text": "I mean almost half the world uses our consumer products so it's hard to beat that.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "But I think open source is really powerful as a new way of building things.",
        "clean_text": "But I think open source is really powerful as a new way of building things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "I mean, it's possible.",
        "clean_text": "I mean, it's possible.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "It may be one of these things like [Bell Labs](https://en.wikipedia.org/wiki/Bell_Labs), where they were working on the [transistor](https://en.wikipedia.org/wiki/Transistor#Bipolar_transistors) because they wanted to enable long-distance calling.",
        "clean_text": "It may be one of these things like Bell Labs, where they were working on the transistor because they wanted to enable long-distance calling.",
        "extracted_information": {
          "links": {
            "Bell Labs": "https://en.wikipedia.org/wiki/Bell_Labs",
            "transistor": "https://en.wikipedia.org/wiki/Transistor#Bipolar_transistors"
          },
          "titles": [
            "Labs), where they were working on the [transistor](https://en.wikipedia.org/wiki/Transistor#Bipolar"
          ]
        }
      },
      {
        "index": 5,
        "original_text": "They did and it ended up being really profitable for them that they were able to enable long-distance calling.",
        "clean_text": "They did and it ended up being really profitable for them that they were able to enable long-distance calling.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "5 to 10 years out from that, if you asked them what was the most useful thing that they invented it's like “okay, we enabled long distance calling and now all these people are long-distance calling.” But if you asked a hundred years later maybe it's a different answer.",
        "clean_text": "5 to 10 years out from that, if you asked them what was the most useful thing that they invented it's like “okay, we enabled long distance calling and now all these people are long-distance calling.” But if you asked a hundred years later maybe it's a different answer.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "I think that's true of a lot of the things that we're building: [Reality Labs](https://about.meta.com/realitylabs/), some of the AI stuff, some of the open source stuff.",
        "clean_text": "I think that's true of a lot of the things that we're building: Reality Labs, some of the AI stuff, some of the open source stuff.",
        "extracted_information": {
          "links": {
            "Reality Labs": "https://about.meta.com/realitylabs/"
          },
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "The specific products evolve, and to some degree come and go, but the advances for humanity persist and that's a cool part of what we all get to do.",
        "clean_text": "The specific products evolve, and to some degree come and go, but the advances for humanity persist and that's a cool part of what we all get to do.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 95,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:14:14",
    "content": "By when will the Llama models be trained on your own custom silicon?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nBy when will the Llama models be trained on your own custom silicon?",
        "clean_text": "By when will the Llama models be trained on your own custom silicon?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 96,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:14:19",
    "content": "Soon, not Llama-4. The approach that we took is we first built [custom silicon that could handle inference](https://ai.meta.com/blog/meta-training-inference-accelerator-AI-MTIA/) for our ranking and recommendation type stuff, so Reels, News Feed ads, etc. That was consuming a lot of GPUs. When we were able to move that to our own silicon, we're now able to use the more expensive [NVIDIA GPUs](https://www.nvidia.com/en-us/data-center/h100/) only for training. At some point we will hopefully have silicon ourselves that we can be using for at first training some of the simpler things, then eventually training these really large models. In the meantime, I'd say the program is going quite well and we're just rolling it out methodically and we have a long-term roadmap for it.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nSoon, not Llama-4.",
        "clean_text": "Soon, not Llama-4.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "The approach that we took is we first built [custom silicon that could handle inference](https://ai.meta.com/blog/meta-training-inference-accelerator-AI-MTIA/) for our ranking and recommendation type stuff, so Reels, News Feed ads, etc.",
        "clean_text": "The approach that we took is we first built custom silicon that could handle inference for our ranking and recommendation type stuff, so Reels, News Feed ads, etc.",
        "extracted_information": {
          "links": {
            "custom silicon that could handle inference": "https://ai.meta.com/blog/meta-training-inference-accelerator-AI-MTIA/"
          },
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "That was consuming a lot of GPUs.",
        "clean_text": "That was consuming a lot of GPUs.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "When we were able to move that to our own silicon, we're now able to use the more expensive [NVIDIA GPUs](https://www.nvidia.com/en-us/data-center/h100/) only for training.",
        "clean_text": "When we were able to move that to our own silicon, we're now able to use the more expensive NVIDIA GPUs only for training.",
        "extracted_information": {
          "links": {
            "NVIDIA GPUs": "https://www.nvidia.com/en-us/data-center/h100/"
          },
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "At some point we will hopefully have silicon ourselves that we can be using for at first training some of the simpler things, then eventually training these really large models.",
        "clean_text": "At some point we will hopefully have silicon ourselves that we can be using for at first training some of the simpler things, then eventually training these really large models.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "In the meantime, I'd say the program is going quite well and we're just rolling it out methodically and we have a long-term roadmap for it.",
        "clean_text": "In the meantime, I'd say the program is going quite well and we're just rolling it out methodically and we have a long-term roadmap for it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 97,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:15:19",
    "content": "Final question. This is totally out of left field. If you were made CEO of [Google+](https://en.wikipedia.org/wiki/Google%2B) could you have made it work?",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nFinal question.",
        "clean_text": "Final question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "This is totally out of left field.",
        "clean_text": "This is totally out of left field.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "If you were made CEO of [Google+](https://en.wikipedia.org/wiki/Google%2B) could you have made it work?",
        "clean_text": "If you were made CEO of Google+ could you have made it work?",
        "extracted_information": {
          "links": {
            "Google+": "https://en.wikipedia.org/wiki/Google%2B"
          },
          "titles": []
        }
      }
    ]
  },
  {
    "index": 98,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:15:24",
    "content": "Google+? Oof. I don't know. That's a very difficult counterfactual.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nGoogle+?",
        "clean_text": "Google+?",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Oof.",
        "clean_text": "Oof.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "I don't know.",
        "clean_text": "I don't know.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "That's a very difficult counterfactual.",
        "clean_text": "That's a very difficult counterfactual.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 99,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:15:35",
    "content": "Okay, then the real final question will be: when [Gemini](https://gemini.google.com/) was launched, was there any chance that [somebody in the office uttered](https://www.vanityfair.com/news/2016/06/how-mark-zuckerberg-led-facebooks-war-to-crush-google-plus): “[Carthago delenda est](https://en.wikipedia.org/wiki/Carthago_delenda_est)”.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nOkay, then the real final question will be: when [Gemini](https://gemini.google.com/) was launched, was there any chance that [somebody in the office uttered](https://www.vanityfair.com/news/2016/06/how-mark-zuckerberg-led-facebooks-war-to-crush-google-plus): “[Carthago delenda est](https://en.wikipedia.org/wiki/Carthago_delenda_est)”.",
        "clean_text": "Okay, then the real final question will be: when Gemini was launched, was there any chance that somebody in the office uttered: “Carthago delenda est”.",
        "extracted_information": {
          "links": {
            "Gemini": "https://gemini.google.com/",
            "somebody in the office uttered": "https://www.vanityfair.com/news/2016/06/how-mark-zuckerberg-led-facebooks-war-to-crush-google-plus",
            "Carthago delenda est": "https://en.wikipedia.org/wiki/Carthago_delenda_est"
          },
          "titles": [
            "delenda"
          ]
        }
      }
    ]
  },
  {
    "index": 100,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:15:43",
    "content": "No, I think we're tamer now. It's a good question. The problem is there was no CEO of Google+. It was just a division within a company. You asked before about what are the scarcest commodities but you asked about it in terms of dollars. I actually think for most companies, of this scale at least, it's focus. When you're a startup maybe you're more constrained on capital. You’re just working on one idea and you might not have all the resources. You cross some threshold at some point with the nature of what you're doing. You're building multiple things. You're creating more value across them but you become more constrained on what you can direct to go well.\n\nThere are always the cases where something random awesome happens in the organization and I don't even know about it. Those are great. But I think in general, the organization's capacity is largely limited by what the CEO and the management team are able to oversee and manage. That's been a big focus for us. As [Ben Horowitz](https://a16z.com/author/ben-horowitz/) says “keep the main thing, the main thing” and try to stay focused on your key priorities.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nNo, I think we're tamer now.",
        "clean_text": "No, I think we're tamer now.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "It's a good question.",
        "clean_text": "It's a good question.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "The problem is there was no CEO of Google+.",
        "clean_text": "The problem is there was no CEO of Google+.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 3,
        "original_text": "It was just a division within a company.",
        "clean_text": "It was just a division within a company.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 4,
        "original_text": "You asked before about what are the scarcest commodities but you asked about it in terms of dollars.",
        "clean_text": "You asked before about what are the scarcest commodities but you asked about it in terms of dollars.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 5,
        "original_text": "I actually think for most companies, of this scale at least, it's focus.",
        "clean_text": "I actually think for most companies, of this scale at least, it's focus.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 6,
        "original_text": "When you're a startup maybe you're more constrained on capital.",
        "clean_text": "When you're a startup maybe you're more constrained on capital.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 7,
        "original_text": "You’re just working on one idea and you might not have all the resources.",
        "clean_text": "You’re just working on one idea and you might not have all the resources.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 8,
        "original_text": "You cross some threshold at some point with the nature of what you're doing.",
        "clean_text": "You cross some threshold at some point with the nature of what you're doing.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 9,
        "original_text": "You're building multiple things.",
        "clean_text": "You're building multiple things.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 10,
        "original_text": "You're creating more value across them but you become more constrained on what you can direct to go well.",
        "clean_text": "You're creating more value across them but you become more constrained on what you can direct to go well.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 11,
        "original_text": "There are always the cases where something random awesome happens in the organization and I don't even know about it.",
        "clean_text": "There are always the cases where something random awesome happens in the organization and I don't even know about it.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 12,
        "original_text": "Those are great.",
        "clean_text": "Those are great.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 13,
        "original_text": "But I think in general, the organization's capacity is largely limited by what the CEO and the management team are able to oversee and manage.",
        "clean_text": "But I think in general, the organization's capacity is largely limited by what the CEO and the management team are able to oversee and manage.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 14,
        "original_text": "That's been a big focus for us.",
        "clean_text": "That's been a big focus for us.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 15,
        "original_text": "As [Ben Horowitz](https://a16z.com/author/ben-horowitz/) says “keep the main thing, the main thing” and try to stay focused on your key priorities.",
        "clean_text": "As Ben Horowitz says “keep the main thing, the main thing” and try to stay focused on your key priorities.",
        "extracted_information": {
          "links": {
            "Ben Horowitz": "https://a16z.com/author/ben-horowitz/"
          },
          "titles": []
        }
      }
    ]
  },
  {
    "index": 101,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:17:14",
    "content": "Awesome, that was excellent, Mark. Thanks so much. That was a lot of fun.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAwesome, that was excellent, Mark.",
        "clean_text": "Awesome, that was excellent, Mark.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Thanks so much.",
        "clean_text": "Thanks so much.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 2,
        "original_text": "That was a lot of fun.",
        "clean_text": "That was a lot of fun.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 102,
    "role": "Guest",
    "speaker": "Mark Zuckerberg",
    "start_time": "01:17:17",
    "content": "Yeah, really fun. Thanks for having me.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nYeah, really fun.",
        "clean_text": "Yeah, really fun.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      },
      {
        "index": 1,
        "original_text": "Thanks for having me.",
        "clean_text": "Thanks for having me.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  },
  {
    "index": 103,
    "role": "Host",
    "speaker": "Dwarkesh Patel",
    "start_time": "01:17:19",
    "content": "Absolutely.",
    "sentences": [
      {
        "index": 0,
        "original_text": "\nAbsolutely.",
        "clean_text": "Absolutely.",
        "extracted_information": {
          "links": {},
          "titles": []
        }
      }
    ]
  }
]